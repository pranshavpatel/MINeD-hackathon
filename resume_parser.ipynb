{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HuHemCcizBfG",
        "outputId": "cf4faaac-7570-46a8-ff82-b9e720fb1039"
      },
      "execution_count": 269,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "CPU times: user 47.2 ms, sys: 5.5 ms, total: 52.7 ms\n",
            "Wall time: 3.28 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# machine specifications:\n",
        "import platform\n",
        "print(platform.machine())\n",
        "print(platform.version())\n",
        "print(platform.platform())\n",
        "print(platform.uname())\n",
        "print(platform.system())\n",
        "print(platform.processor())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7cYAorXEwIv",
        "outputId": "edfe396c-2a68-46a0-a572-4c0a4cf548e5"
      },
      "execution_count": 270,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x86_64\n",
            "#1 SMP PREEMPT_DYNAMIC Sat Nov 18 15:31:17 UTC 2023\n",
            "Linux-6.1.58+-x86_64-with-glibc2.35\n",
            "uname_result(system='Linux', node='45198cd6bcf3', release='6.1.58+', version='#1 SMP PREEMPT_DYNAMIC Sat Nov 18 15:31:17 UTC 2023', machine='x86_64')\n",
            "Linux\n",
            "x86_64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "!pip install spacy\n",
        "!python -m spacy download en_core_web_sm\n",
        "!pip install PyMuPDF\n",
        "!pip install python-docx\n",
        "!pip install beautifulsoup4 lxml\n",
        "!pip install pytesseract\n",
        "!sudo apt-get install tesseract-ocr\n",
        "!pip install tensorflow\n",
        "!pip install sentence_transformers\n",
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oj-zR3pixH70",
        "outputId": "a3be291b-fc55-4cf4-f0a5-af4776a357e8"
      },
      "execution_count": 271,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.6.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.25.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.6.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.25.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Requirement already satisfied: PyMuPDF in /usr/local/lib/python3.10/dist-packages (1.23.26)\n",
            "Requirement already satisfied: PyMuPDFb==1.23.22 in /usr/local/lib/python3.10/dist-packages (from PyMuPDF) (1.23.22)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.10/dist-packages (1.1.0)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.10.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (4.9.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.10/dist-packages (0.3.10)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (23.2)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (9.4.0)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.10.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.10/dist-packages (2.5.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.38.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.1.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.20.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (0.4.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "CPU times: user 772 ms, sys: 70.6 ms, total: 843 ms\n",
            "Wall time: 1min 17s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 272,
      "metadata": {
        "id": "esNMRoYcSNvs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f0b7247-1854-4f4e-94f6-3caeaee02fad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.4 ms, sys: 0 ns, total: 1.4 ms\n",
            "Wall time: 12.2 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "import json\n",
        "import re\n",
        "import fitz\n",
        "from docx import Document\n",
        "from bs4 import BeautifulSoup\n",
        "import pytesseract\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer, util"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install docx2pdf\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_oX6oD4RKi0",
        "outputId": "a77343f2-6f55-4a9d-da28-0ee7b8261a05"
      },
      "execution_count": 273,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: docx2pdf in /usr/local/lib/python3.10/dist-packages (0.1.8)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from docx2pdf) (4.66.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "from docx2pdf import convert\n",
        "\n",
        "def doc2text(file_path) :\n",
        "\n",
        "    if file_path.endswith('pdf'):\n",
        "        with fitz.open(file_path) as doc:\n",
        "            text = \"\"\n",
        "            for page in doc:\n",
        "                text += page.get_text()\n",
        "        return text\n",
        "\n",
        "    elif file_path.endswith('docx') or file_path.endswith('DOCX') or file_path.endswith('Docx'):\n",
        "        document = Document(file_path)\n",
        "        text = []\n",
        "        for paragraph in document.paragraphs:\n",
        "            text.append(paragraph.text)\n",
        "        return '\\n'.join(text)\n",
        "\n",
        "    elif file_path.endswith('html') or file_path.endswith('HTML'):\n",
        "        with open(file_path, 'r', encoding='utf-8') as file:\n",
        "            html_content = file.read()\n",
        "        soup = BeautifulSoup(html_content, 'lxml')\n",
        "        return soup.get_text(separator='\\n', strip=True)\n",
        "\n",
        "    elif file_path.endswith('jpg') or file_path.endswith('jpeg') or file_path.endswith('png'):\n",
        "      image = Image.open(file_path)\n",
        "      extracted_text = pytesseract.image_to_string(image)\n",
        "      return extracted_text\n"
      ],
      "metadata": {
        "id": "uuZHPDZ1aGLz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9b7ba8c-6080-4ea3-e5c2-83943ab026b8"
      },
      "execution_count": 274,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 15 µs, sys: 0 ns, total: 15 µs\n",
            "Wall time: 18.4 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resume Parsing"
      ],
      "metadata": {
        "id": "n9x3RrDsy0Jh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 275,
      "metadata": {
        "id": "y6lAnbfESWBi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16ccaa19-d113-4e28-a88f-a94ea646fe4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 10 µs, sys: 0 ns, total: 10 µs\n",
            "Wall time: 13.4 µs\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "sec = [[#skills\n",
        "        'areas of experience',\n",
        "        'areas of expertise',\n",
        "        'areas of knowledge',\n",
        "        'skills',\n",
        "\n",
        "        \"other skills\",\n",
        "        \"other abilities\",\n",
        "        'career related skills',\n",
        "        'professional skills',\n",
        "        'specialized skills',\n",
        "        'technical skills',\n",
        "        'soft skills',\n",
        "        'computer skills',\n",
        "        'personal skills',\n",
        "        # 'computer knowledge',\n",
        "        # 'technologies',\n",
        "\n",
        "        'proficiencies',\n",
        "        'languages',\n",
        "        'language competencies and skills',\n",
        "        'programming languages',\n",
        "        'competencies'\n",
        "],\n",
        "      [#experience\n",
        "        'employment history',\n",
        "        'employment data',\n",
        "        'career summary',\n",
        "        'work history',\n",
        "       'technical experience',\n",
        "        'working history',\n",
        "        'work experience',\n",
        "        'experience',\n",
        "        'professional experience',\n",
        "        'professional background',\n",
        "        'professional employment',\n",
        "        'additional experience',\n",
        "        'career related experience',\n",
        "        \"professional employment history\",\n",
        "        'related experience',\n",
        "        'relevant experience',\n",
        "        'programming experience',\n",
        "        'freelance',\n",
        "        'freelance experience',\n",
        "        'internship experience',\n",
        "        'internships',\n",
        "        'apprenticeships',\n",
        "        'army experience',\n",
        "        'military experience',\n",
        "        'military background',\n",
        "               'special training',\n",
        "       'training'\n",
        "\n",
        "],\n",
        "[#education\n",
        "        'academic background',\n",
        "        'academic experience',\n",
        "\n",
        "        'courses',\n",
        "        'qualification',\n",
        "        'related courses',\n",
        "        'education',\n",
        "        'educational background',\n",
        "        'educational qualifications',\n",
        "        'educational training',\n",
        "        'education and training',\n",
        "        'academic training',\n",
        "        'Academic Qualification',\n",
        "        #'professional training',\n",
        "        'course project experience',\n",
        "        'related course projects',\n",
        "        'college activities',\n",
        "        'certifications',\n",
        "    ],\n",
        "\n",
        "\n",
        "\n",
        "[#miscellaneous\n",
        "        'activities and honors',\n",
        "        #'activities',\n",
        "        'affiliations',\n",
        "        'professional affiliations',\n",
        "        'associations',\n",
        "        'professional associations',\n",
        "        'memberships',\n",
        "        'professional memberships',\n",
        "        'athletic involvement',\n",
        "        'community involvement',\n",
        "\n",
        "        'civic activities',\n",
        "        'extra-Curricular activities',\n",
        "        'professional activities',\n",
        "        'volunteer work',\n",
        "        'volunteer experience',\n",
        "        'additional information',\n",
        "\n",
        "],\n",
        "\n",
        "[#achievements\n",
        "        'achievement',\n",
        "        'achievements',\n",
        "        'awards and achievements',\n",
        "        'licenses',\n",
        "        'license',\n",
        "\n",
        "        'conference presentations',\n",
        "        'conventions',\n",
        "        'dissertations',\n",
        "        'exhibits',\n",
        "        'papers',\n",
        "        'publications',\n",
        "        'professional publications',\n",
        "        'research experience',\n",
        "        'research grants',\n",
        "\n",
        "\n",
        "        'research projects',\n",
        "        'personal projects',\n",
        "        'current research interests',\n",
        "\n",
        "]\n",
        "]\n",
        "\n",
        "section_names=[\"skills\",\"experience\",\"education\",\"miscellaneous\",\"achievements\"]\n",
        "check_segmented = [\n",
        "    False,\n",
        "    False,\n",
        "    False,\n",
        "    False,\n",
        "    False,\n",
        "\n",
        "]\n",
        "\n",
        "def classify_sections(text):\n",
        "    # custom logic for classifying sections (similar to the previous example)\n",
        "    sections = {}\n",
        "    current_section = None\n",
        "    temp=False\n",
        "    for line in text.split('\\n'):\n",
        "     # print(line)\n",
        "      temp=False\n",
        "      for section_keywords in sec:\n",
        "        if  (check_segmented[sec.index(section_keywords)]==False) and any((keyword.lower() in line.lower())  for keyword in section_keywords):\n",
        "            for i in range(len(check_segmented)):\n",
        "              check_segmented[i]=False\n",
        "            check_segmented[sec.index(section_keywords)] = True\n",
        "\n",
        "            temp=True\n",
        "            current_section =section_names[sec.index(section_keywords)]\n",
        "            if sections.get(current_section,0)!=0:\n",
        "              continue\n",
        "            sections[current_section] = []\n",
        "            break\n",
        "      if current_section !=None and temp==False:\n",
        "        sections[current_section].append(line)\n",
        "\n",
        "\n",
        "    return sections\n",
        "\n",
        "def parse_resume(path):\n",
        "    text = doc2text(path)\n",
        "    sections = classify_sections(text)\n",
        "    return text, sections\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "import pandas as pd\n",
        "df=pd.DataFrame(columns=section_names)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "i55C1RHmqNlM",
        "outputId": "65e4f6fc-a931-4912-d768-cffb137dfb98"
      },
      "execution_count": 276,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2.83 ms, sys: 0 ns, total: 2.83 ms\n",
            "Wall time: 3.32 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [skills, experience, education, miscellaneous, achievements]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b769581d-759f-4880-83fb-300544913f48\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>skills</th>\n",
              "      <th>experience</th>\n",
              "      <th>education</th>\n",
              "      <th>miscellaneous</th>\n",
              "      <th>achievements</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b769581d-759f-4880-83fb-300544913f48')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b769581d-759f-4880-83fb-300544913f48 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b769581d-759f-4880-83fb-300544913f48');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_98a04bf3-2673-4247-a8bc-02c1154058ef\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_98a04bf3-2673-4247-a8bc-02c1154058ef button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "repr_error": "'str' object has no attribute 'empty'"
            }
          },
          "metadata": {},
          "execution_count": 276
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 277,
      "metadata": {
        "id": "0bQOogIXZxF4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10e8be9f-4367-4587-b761-b7b270fdaa95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resume Sections:\n",
            "Education   :\n",
            "Columbia University\n",
            "New York, NY\n",
            "Master of Science in Data Science, GPA: 4.08/4.00\n",
            "Dec 2020\n",
            "Coursework: Machine Learning, Applied Machine Learning, Applied Deep Learning, Statistical Inference & Modeling,\n",
            "Personalization Theory, Natural Language Processing, Algorithms for Data Science, Computer Systems, Exploratory Data\n",
            "Analysis and Visualization\n",
            "Nirma University\n",
            "Ahmedabad, India\n",
            "Bachelor of Technology in Computer Engineering, GPA: 9.50/10, Rank: 2/900\n",
            "May 2019\n",
            "Coursework: Machine Learning, Deep Learning, Artificial Intelligence, Linear Algebra, Algorithms\n",
            "-----------------\n",
            "Experience   :\n",
            "SLB Software Technology Innovation Center (STIC)\n",
            "Menlo Park, CA\n",
            "Data Scientist\n",
            "Feb 2021 - Present\n",
            "Physics-Informed Machine Learning and Time Series Analysis\n",
            "● Developed Physics Informed Machine Learning based Hybrid Framework to create an advisory system that identifies the\n",
            "regions with risky Stick/Slip conditions and outputs an optimal operating window for drilling the future stands\n",
            "● Devised Hybrid framework using Physics Informed Machine Learning for digitally generating LWD logs (Gamma-Ray\n",
            "logs) in real-time to increase efficiency and robustness of log collection process\n",
            "● Working towards implementation of Physics Inspired Machine Learning based toolbox for Time Series data\n",
            "Computer Vision\n",
            "● Researched and implemented various Computer Vision based use cases to improve Health Safety and Environment\n",
            "● Evaluated 5+ state of the at solutions for Object Detection, Object Tracking, and Pose Estimation. Fine-tuned different\n",
            "object detection models and integrated them into the pose estimation pipelines for increased performance for field datasets\n",
            "Media Center of Art and History at Columbia University\n",
            "New York, NY\n",
            "Graduate Research Assistant\n",
            "Mar 2020 - Dec 2020\n",
            "● Engineered way to automate process of slide analysis for collection of slides, deploying image processing and ML/DL\n",
            "techniques to detect originality of photographic images in 35mm slides collection\n",
            "● Formulated pipeline to replicate entire manual process by initially filtering images based on citation used in slides, followed\n",
            "by identifying presence of Halftone patterns (Precision: 95%, Recall:82%)\n",
            "Unilever\n",
            "Englewood Cliffs, NJ\n",
            "Data Science Analyst\n",
            "Mar 2020 - Dec 2020\n",
            "● Developed and deployed an application to streamline the feature extraction and data engineering process for Process\n",
            "Analytics Engine\n",
            "● Supported development of Process Analytics Engine to get the insights interactively using the data collected from\n",
            "production unit\n",
            "1\n",
            "Swiss Reinsurance America Corporation\n",
            "Armonk, NY\n",
            "Data Scientist Intern\n",
            "May 2020 - Aug 2020\n",
            "● Designed and developed Smart Underwriting Framework to generate scores for each submission based on propensity to\n",
            "bind; Prioritizing processing for submissions based on scores improved Cumulative Gains by 20%\n",
            "● Analyzed Drift in Data using KL Divergence and Logistic Regression-based models, constructed technique to retrain\n",
            "model dynamically in production setting to ensure Domain Adaptability\n",
            "compressing\n",
            "● Designed low latency compressed models with minimal accuracy drop for formulated models for multiple datasets\n",
            "Hybrid approach combining Content and Model-based Techniques for Recommendation\n",
            "Sep 2019 - Dec 2019\n",
            "● Created Restaurant Recommendation System based on Yelp dataset (2019) (6,685,900 reviews, 192,609 businesses, 200,000\n",
            "pictures, ten metropolitan areas, over 1.2 million business attributes: hours, parking, availability, and ambiance)\n",
            "● Developed Recommendation System utilizing various techniques: Alternating Least Square based Matrix Factorization,\n",
            "Factorization Machines, Content-based Recommendation capturing information from Images/Text-based reviews\n",
            "2\n",
            "● Accelerated performance of Recommendation Engine by engineering way to combine results from various approaches to\n",
            "cultivate strengths of each model and get more generalized recommendations\n",
            "Optimal Location Prediction for Emergency Stations\n",
            "Jul 2018 - Jan 2019\n",
            "● Identified and engineered various influencing parameters namely location attributes, population density, traffic, navigation,\n",
            "frequency of ambulance calls, and weather conditions\n",
            "● Formulated various ML/DL Models to identify best suitable for Travel Time Estimation between different locations of city;\n",
            "Travel Time estimated from XGBoost is used to drive K-Medoids for predicting optimal locations\n",
            "● Conceptualized approach demonstrated promising test results - Decreased turnaround time along with reduced utility of\n",
            "resources; for Staten Island: average time reduced by 6 seconds utilizing 14 Fire Stations in comparison to 19 actual ones\n",
            "End-to-End Sentence Level Lipreading\n",
            "Jan 2018 - Apr 2018\n",
            "● Designed model for performing end-to-end sentence level lip-reading, rather than approaches of detecting individual words\n",
            "by simultaneously recognizing spatiotemporal visual features and sequence model; Improved performance by approximately\n",
            "10% over the LSTM Baseline\n",
            "● Structured method to process frames (captured at 25 fps from GRID Corpus) leveraging combination of CNN and\n",
            "Bidirectional Gated Recurrent Units (Bi-GRUs) to enhance performance of end-to-end sentence formation\n",
            "-----------------\n",
            "Achievements   :\n",
            "document summarizing 89 research papers involving DL-based approaches for Electronic Health Records\n",
            "Samsung R&D Institute\n",
            "Noida, India\n",
            "Research Intern\n",
            "Jan 2019 - May 2019\n",
            "● Researched various On-Device AI solutions as part of AI core team and contributed to enhancing quality of services\n",
            "provided by Samsung for its mobile devices; Produced ML/DL models by utilizing Scikit-learn, TensorFlow, TF-Lite\n",
            "frameworks\n",
            "● Devised techniques for Facial Anti-Spoofing System leveraging various ML/DL methods in Python and deployed it as an\n",
            "Android Application\n",
            "● Analyzed different On-Device AI solutions for health and multimedia services on low-end Samsung smartphones with\n",
            "1GB of RAM to ensure robustness of solutions\n",
            "PUBLICATIONS\n",
            "Journal Publications:\n",
            "[1] Param Popat, Prasham Sheth, and Swati Jain. \"Animal/Object Identification Using Deep Learning on Raspberry Pi.\" In\n",
            "Information and Communication Technology for Intelligent Systems: Proceedings of ICTIS 2018, Volume 1, pp. 319-327.\n",
            "Springer Singapore, 2019.\n",
            "[2] Prasham Sheth, Priyank Thakkar, and Praxal Patel. \"Optimal Location Prediction for Emergency Stations Using Machine\n",
            "Learning.\" International Journal of Operational Research. 2022.\n",
            "[3] Prasham Sheth, Sai Shravani Sistla, Indranil Roychoudhury, Mengdi Gao, Crispin Chatar, Jose Celaya, and Priya Mishra.\n",
            "\"Real-Time Gamma Ray Log Generation from Drilling Parameters of Offset Wells Using Physics-Informed Machine\n",
            "Learning.\" SPE Journal (2023): 1-11.\n",
            "Conference Publications:\n",
            "[1] Prasham Sheth, Indranil Roychoudhury, Crispin Chatar, and José Celaya. \"A Hybrid Physics-Based and Machine-Learning\n",
            "Approach for Stick/Slip Prediction.\" In IADC/SPE International Drilling Conference and Exhibition. OnePetro, 2022.\n",
            "[2] Prasham Sheth, Sai Shravani Sistla, Indranil Roychoudhury, Mengdi Gao, Crispin Chatar, Jose Celaya, and Priya Mishra.\n",
            "\"Real-Time Digital Log Generation from Drilling Parameters of Offset Wells Using Physics Informed Machine Learning.\"\n",
            "In SPE/IADC International Drilling Conference and Exhibition. OnePetro, 2023.\n",
            "ACADEMIC PROJECTS\n",
            "Energy Efficient AI on Edge Devices (Master Thesis Project)\n",
            "Sep 2020 - Dec 2020\n",
            "● Developed techniques for compressing Deep Learning Models for faster inference on edge devices and reduced carbon\n",
            "footprint in association with GE Research\n",
            "-----------------\n",
            "Skills   :\n",
            "● Programming Languages: Python, SQL, R, Java, C++, C\n",
            "● Tools and Technologies: Scikit-Learn, NumPy, Pandas, Statsmodels, PyTorch, OpenCV, Scipy, Google BigQuery, Oracle\n",
            "DS, MongoDB, Google Cloud Platform, GitHub, LaTeX\n",
            "3\n",
            "\n",
            "-----------------\n",
            "CPU times: user 31.6 ms, sys: 2.95 ms, total: 34.5 ms\n",
            "Wall time: 98.4 ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<timed exec>:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "import os\n",
        "resume_content=''\n",
        "for filename in os.listdir(\"/content/drive/MyDrive/hackathon/resume-data\"):\n",
        "\n",
        "    resume_content, sections = parse_resume('/content/drive/MyDrive/hackathon/Resume Validation Set/easy_resume_level1_a.pdf')\n",
        "    df=df.append(sections,ignore_index=True)\n",
        "    print(\"Resume Sections:\")\n",
        "    for section, content in sections.items():\n",
        "      print(section.capitalize() + \"   :\")\n",
        "\n",
        "      print('\\n'.join(content))\n",
        "\n",
        "      print(\"-----------------\")\n",
        "    break\n",
        "    print(\"******************************************************************\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Define a function to concatenate skill and experience for each row\n",
        "def concatenate_skills_experience(row):\n",
        "    # Convert the list of skills to a string\n",
        "    skills_str = ', '.join(row['skills']) if isinstance(row['skills'], list) else str(row['skills'])\n",
        "    # Convert the element in the 'experience' column to a string\n",
        "    experience_str = ', '.join(row['experience']) if isinstance(row['experience'], list) else str(row['experience'])\n",
        "    return skills_str + ', ' + experience_str\n",
        "\n",
        "# Create a new DataFrame 'x' with the 'skills' and 'experience' columns\n",
        "x = df[['skills', 'experience']].copy()\n",
        "\n",
        "# Apply the concatenate_skills_experience function to each row and assign the result to column 'y'\n",
        "x['y'] = x.apply(concatenate_skills_experience, axis=1)\n",
        "\n",
        "# Drop the original 'skills' and 'experience' columns\n",
        "x.drop(['skills', 'experience'], axis=1, inplace=True)\n",
        "\n",
        "x\n"
      ],
      "metadata": {
        "id": "Ooxw8NRrVZ6E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "b772ec83-b072-418d-a39d-80929a119227"
      },
      "execution_count": 278,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 5.28 ms, sys: 0 ns, total: 5.28 ms\n",
            "Wall time: 5.25 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   y\n",
              "0  ● Programming Languages: Python, SQL, R, Java,..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7499c534-eb48-4ad9-a11b-ebfe3f9db244\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>● Programming Languages: Python, SQL, R, Java,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7499c534-eb48-4ad9-a11b-ebfe3f9db244')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7499c534-eb48-4ad9-a11b-ebfe3f9db244 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7499c534-eb48-4ad9-a11b-ebfe3f9db244');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_1f00c707-c472-4142-a189-d5d2d4dd9a77\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('x')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_1f00c707-c472-4142-a189-d5d2d4dd9a77 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('x');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "x",
              "summary": "{\n  \"name\": \"x\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"y\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\\u25cf Programming Languages: Python, SQL, R, Java, C++, C, \\u25cf Tools and Technologies: Scikit-Learn, NumPy, Pandas, Statsmodels, PyTorch, OpenCV, Scipy, Google BigQuery, Oracle, DS, MongoDB, Google Cloud Platform, GitHub, LaTeX, 3, , SLB Software Technology Innovation Center (STIC), Menlo Park, CA, Data Scientist, Feb 2021 - Present, Physics-Informed Machine Learning and Time Series Analysis, \\u25cf Developed Physics Informed Machine Learning based Hybrid Framework to create an advisory system that identifies the, regions with risky Stick/Slip conditions and outputs an optimal operating window for drilling the future stands, \\u25cf Devised Hybrid framework using Physics Informed Machine Learning for digitally generating LWD logs (Gamma-Ray, logs) in real-time to increase efficiency and robustness of log collection process, \\u25cf Working towards implementation of Physics Inspired Machine Learning based toolbox for Time Series data, Computer Vision, \\u25cf Researched and implemented various Computer Vision based use cases to improve Health Safety and Environment, \\u25cf Evaluated 5+ state of the at solutions for Object Detection, Object Tracking, and Pose Estimation. Fine-tuned different, object detection models and integrated them into the pose estimation pipelines for increased performance for field datasets, Media Center of Art and History at Columbia University, New York, NY, Graduate Research Assistant, Mar 2020 - Dec 2020, \\u25cf Engineered way to automate process of slide analysis for collection of slides, deploying image processing and ML/DL, techniques to detect originality of photographic images in 35mm slides collection, \\u25cf Formulated pipeline to replicate entire manual process by initially filtering images based on citation used in slides, followed, by identifying presence of Halftone patterns (Precision: 95%, Recall:82%), Unilever, Englewood Cliffs, NJ, Data Science Analyst, Mar 2020 - Dec 2020, \\u25cf Developed and deployed an application to streamline the feature extraction and data engineering process for Process, Analytics Engine, \\u25cf Supported development of Process Analytics Engine to get the insights interactively using the data collected from, production unit, 1, Swiss Reinsurance America Corporation, Armonk, NY, Data Scientist Intern, May 2020 - Aug 2020, \\u25cf Designed and developed Smart Underwriting Framework to generate scores for each submission based on propensity to, bind; Prioritizing processing for submissions based on scores improved Cumulative Gains by 20%, \\u25cf Analyzed Drift in Data using KL Divergence and Logistic Regression-based models, constructed technique to retrain, model dynamically in production setting to ensure Domain Adaptability, compressing, \\u25cf Designed low latency compressed models with minimal accuracy drop for formulated models for multiple datasets, Hybrid approach combining Content and Model-based Techniques for Recommendation, Sep 2019 - Dec 2019, \\u25cf Created Restaurant Recommendation System based on Yelp dataset (2019) (6,685,900 reviews, 192,609 businesses, 200,000, pictures, ten metropolitan areas, over 1.2 million business attributes: hours, parking, availability, and ambiance), \\u25cf Developed Recommendation System utilizing various techniques: Alternating Least Square based Matrix Factorization,, Factorization Machines, Content-based Recommendation capturing information from Images/Text-based reviews, 2, \\u25cf Accelerated performance of Recommendation Engine by engineering way to combine results from various approaches to, cultivate strengths of each model and get more generalized recommendations, Optimal Location Prediction for Emergency Stations, Jul 2018 - Jan 2019, \\u25cf Identified and engineered various influencing parameters namely location attributes, population density, traffic, navigation,, frequency of ambulance calls, and weather conditions, \\u25cf Formulated various ML/DL Models to identify best suitable for Travel Time Estimation between different locations of city;, Travel Time estimated from XGBoost is used to drive K-Medoids for predicting optimal locations, \\u25cf Conceptualized approach demonstrated promising test results - Decreased turnaround time along with reduced utility of, resources; for Staten Island: average time reduced by 6 seconds utilizing 14 Fire Stations in comparison to 19 actual ones, End-to-End Sentence Level Lipreading, Jan 2018 - Apr 2018, \\u25cf Designed model for performing end-to-end sentence level lip-reading, rather than approaches of detecting individual words, by simultaneously recognizing spatiotemporal visual features and sequence model; Improved performance by approximately, 10% over the LSTM Baseline, \\u25cf Structured method to process frames (captured at 25 fps from GRID Corpus) leveraging combination of CNN and, Bidirectional Gated Recurrent Units (Bi-GRUs) to enhance performance of end-to-end sentence formation\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 278
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract Noun Phrases"
      ],
      "metadata": {
        "id": "uml-aZ-Ky5VD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "import spacy\n",
        "import pandas as pd\n",
        "\n",
        "# Load the English language model in SpaCy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Function to extract noun phrases from text using SpaCy\n",
        "def extract_noun_phrases(text):\n",
        "    doc = nlp(text)\n",
        "    noun_phrases = [chunk.text for chunk in doc.noun_chunks]\n",
        "    return noun_phrases\n",
        "\n",
        "# Load the DataFrame 'x' created in the previous code\n",
        "# Replace 'x.csv' with the actual file path if saving/loading from a file\n",
        "\n",
        "\n",
        "# Extract noun phrases from the 'y' column of DataFrame 'x'\n",
        "noun_phrases = []\n",
        "for text in x['y']:\n",
        "    noun_phrases.extend(extract_noun_phrases(text))\n",
        "\n",
        "noun_phrases"
      ],
      "metadata": {
        "id": "R4TagTo9gQEv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a318b14b-8601-41ff-db01-e39cbded7647"
      },
      "execution_count": 279,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 879 ms, sys: 14.9 ms, total: 894 ms\n",
            "Wall time: 896 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['● Programming Languages',\n",
              " 'Python',\n",
              " 'SQL',\n",
              " 'R',\n",
              " 'Java',\n",
              " 'C++',\n",
              " 'C',\n",
              " 'Tools',\n",
              " 'Technologies',\n",
              " 'Scikit-Learn',\n",
              " 'NumPy',\n",
              " 'Pandas',\n",
              " 'Statsmodels',\n",
              " 'PyTorch',\n",
              " 'OpenCV',\n",
              " 'Scipy',\n",
              " 'Google BigQuery',\n",
              " 'Oracle',\n",
              " 'DS',\n",
              " 'MongoDB',\n",
              " 'Google Cloud Platform',\n",
              " 'GitHub',\n",
              " 'LaTeX',\n",
              " 'SLB Software Technology Innovation Center',\n",
              " 'STIC',\n",
              " 'Menlo Park',\n",
              " 'CA',\n",
              " 'Data Scientist',\n",
              " 'Feb 2021 - Present',\n",
              " 'Physics-Informed Machine Learning',\n",
              " 'Time Series Analysis',\n",
              " 'Developed Physics Informed Machine Learning',\n",
              " 'Hybrid Framework',\n",
              " 'an advisory system',\n",
              " 'that',\n",
              " 'the, regions',\n",
              " 'risky Stick/Slip conditions',\n",
              " 'outputs',\n",
              " 'an optimal operating window',\n",
              " 'the future stands',\n",
              " 'Devised Hybrid framework',\n",
              " 'Physics Informed Machine Learning',\n",
              " 'digitally generating LWD logs',\n",
              " 'Gamma-Ray',\n",
              " 'logs',\n",
              " 'real-time',\n",
              " 'efficiency',\n",
              " 'robustness',\n",
              " 'log collection process',\n",
              " 'implementation',\n",
              " 'Physics Inspired Machine Learning based toolbox',\n",
              " 'Time Series data',\n",
              " 'Computer Vision',\n",
              " 'various Computer Vision based use cases',\n",
              " 'Health Safety',\n",
              " 'Environment',\n",
              " 'state',\n",
              " 'the',\n",
              " 'solutions',\n",
              " 'Object Detection',\n",
              " 'Object Tracking',\n",
              " 'Pose Estimation',\n",
              " 'detection models',\n",
              " 'them',\n",
              " 'the pose estimation pipelines',\n",
              " 'increased performance',\n",
              " 'field datasets',\n",
              " 'Media Center',\n",
              " 'Art',\n",
              " 'History',\n",
              " 'Columbia University',\n",
              " 'automate process',\n",
              " 'slide analysis',\n",
              " 'collection',\n",
              " 'slides',\n",
              " 'image processing',\n",
              " 'ML/DL',\n",
              " 'originality',\n",
              " 'photographic images',\n",
              " '35mm slides collection',\n",
              " 'Formulated pipeline',\n",
              " 'entire manual process',\n",
              " 'initially filtering images',\n",
              " 'citation',\n",
              " 'slides',\n",
              " 'presence',\n",
              " 'Halftone patterns',\n",
              " '(Precision',\n",
              " '95%',\n",
              " 'Recall:82%',\n",
              " 'Unilever',\n",
              " 'Englewood Cliffs',\n",
              " 'NJ',\n",
              " 'Data Science Analyst',\n",
              " 'Mar',\n",
              " 'an application',\n",
              " 'the feature extraction and data engineering process',\n",
              " 'Process',\n",
              " 'Analytics Engine',\n",
              " 'Process Analytics Engine',\n",
              " 'the insights',\n",
              " 'the data',\n",
              " 'production unit',\n",
              " 'Swiss Reinsurance America Corporation',\n",
              " 'Armonk',\n",
              " 'NY',\n",
              " 'Data Scientist Intern',\n",
              " 'May 2020 - Aug',\n",
              " 'Smart Underwriting Framework',\n",
              " 'scores',\n",
              " 'each submission',\n",
              " 'propensity',\n",
              " 'Prioritizing processing',\n",
              " 'submissions',\n",
              " 'scores',\n",
              " 'Cumulative Gains',\n",
              " '20%',\n",
              " 'Analyzed Drift',\n",
              " 'Data',\n",
              " 'KL Divergence',\n",
              " 'Logistic Regression-based models',\n",
              " 'technique',\n",
              " 'retrain',\n",
              " 'Domain Adaptability',\n",
              " 'compressing',\n",
              " 'low latency compressed models',\n",
              " 'minimal accuracy drop',\n",
              " 'formulated models',\n",
              " 'multiple datasets',\n",
              " 'Content',\n",
              " 'Model-based Techniques',\n",
              " 'Recommendation',\n",
              " 'Sep 2019 - Dec 2019, ● Created Restaurant Recommendation System',\n",
              " 'Yelp',\n",
              " '200,000, pictures',\n",
              " 'ten metropolitan areas',\n",
              " 'over 1.2 million business attributes',\n",
              " 'hours',\n",
              " 'parking',\n",
              " 'availability',\n",
              " 'ambiance',\n",
              " 'various techniques',\n",
              " 'Least Square based Matrix Factorization',\n",
              " 'Factorization Machines',\n",
              " 'Content-based Recommendation capturing information',\n",
              " 'Images/Text-based reviews',\n",
              " 'Accelerated performance',\n",
              " 'Recommendation Engine',\n",
              " 'engineering way',\n",
              " 'results',\n",
              " 'various approaches',\n",
              " 'strengths',\n",
              " 'each model',\n",
              " 'more generalized recommendations',\n",
              " 'Optimal Location Prediction',\n",
              " 'Emergency Stations',\n",
              " 'various influencing parameters',\n",
              " 'namely location attributes',\n",
              " 'population density',\n",
              " 'traffic',\n",
              " 'navigation',\n",
              " 'frequency',\n",
              " 'ambulance calls',\n",
              " 'weather conditions',\n",
              " 'various ML/DL Models',\n",
              " 'Travel Time Estimation',\n",
              " 'different locations',\n",
              " 'city',\n",
              " 'Travel Time',\n",
              " 'XGBoost',\n",
              " 'K-Medoids',\n",
              " 'optimal locations',\n",
              " 'Conceptualized approach',\n",
              " 'test results',\n",
              " 'reduced utility',\n",
              " 'resources',\n",
              " 'Staten Island',\n",
              " '6 seconds',\n",
              " '14 Fire Stations',\n",
              " 'comparison',\n",
              " '19 actual ones',\n",
              " 'End',\n",
              " 'Jan',\n",
              " '● Designed model',\n",
              " 'end',\n",
              " 'approaches',\n",
              " 'individual words',\n",
              " 'spatiotemporal visual features',\n",
              " 'sequence model',\n",
              " 'Improved performance',\n",
              " '10%',\n",
              " 'the LSTM Baseline',\n",
              " 'Structured method',\n",
              " 'frames',\n",
              " '25 fps',\n",
              " 'GRID Corpus',\n",
              " 'leveraging combination',\n",
              " 'CNN',\n",
              " 'Bidirectional Gated Recurrent Units',\n",
              " '(Bi-GRUs',\n",
              " 'performance',\n",
              " 'end']"
            ]
          },
          "metadata": {},
          "execution_count": 279
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "import pandas as pd\n",
        "df1 = pd.read_csv(r'/content/drive/MyDrive/hackathon/noun_phrases_1.csv')\n",
        "df2 = pd.read_csv(r'/content/drive/MyDrive/hackathon/noun_phrases_2.csv')\n",
        "\n",
        "\n",
        "# Append df2 to df1\n",
        "merged_df = df1.append(df2)\n",
        "merged_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "i1wq0qPEhrB8",
        "outputId": "a451f585-1e76-4e1c-b0b4-80dc261d407c"
      },
      "execution_count": 280,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 7.2 ms, sys: 1.94 ms, total: 9.14 ms\n",
            "Wall time: 16.1 ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<timed exec>:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     noun_phrase  skills/non_skills\n",
              "0     management decision-making             skills\n",
              "1                       Power bi             skills\n",
              "2                        Tableau             skills\n",
              "3            visualization tools             skills\n",
              "4                      Snowflake             skills\n",
              "...                          ...                ...\n",
              "1494                    database         non_skills\n",
              "1495            direct marketing         non_skills\n",
              "1496      the firm’s top clients         non_skills\n",
              "1497                      nature         non_skills\n",
              "1498             spending habits         non_skills\n",
              "\n",
              "[2498 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ee6fe8dd-4ffd-4da7-99bf-b8c03740785d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>noun_phrase</th>\n",
              "      <th>skills/non_skills</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>management decision-making</td>\n",
              "      <td>skills</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Power bi</td>\n",
              "      <td>skills</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Tableau</td>\n",
              "      <td>skills</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>visualization tools</td>\n",
              "      <td>skills</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Snowflake</td>\n",
              "      <td>skills</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1494</th>\n",
              "      <td>database</td>\n",
              "      <td>non_skills</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1495</th>\n",
              "      <td>direct marketing</td>\n",
              "      <td>non_skills</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1496</th>\n",
              "      <td>the firm’s top clients</td>\n",
              "      <td>non_skills</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1497</th>\n",
              "      <td>nature</td>\n",
              "      <td>non_skills</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1498</th>\n",
              "      <td>spending habits</td>\n",
              "      <td>non_skills</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2498 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ee6fe8dd-4ffd-4da7-99bf-b8c03740785d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ee6fe8dd-4ffd-4da7-99bf-b8c03740785d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ee6fe8dd-4ffd-4da7-99bf-b8c03740785d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b23eb0f9-8af7-4ad9-bb41-05ad5cf6c39a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b23eb0f9-8af7-4ad9-bb41-05ad5cf6c39a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b23eb0f9-8af7-4ad9-bb41-05ad5cf6c39a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_28574f60-1888-400e-a4d8-01b0fb4bf8d2\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('merged_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_28574f60-1888-400e-a4d8-01b0fb4bf8d2 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('merged_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "merged_df",
              "summary": "{\n  \"name\": \"merged_df\",\n  \"rows\": 2498,\n  \"fields\": [\n    {\n      \"column\": \"noun_phrase\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1869,\n        \"samples\": [\n          \"Housing Price Projection\",\n          \"decreases\",\n          \"OpenCV\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \" skills/non_skills\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"non_skills\",\n          \"skills\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 280
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "merged_df = merged_df.sample(frac=1, random_state=42)\n",
        "merged_df.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "24EWcFFvPjrD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c53112f4-2108-4c0a-9624-9ec4bcd51380"
      },
      "execution_count": 281,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2.72 ms, sys: 0 ns, total: 2.72 ms\n",
            "Wall time: 2.94 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "merged_df['noun_phrase']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnEXhxvZTyn-",
        "outputId": "cb34e5f4-294b-498f-ca67-de8cb6a97b02"
      },
      "execution_count": 282,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 177 µs, sys: 8 µs, total: 185 µs\n",
            "Wall time: 194 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                           portfolio\n",
              "1                                 Key\n",
              "2                   various locations\n",
              "3                                   ●\n",
              "4                    Google Workspace\n",
              "                    ...              \n",
              "2493                              Apr\n",
              "2494                          MongoDB\n",
              "2495                      A/B Testing\n",
              "2496    Hybrid Neural Network Library\n",
              "2497        the subject matter expert\n",
              "Name: noun_phrase, Length: 2498, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 282
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Skill Extraction"
      ],
      "metadata": {
        "id": "rnQ9G-j20dwG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "mapping = {'skills': 1, 'non_skills': 0}\n",
        "\n",
        "merged_df[' skills/non_skills'] = merged_df[' skills/non_skills'].map(mapping)\n"
      ],
      "metadata": {
        "id": "zDwNgLhtXokl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45ca0394-c1f9-49a8-c278-f2456fa426a3"
      },
      "execution_count": 283,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2.53 ms, sys: 0 ns, total: 2.53 ms\n",
            "Wall time: 2.61 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "merged_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "yQemaqYDYpiL",
        "outputId": "d5828e50-144e-496d-a686-0cf5227b4b52"
      },
      "execution_count": 284,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 6 µs, sys: 0 ns, total: 6 µs\n",
            "Wall time: 10.5 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        noun_phrase   skills/non_skills\n",
              "0                         portfolio                   0\n",
              "1                               Key                   0\n",
              "2                 various locations                   0\n",
              "3                                 ●                   0\n",
              "4                  Google Workspace                   1\n",
              "...                             ...                 ...\n",
              "2493                            Apr                   0\n",
              "2494                        MongoDB                   1\n",
              "2495                    A/B Testing                   1\n",
              "2496  Hybrid Neural Network Library                   1\n",
              "2497      the subject matter expert                   0\n",
              "\n",
              "[2498 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3fd2281d-f441-4b87-bf78-6af553dc971f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>noun_phrase</th>\n",
              "      <th>skills/non_skills</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>portfolio</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Key</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>various locations</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>●</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Google Workspace</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2493</th>\n",
              "      <td>Apr</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2494</th>\n",
              "      <td>MongoDB</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2495</th>\n",
              "      <td>A/B Testing</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2496</th>\n",
              "      <td>Hybrid Neural Network Library</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2497</th>\n",
              "      <td>the subject matter expert</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2498 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3fd2281d-f441-4b87-bf78-6af553dc971f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3fd2281d-f441-4b87-bf78-6af553dc971f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3fd2281d-f441-4b87-bf78-6af553dc971f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f79dafca-352a-454c-a1c6-91448d2badae\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f79dafca-352a-454c-a1c6-91448d2badae')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f79dafca-352a-454c-a1c6-91448d2badae button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_1db7454b-377d-4175-8147-e53ba7b02f1f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('merged_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_1db7454b-377d-4175-8147-e53ba7b02f1f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('merged_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "merged_df",
              "summary": "{\n  \"name\": \"merged_df\",\n  \"rows\": 2498,\n  \"fields\": [\n    {\n      \"column\": \"noun_phrase\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1869,\n        \"samples\": [\n          \"k-Means\",\n          \"different initializers\",\n          \"insights\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \" skills/non_skills\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 284
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "merged_df['noun_phrase'] = merged_df['noun_phrase'].astype(str)"
      ],
      "metadata": {
        "id": "YuOLyrHDU6Wd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ebd28cc-e8fe-4ddc-dcdb-f47e19158ed4"
      },
      "execution_count": 285,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 924 µs, sys: 0 ns, total: 924 µs\n",
            "Wall time: 935 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training for skill extraction"
      ],
      "metadata": {
        "id": "ydaOBPE-1JhC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.layers import SpatialDropout1D, LSTM, Conv1D, GlobalMaxPooling1D, Dense, Embedding\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten\n",
        "# Tokenize the noun phrases\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(merged_df['noun_phrase'])\n",
        "X_sequences = tokenizer.texts_to_sequences(merged_df['noun_phrase'])\n",
        "print(X_sequences)\n",
        "# Pad sequences to ensure uniform length\n",
        "max_length = 100\n",
        "X_padded = pad_sequences(X_sequences, maxlen=max_length, padding='post')\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_padded, merged_df[' skills/non_skills'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the model\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=100, input_length=max_length),\n",
        "    Conv1D(filters=128, kernel_size=5, activation='relu'),\n",
        "    GlobalMaxPooling1D(),\n",
        "    # Flatten(),\n",
        "    Dense(units=10, activation='relu'),\n",
        "    Dense(units=1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print model summary\n",
        "print(model.summary())\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=30, batch_size=32)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss}, Test Accuracy: {accuracy}')\n"
      ],
      "metadata": {
        "id": "7U-eKbp7ZtGB"
      },
      "execution_count": 286,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "model.save('/content/drive/MyDrive/hackathon/model.h5')\n",
        "import tensorflow as tf\n",
        "\n",
        "# model = tf.keras.models.load_model('/content/drive/MyDrive/hackathon/model.h5')\n"
      ],
      "metadata": {
        "id": "_jACUIiMaDoK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96d61057-cf0e-453a-8825-cd3a678ef209"
      },
      "execution_count": 287,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 151 ms, sys: 7.15 ms, total: 159 ms\n",
            "Wall time: 990 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Skill Extraction"
      ],
      "metadata": {
        "id": "nW0eCEN92R17"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "text='\\n'.join(df['skills'][0])\n",
        "# text+=df['experience'][0]\n",
        "text+='\\n'.join(df['experience'][0])\n",
        "text"
      ],
      "metadata": {
        "id": "-insKt4DgEC-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "outputId": "b2a4cddd-2e2e-472a-e765-67fd983146e9"
      },
      "execution_count": 288,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 429 µs, sys: 0 ns, total: 429 µs\n",
            "Wall time: 440 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'● Programming Languages: Python, SQL, R, Java, C++, C\\n● Tools and Technologies: Scikit-Learn, NumPy, Pandas, Statsmodels, PyTorch, OpenCV, Scipy, Google BigQuery, Oracle\\nDS, MongoDB, Google Cloud Platform, GitHub, LaTeX\\n3\\nSLB Software Technology Innovation Center (STIC)\\nMenlo Park, CA\\nData Scientist\\nFeb 2021 - Present\\nPhysics-Informed Machine Learning and Time Series Analysis\\n● Developed Physics Informed Machine Learning based Hybrid Framework to create an advisory system that identifies the\\nregions with risky Stick/Slip conditions and outputs an optimal operating window for drilling the future stands\\n● Devised Hybrid framework using Physics Informed Machine Learning for digitally generating LWD logs (Gamma-Ray\\nlogs) in real-time to increase efficiency and robustness of log collection process\\n● Working towards implementation of Physics Inspired Machine Learning based toolbox for Time Series data\\nComputer Vision\\n● Researched and implemented various Computer Vision based use cases to improve Health Safety and Environment\\n● Evaluated 5+ state of the at solutions for Object Detection, Object Tracking, and Pose Estimation. Fine-tuned different\\nobject detection models and integrated them into the pose estimation pipelines for increased performance for field datasets\\nMedia Center of Art and History at Columbia University\\nNew York, NY\\nGraduate Research Assistant\\nMar 2020 - Dec 2020\\n● Engineered way to automate process of slide analysis for collection of slides, deploying image processing and ML/DL\\ntechniques to detect originality of photographic images in 35mm slides collection\\n● Formulated pipeline to replicate entire manual process by initially filtering images based on citation used in slides, followed\\nby identifying presence of Halftone patterns (Precision: 95%, Recall:82%)\\nUnilever\\nEnglewood Cliffs, NJ\\nData Science Analyst\\nMar 2020 - Dec 2020\\n● Developed and deployed an application to streamline the feature extraction and data engineering process for Process\\nAnalytics Engine\\n● Supported development of Process Analytics Engine to get the insights interactively using the data collected from\\nproduction unit\\n1\\nSwiss Reinsurance America Corporation\\nArmonk, NY\\nData Scientist Intern\\nMay 2020 - Aug 2020\\n● Designed and developed Smart Underwriting Framework to generate scores for each submission based on propensity to\\nbind; Prioritizing processing for submissions based on scores improved Cumulative Gains by 20%\\n● Analyzed Drift in Data using KL Divergence and Logistic Regression-based models, constructed technique to retrain\\nmodel dynamically in production setting to ensure Domain Adaptability\\ncompressing\\n● Designed low latency compressed models with minimal accuracy drop for formulated models for multiple datasets\\nHybrid approach combining Content and Model-based Techniques for Recommendation\\nSep 2019 - Dec 2019\\n● Created Restaurant Recommendation System based on Yelp dataset (2019) (6,685,900 reviews, 192,609 businesses, 200,000\\npictures, ten metropolitan areas, over 1.2 million business attributes: hours, parking, availability, and ambiance)\\n● Developed Recommendation System utilizing various techniques: Alternating Least Square based Matrix Factorization,\\nFactorization Machines, Content-based Recommendation capturing information from Images/Text-based reviews\\n2\\n● Accelerated performance of Recommendation Engine by engineering way to combine results from various approaches to\\ncultivate strengths of each model and get more generalized recommendations\\nOptimal Location Prediction for Emergency Stations\\nJul 2018 - Jan 2019\\n● Identified and engineered various influencing parameters namely location attributes, population density, traffic, navigation,\\nfrequency of ambulance calls, and weather conditions\\n● Formulated various ML/DL Models to identify best suitable for Travel Time Estimation between different locations of city;\\nTravel Time estimated from XGBoost is used to drive K-Medoids for predicting optimal locations\\n● Conceptualized approach demonstrated promising test results - Decreased turnaround time along with reduced utility of\\nresources; for Staten Island: average time reduced by 6 seconds utilizing 14 Fire Stations in comparison to 19 actual ones\\nEnd-to-End Sentence Level Lipreading\\nJan 2018 - Apr 2018\\n● Designed model for performing end-to-end sentence level lip-reading, rather than approaches of detecting individual words\\nby simultaneously recognizing spatiotemporal visual features and sequence model; Improved performance by approximately\\n10% over the LSTM Baseline\\n● Structured method to process frames (captured at 25 fps from GRID Corpus) leveraging combination of CNN and\\nBidirectional Gated Recurrent Units (Bi-GRUs) to enhance performance of end-to-end sentence formation'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 288
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "def extract_skills(text):\n",
        "    noun_phrases = extract_noun_phrases(text)\n",
        "    noun_phrases = np.array(noun_phrases).astype(str)\n",
        "\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(noun_phrases)\n",
        "    X_sequences = tokenizer.texts_to_sequences(noun_phrases)\n",
        "\n",
        "    # Pad sequences to ensure uniform length\n",
        "    max_length = 100\n",
        "    X_padded = pad_sequences(X_sequences, maxlen=max_length, padding='post')\n",
        "\n",
        "    # Reshape input data to add embedding dimension\n",
        "    X_padded = np.expand_dims(X_padded, axis=-1)  # Add embedding dimension\n",
        "\n",
        "    predictions = model.predict(X_padded)\n",
        "\n",
        "    # Filter predicted skills based on the threshold\n",
        "    threshold = 0.5  # Adjust as needed\n",
        "    predicted_skills = [noun_phrases[i] for i, pred in enumerate(predictions) if pred > threshold]\n",
        "\n",
        "    return predicted_skills\n"
      ],
      "metadata": {
        "id": "jlWyxP7PZPiH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "282f30f6-b41f-4e2d-dbd4-044cd7db8ce8"
      },
      "execution_count": 289,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 9 µs, sys: 0 ns, total: 9 µs\n",
            "Wall time: 14.5 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "extracted_skills = extract_skills(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSYAYf_jbxT3",
        "outputId": "1da22162-2adc-4394-f462-94d8bd72a700"
      },
      "execution_count": 290,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 9ms/step\n",
            "CPU times: user 394 ms, sys: 3.86 ms, total: 398 ms\n",
            "Wall time: 377 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "print(f'Extracted Skills: {extracted_skills}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLJMCenR2czv",
        "outputId": "fed39338-7613-4bfc-b281-56e6e9b8cebf"
      },
      "execution_count": 291,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Skills: ['● Programming Languages', 'R', 'Scikit-Learn', 'Pandas', 'OpenCV', 'Scipy', 'MongoDB', 'Google Cloud Platform', 'GitHub', '3\\nSLB Software Technology Innovation Center', 'STIC', 'Menlo Park', 'CA\\nData Scientist\\nFeb', 'Present\\nPhysics-Informed Machine Learning and Time Series Analysis\\n● Developed Physics Informed Machine Learning', 'Hybrid Framework', 'an advisory system', 'the\\nregions', 'risky Stick/Slip conditions', '● Devised Hybrid framework', 'Physics Informed Machine Learning', 'Gamma-Ray\\nlogs', 'log collection process', 'Physics Inspired Machine Learning based toolbox', 'Time Series data\\nComputer Vision', 'various Computer Vision based use cases', 'state', 'Object Detection', 'Object Tracking', 'Pose Estimation', 'Fine-tuned different\\nobject detection models', 'the pose estimation pipelines', 'increased performance', 'field datasets\\nMedia Center', 'Graduate Research', 'automate process', 'slide analysis', 'collection', 'slides', 'image processing', 'ML/DL\\ntechniques', 'photographic images', '35mm slides collection\\n● Formulated pipeline', 'entire manual process', 'citation', 'slides', '(Precision', '95%', 'NJ\\nData Science Analyst\\nMar', '- Dec', 'the feature extraction and data engineering process', 'Process\\nAnalytics Engine\\n● Supported development', 'Process Analytics Engine', '1\\nSwiss Reinsurance America Corporation\\nArmonk', 'Smart Underwriting Framework', 'Prioritizing processing', 'submissions', 'Logistic Regression-based models', 'technique', 'Domain Adaptability', 'minimal accuracy drop', 'formulated models', 'Model-based Techniques', 'Recommendation\\nSep 2019 - Dec 2019\\n● Created Restaurant Recommendation System', 'Yelp', '(6,685,900 reviews', '192,609 businesses', '200,000\\npictures', 'hours, parking, availability, and ambiance)\\n● Developed Recommendation System', 'Content-based Recommendation capturing information', 'Images/Text-based reviews', 'various approaches', 'each model', 'Emergency Stations', 'navigation', 'weather conditions', 'various ML/DL Models', 'Travel Time Estimation', 'different locations', 'Travel Time', 'XGBoost', 'Staten Island', '14 Fire Stations', 'approaches', 'individual words', 'spatiotemporal visual features', 'approximately\\n10%', 'the LSTM Baseline\\n● Structured method', 'GRID Corpus', 'performance']\n",
            "CPU times: user 183 µs, sys: 8 µs, total: 191 µs\n",
            "Wall time: 180 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "final_skills = '\\n'.join(extracted_skills)"
      ],
      "metadata": {
        "id": "FXmembUXECJK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24a9cd67-6024-4524-ea85-0dddcfdf2aee"
      },
      "execution_count": 292,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 24 µs, sys: 1 µs, total: 25 µs\n",
            "Wall time: 30 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Abstractive Skill Extraction"
      ],
      "metadata": {
        "id": "4nEb4nPL2GSP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "nlp_model = spacy.load('/content/drive/MyDrive/hackathon/skills_model')\n",
        "# text=df['skills']\n",
        "doc = nlp_model(final_skills)\n",
        "abstractive_skills=''\n",
        "for ent in doc.ents:\n",
        "  abstractive_skills+=ent.text\n",
        "  print(f'{ent.label_.upper()}->\\n {ent.text}')"
      ],
      "metadata": {
        "id": "1c-ZwDBjbK62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19636b95-171d-4c17-e42b-9fb143f31f73"
      },
      "execution_count": 293,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 795 ms, sys: 27 ms, total: 822 ms\n",
            "Wall time: 948 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1-F_DVyERQp",
        "outputId": "940cd93a-f02f-4660-cfe0-0a804d08b69d"
      },
      "execution_count": 294,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "● Programming Languages\n",
              "R\n",
              "Scikit-Learn\n",
              "Pandas\n",
              "OpenCV\n",
              "Scipy\n",
              "MongoDB\n",
              "Google Cloud Platform\n",
              "GitHub\n",
              "3\n",
              "SLB Software Technology Innovation Center\n",
              "STIC\n",
              "Menlo Park\n",
              "CA\n",
              "Data Scientist\n",
              "Feb\n",
              "Present\n",
              "Physics-Informed Machine Learning and Time Series Analysis\n",
              "● Developed Physics Informed Machine Learning\n",
              "Hybrid Framework\n",
              "an advisory system\n",
              "the\n",
              "regions\n",
              "risky Stick/Slip conditions\n",
              "● Devised Hybrid framework\n",
              "Physics Informed Machine Learning\n",
              "Gamma-Ray\n",
              "logs\n",
              "log collection process\n",
              "Physics Inspired Machine Learning based toolbox\n",
              "Time Series data\n",
              "Computer Vision\n",
              "various Computer Vision based use cases\n",
              "state\n",
              "Object Detection\n",
              "Object Tracking\n",
              "Pose Estimation\n",
              "Fine-tuned different\n",
              "object detection models\n",
              "the pose estimation pipelines\n",
              "increased performance\n",
              "field datasets\n",
              "Media Center\n",
              "Graduate Research\n",
              "automate process\n",
              "slide analysis\n",
              "collection\n",
              "slides\n",
              "image processing\n",
              "ML/DL\n",
              "techniques\n",
              "photographic images\n",
              "35mm slides collection\n",
              "● Formulated pipeline\n",
              "entire manual process\n",
              "citation\n",
              "slides\n",
              "(Precision\n",
              "95%\n",
              "NJ\n",
              "Data Science Analyst\n",
              "Mar\n",
              "- Dec\n",
              "the feature extraction and data engineering process\n",
              "Process\n",
              "Analytics Engine\n",
              "● Supported development\n",
              "Process Analytics Engine\n",
              "1\n",
              "Swiss Reinsurance America Corporation\n",
              "Armonk\n",
              "Smart Underwriting Framework\n",
              "Prioritizing processing\n",
              "submissions\n",
              "Logistic Regression-based models\n",
              "technique\n",
              "Domain Adaptability\n",
              "minimal accuracy drop\n",
              "formulated models\n",
              "Model-based Techniques\n",
              "Recommendation\n",
              "Sep 2019 - Dec 2019\n",
              "● Created Restaurant Recommendation System\n",
              "Yelp\n",
              "(6,685,900 reviews\n",
              "192,609 businesses\n",
              "200,000\n",
              "pictures\n",
              "hours, parking, availability, and ambiance)\n",
              "● Developed Recommendation System\n",
              "Content-based Recommendation capturing information\n",
              "Images/Text-based reviews\n",
              "various approaches\n",
              "each model\n",
              "Emergency Stations\n",
              "navigation\n",
              "weather conditions\n",
              "various ML/DL Models\n",
              "Travel Time Estimation\n",
              "different locations\n",
              "Travel Time\n",
              "XGBoost\n",
              "Staten Island\n",
              "14 Fire Stations\n",
              "approaches\n",
              "individual words\n",
              "spatiotemporal visual features\n",
              "approximately\n",
              "10%\n",
              "the LSTM Baseline\n",
              "● Structured method\n",
              "GRID Corpus\n",
              "performance"
            ]
          },
          "metadata": {},
          "execution_count": 294
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "final_designation = '\\n'.join(df['experience'][0])\n",
        "final_designation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "id": "OGfO2OeDEkqF",
        "outputId": "f9f6294f-b5e7-4350-ecd7-ec137e89eda8"
      },
      "execution_count": 295,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 139 µs, sys: 6 µs, total: 145 µs\n",
            "Wall time: 149 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'SLB Software Technology Innovation Center (STIC)\\nMenlo Park, CA\\nData Scientist\\nFeb 2021 - Present\\nPhysics-Informed Machine Learning and Time Series Analysis\\n● Developed Physics Informed Machine Learning based Hybrid Framework to create an advisory system that identifies the\\nregions with risky Stick/Slip conditions and outputs an optimal operating window for drilling the future stands\\n● Devised Hybrid framework using Physics Informed Machine Learning for digitally generating LWD logs (Gamma-Ray\\nlogs) in real-time to increase efficiency and robustness of log collection process\\n● Working towards implementation of Physics Inspired Machine Learning based toolbox for Time Series data\\nComputer Vision\\n● Researched and implemented various Computer Vision based use cases to improve Health Safety and Environment\\n● Evaluated 5+ state of the at solutions for Object Detection, Object Tracking, and Pose Estimation. Fine-tuned different\\nobject detection models and integrated them into the pose estimation pipelines for increased performance for field datasets\\nMedia Center of Art and History at Columbia University\\nNew York, NY\\nGraduate Research Assistant\\nMar 2020 - Dec 2020\\n● Engineered way to automate process of slide analysis for collection of slides, deploying image processing and ML/DL\\ntechniques to detect originality of photographic images in 35mm slides collection\\n● Formulated pipeline to replicate entire manual process by initially filtering images based on citation used in slides, followed\\nby identifying presence of Halftone patterns (Precision: 95%, Recall:82%)\\nUnilever\\nEnglewood Cliffs, NJ\\nData Science Analyst\\nMar 2020 - Dec 2020\\n● Developed and deployed an application to streamline the feature extraction and data engineering process for Process\\nAnalytics Engine\\n● Supported development of Process Analytics Engine to get the insights interactively using the data collected from\\nproduction unit\\n1\\nSwiss Reinsurance America Corporation\\nArmonk, NY\\nData Scientist Intern\\nMay 2020 - Aug 2020\\n● Designed and developed Smart Underwriting Framework to generate scores for each submission based on propensity to\\nbind; Prioritizing processing for submissions based on scores improved Cumulative Gains by 20%\\n● Analyzed Drift in Data using KL Divergence and Logistic Regression-based models, constructed technique to retrain\\nmodel dynamically in production setting to ensure Domain Adaptability\\ncompressing\\n● Designed low latency compressed models with minimal accuracy drop for formulated models for multiple datasets\\nHybrid approach combining Content and Model-based Techniques for Recommendation\\nSep 2019 - Dec 2019\\n● Created Restaurant Recommendation System based on Yelp dataset (2019) (6,685,900 reviews, 192,609 businesses, 200,000\\npictures, ten metropolitan areas, over 1.2 million business attributes: hours, parking, availability, and ambiance)\\n● Developed Recommendation System utilizing various techniques: Alternating Least Square based Matrix Factorization,\\nFactorization Machines, Content-based Recommendation capturing information from Images/Text-based reviews\\n2\\n● Accelerated performance of Recommendation Engine by engineering way to combine results from various approaches to\\ncultivate strengths of each model and get more generalized recommendations\\nOptimal Location Prediction for Emergency Stations\\nJul 2018 - Jan 2019\\n● Identified and engineered various influencing parameters namely location attributes, population density, traffic, navigation,\\nfrequency of ambulance calls, and weather conditions\\n● Formulated various ML/DL Models to identify best suitable for Travel Time Estimation between different locations of city;\\nTravel Time estimated from XGBoost is used to drive K-Medoids for predicting optimal locations\\n● Conceptualized approach demonstrated promising test results - Decreased turnaround time along with reduced utility of\\nresources; for Staten Island: average time reduced by 6 seconds utilizing 14 Fire Stations in comparison to 19 actual ones\\nEnd-to-End Sentence Level Lipreading\\nJan 2018 - Apr 2018\\n● Designed model for performing end-to-end sentence level lip-reading, rather than approaches of detecting individual words\\nby simultaneously recognizing spatiotemporal visual features and sequence model; Improved performance by approximately\\n10% over the LSTM Baseline\\n● Structured method to process frames (captured at 25 fps from GRID Corpus) leveraging combination of CNN and\\nBidirectional Gated Recurrent Units (Bi-GRUs) to enhance performance of end-to-end sentence formation'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 295
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Find Job titles in resume"
      ],
      "metadata": {
        "id": "cGiV7ecr3nnr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "store_designations = []\n",
        "\n",
        "nlp_model_d = spacy.load('/content/drive/MyDrive/hackathon/designation_model')\n",
        "doc = nlp_model_d(final_designation)\n",
        "for ent in doc.ents:\n",
        "    store_designations.append(ent.text)\n",
        "    print(f'{ent.label_.upper():{30}}- {ent.text}')"
      ],
      "metadata": {
        "id": "AYao5cOaEbsi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db244933-c160-47f2-df34-0939872f8712"
      },
      "execution_count": 296,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DESIGNATION                   - Data Scientist\n",
            "DESIGNATION                   - Graduate Research Assistant\n",
            "DESIGNATION                   - Data Science Analyst\n",
            "DESIGNATION                   - Data Scientist Intern\n",
            "CPU times: user 1.03 s, sys: 37.1 ms, total: 1.07 s\n",
            "Wall time: 1.19 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "store_designations"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srYTUZYdKrWy",
        "outputId": "527439fa-c1f2-4da7-99ab-849867b0e717"
      },
      "execution_count": 297,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
            "Wall time: 8.34 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Data Scientist',\n",
              " 'Graduate Research Assistant',\n",
              " 'Data Science Analyst',\n",
              " 'Data Scientist Intern']"
            ]
          },
          "metadata": {},
          "execution_count": 297
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# O-Net mapping for Standardised Job Title"
      ],
      "metadata": {
        "id": "IzEwrK9P4Trv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Get the file path\n",
        "file_path = '/content/drive/MyDrive/hackathon/data.csv'\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "df_ = pd.read_csv(file_path)\n",
        "\n",
        "# Get the desired column as a list\n",
        "labels = df_['Title'].tolist()\n",
        "codes = df_['O*NET Code'].tolist()\n",
        "res = dict(zip(labels, codes))"
      ],
      "metadata": {
        "id": "YbmyxMD4ly-w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4a2041c-5d9b-43e6-a0af-a730c144f896"
      },
      "execution_count": 298,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 7.91 ms, sys: 0 ns, total: 7.91 ms\n",
            "Wall time: 11.8 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "model2 = SentenceTransformer('all-MiniLM-L6-v2')"
      ],
      "metadata": {
        "id": "81glzBJKnxEN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ce74a1c-87c5-4e3c-ce85-36bb1f194aae"
      },
      "execution_count": 299,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 174 ms, sys: 13.9 ms, total: 188 ms\n",
            "Wall time: 1.06 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "standard_job_titles = labels\n",
        "standard_embeddings = model2.encode(standard_job_titles)"
      ],
      "metadata": {
        "id": "U7fdtblPn8Wa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa5fee82-7b9c-4205-ea43-188e44c5d176"
      },
      "execution_count": 300,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 6.86 s, sys: 45.3 ms, total: 6.9 s\n",
            "Wall time: 8.66 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "extracted_job_titles = store_designations\n",
        "extracted_embeddings = model2.encode(extracted_job_titles)"
      ],
      "metadata": {
        "id": "-OsGj7XYoDfH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f38fbfbb-1139-4a76-a56d-2d992ffcfdaf"
      },
      "execution_count": 301,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 43 ms, sys: 0 ns, total: 43 ms\n",
            "Wall time: 43.3 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Function to find the most similar standard job title for each extracted job title\n",
        "def find_most_similar_jobs(extracted_embeddings, standard_embeddings, standard_job_titles):\n",
        "    for extracted_embedding in extracted_embeddings:\n",
        "        similarities = util.cos_sim(extracted_embedding, standard_embeddings)\n",
        "        max_index = np.argmax(similarities)\n",
        "\n",
        "        yield standard_job_titles[max_index]"
      ],
      "metadata": {
        "id": "ZgkzYLJDoEtP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aecd50b7-beb3-4eaa-822b-2599d9030991"
      },
      "execution_count": 302,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 7 µs, sys: 0 ns, total: 7 µs\n",
            "Wall time: 11.7 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Mapping each extracted job title to the most similar standard job title\n",
        "mapped_job_titles = list(find_most_similar_jobs(extracted_embeddings, standard_embeddings, standard_job_titles))\n",
        "for extracted, mapped in zip(store_designations, mapped_job_titles):\n",
        "    print(f'Extracted: {extracted} -> Mapped: {mapped}')"
      ],
      "metadata": {
        "id": "-TUNWo_roNJX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d139569-9a1f-4a94-aa97-c36e6600665b"
      },
      "execution_count": 303,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted: Data Scientist -> Mapped: Data Scientists\n",
            "Extracted: Graduate Research Assistant -> Mapped: Social Science Research Assistants\n",
            "Extracted: Data Science Analyst -> Mapped: Data Scientists\n",
            "Extracted: Data Scientist Intern -> Mapped: Data Scientists\n",
            "CPU times: user 11.2 ms, sys: 7 µs, total: 11.2 ms\n",
            "Wall time: 16.1 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting Education"
      ],
      "metadata": {
        "id": "7tCwSRIH449I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %%time\n",
        "# if not df['education'].empty:\n",
        "#     # Drop NaN values and convert elements to strings\n",
        "#     df['education'] = df['education'].dropna().astype(str)\n",
        "#     final_education = '\\n'.join(df['education'])\n",
        "#     print(final_education)\n"
      ],
      "metadata": {
        "id": "Zbh21VwLd3RE"
      },
      "execution_count": 304,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting Timeline"
      ],
      "metadata": {
        "id": "S4fYMR8-5SoE"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L7-zxSDcKeW0"
      },
      "execution_count": 304,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MS_YL1kVlP4l"
      },
      "execution_count": 304,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mapping description and extracting skills for each job title"
      ],
      "metadata": {
        "id": "SqGdU2EMbJcV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "s=df['experience'][0]\n",
        "s=' '.join(s)\n",
        "l=[0]\n",
        "for i in store_designations:\n",
        "  l+=[s.index(i)]\n",
        "l+=[len(s)]\n",
        "l\n",
        "se=[]\n",
        "for i in range(1,len(l)-1):\n",
        "  se+=[s[l[i]:l[i+1]]]\n",
        "sk=[]\n",
        "for d in se:\n",
        "  sk+=[extract_skills(d)]\n",
        "sk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MI3eQLg9aMo5",
        "outputId": "9f90ff6f-aaf5-4351-d310-79b7e10b70bc"
      },
      "execution_count": 305,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 11ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 130ms/step\n",
            "3/3 [==============================] - 0s 19ms/step\n",
            "CPU times: user 823 ms, sys: 14.6 ms, total: 838 ms\n",
            "Wall time: 1.29 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Hybrid Framework',\n",
              "  'an advisory system',\n",
              "  'that',\n",
              "  'risky Stick/Slip conditions',\n",
              "  'an optimal operating window',\n",
              "  'Physics Informed Machine Learning',\n",
              "  'digitally generating LWD logs',\n",
              "  'Gamma-Ray logs',\n",
              "  'real-time',\n",
              "  'efficiency',\n",
              "  'robustness',\n",
              "  'log collection process',\n",
              "  'Physics Inspired Machine Learning based toolbox',\n",
              "  'Time Series data Computer Vision',\n",
              "  'various Computer Vision based use cases',\n",
              "  'Health Safety',\n",
              "  '+ state',\n",
              "  'Object Detection',\n",
              "  'Fine-tuned different object detection models',\n",
              "  'increased performance',\n",
              "  'field datasets Media Center',\n",
              "  'Art',\n",
              "  'History'],\n",
              " ['Graduate Research Assistant Mar',\n",
              "  '● Engineered way',\n",
              "  'slide analysis',\n",
              "  'slides',\n",
              "  'ML/DL techniques',\n",
              "  'photographic images',\n",
              "  '35mm',\n",
              "  'collection ● Formulated pipeline',\n",
              "  'entire manual process',\n",
              "  'slides',\n",
              "  '95%',\n",
              "  'Recall:82%',\n",
              "  'Unilever Englewood Cliffs'],\n",
              " ['an application',\n",
              "  'the feature extraction and data engineering process',\n",
              "  'Process Analytics Engine ● Supported development',\n",
              "  'production unit',\n",
              "  '1 Swiss Reinsurance America Corporation Armonk'],\n",
              " ['- Aug',\n",
              "  'Smart Underwriting Framework',\n",
              "  'scores',\n",
              "  'each submission',\n",
              "  'scores',\n",
              "  'Cumulative Gains',\n",
              "  '20% ● Analyzed Drift',\n",
              "  'Data',\n",
              "  'KL Divergence',\n",
              "  'Logistic Regression-based models',\n",
              "  'retrain model',\n",
              "  'Domain Adaptability compressing ● Designed low latency',\n",
              "  'minimal accuracy drop',\n",
              "  'formulated models',\n",
              "  'Content',\n",
              "  'Model-based Techniques',\n",
              "  '● Created Restaurant Recommendation System',\n",
              "  '200,000 pictures',\n",
              "  'ten metropolitan areas',\n",
              "  'ambiance',\n",
              "  'Matrix Factorization',\n",
              "  'Factorization Machines',\n",
              "  'Content-based Recommendation capturing information',\n",
              "  'Images/Text-based reviews',\n",
              "  'engineering way',\n",
              "  'various approaches',\n",
              "  'strengths',\n",
              "  'each model',\n",
              "  'more generalized recommendations',\n",
              "  'Optimal Location Prediction',\n",
              "  'Emergency Stations',\n",
              "  'population density',\n",
              "  'traffic',\n",
              "  'frequency',\n",
              "  'ambulance calls',\n",
              "  'weather conditions',\n",
              "  'various ML/DL Models',\n",
              "  'Travel Time Estimation',\n",
              "  'Travel Time',\n",
              "  'XGBoost',\n",
              "  'resources',\n",
              "  '14 Fire Stations',\n",
              "  'comparison',\n",
              "  'End',\n",
              "  'end',\n",
              "  'approaches',\n",
              "  'the LSTM Baseline ● Structured method',\n",
              "  'leveraging combination',\n",
              "  'Bidirectional Gated Recurrent Units',\n",
              "  '(Bi-GRUs',\n",
              "  'end']]"
            ]
          },
          "metadata": {},
          "execution_count": 305
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "skill_preds=[]\n",
        "for skill in sk:\n",
        "  temp='\\n'.join(skill)\n",
        "  doc=nlp_model(temp)\n",
        "  temp_skills=''\n",
        "  for ent in doc.ents:\n",
        "   temp_skills+=ent.text\n",
        "  skill_preds.append(temp_skills)"
      ],
      "metadata": {
        "id": "3GqeSgCjbsxA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb39b221-ced0-40a3-f63c-fa653c015115"
      },
      "execution_count": 306,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 161 ms, sys: 1.85 ms, total: 162 ms\n",
            "Wall time: 265 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resume Summary"
      ],
      "metadata": {
        "id": "fMLOC5XlB_mp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "id": "14zk6dbMFU0n",
        "outputId": "c83cc7a9-821c-4b57-9bab-81c99ee994d5"
      },
      "execution_count": 307,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              skills  \\\n",
              "0  [● Programming Languages: Python, SQL, R, Java...   \n",
              "\n",
              "                                          experience  \\\n",
              "0  [SLB Software Technology Innovation Center (ST...   \n",
              "\n",
              "                                           education miscellaneous  \\\n",
              "0  [Columbia University, New York, NY, Master of ...           NaN   \n",
              "\n",
              "                                        achievements  \n",
              "0  [document summarizing 89 research papers invol...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a9df1563-40d4-47e6-9ec9-968a13ed0847\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>skills</th>\n",
              "      <th>experience</th>\n",
              "      <th>education</th>\n",
              "      <th>miscellaneous</th>\n",
              "      <th>achievements</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[● Programming Languages: Python, SQL, R, Java...</td>\n",
              "      <td>[SLB Software Technology Innovation Center (ST...</td>\n",
              "      <td>[Columbia University, New York, NY, Master of ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[document summarizing 89 research papers invol...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a9df1563-40d4-47e6-9ec9-968a13ed0847')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a9df1563-40d4-47e6-9ec9-968a13ed0847 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a9df1563-40d4-47e6-9ec9-968a13ed0847');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_52b58c6f-bbf7-4733-918d-824ca6367518\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_52b58c6f-bbf7-4733-918d-824ca6367518 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "repr_error": "'str' object has no attribute 'empty'"
            }
          },
          "metadata": {},
          "execution_count": 307
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "raw_exp='\\n'.join(df.iloc[0]['experience'])\n",
        "raw_exp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "id": "urHdETlLKGfx",
        "outputId": "fd4468d4-91ce-44a0-ba0e-3d532b0a7180"
      },
      "execution_count": 308,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 528 µs, sys: 0 ns, total: 528 µs\n",
            "Wall time: 10 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'SLB Software Technology Innovation Center (STIC)\\nMenlo Park, CA\\nData Scientist\\nFeb 2021 - Present\\nPhysics-Informed Machine Learning and Time Series Analysis\\n● Developed Physics Informed Machine Learning based Hybrid Framework to create an advisory system that identifies the\\nregions with risky Stick/Slip conditions and outputs an optimal operating window for drilling the future stands\\n● Devised Hybrid framework using Physics Informed Machine Learning for digitally generating LWD logs (Gamma-Ray\\nlogs) in real-time to increase efficiency and robustness of log collection process\\n● Working towards implementation of Physics Inspired Machine Learning based toolbox for Time Series data\\nComputer Vision\\n● Researched and implemented various Computer Vision based use cases to improve Health Safety and Environment\\n● Evaluated 5+ state of the at solutions for Object Detection, Object Tracking, and Pose Estimation. Fine-tuned different\\nobject detection models and integrated them into the pose estimation pipelines for increased performance for field datasets\\nMedia Center of Art and History at Columbia University\\nNew York, NY\\nGraduate Research Assistant\\nMar 2020 - Dec 2020\\n● Engineered way to automate process of slide analysis for collection of slides, deploying image processing and ML/DL\\ntechniques to detect originality of photographic images in 35mm slides collection\\n● Formulated pipeline to replicate entire manual process by initially filtering images based on citation used in slides, followed\\nby identifying presence of Halftone patterns (Precision: 95%, Recall:82%)\\nUnilever\\nEnglewood Cliffs, NJ\\nData Science Analyst\\nMar 2020 - Dec 2020\\n● Developed and deployed an application to streamline the feature extraction and data engineering process for Process\\nAnalytics Engine\\n● Supported development of Process Analytics Engine to get the insights interactively using the data collected from\\nproduction unit\\n1\\nSwiss Reinsurance America Corporation\\nArmonk, NY\\nData Scientist Intern\\nMay 2020 - Aug 2020\\n● Designed and developed Smart Underwriting Framework to generate scores for each submission based on propensity to\\nbind; Prioritizing processing for submissions based on scores improved Cumulative Gains by 20%\\n● Analyzed Drift in Data using KL Divergence and Logistic Regression-based models, constructed technique to retrain\\nmodel dynamically in production setting to ensure Domain Adaptability\\ncompressing\\n● Designed low latency compressed models with minimal accuracy drop for formulated models for multiple datasets\\nHybrid approach combining Content and Model-based Techniques for Recommendation\\nSep 2019 - Dec 2019\\n● Created Restaurant Recommendation System based on Yelp dataset (2019) (6,685,900 reviews, 192,609 businesses, 200,000\\npictures, ten metropolitan areas, over 1.2 million business attributes: hours, parking, availability, and ambiance)\\n● Developed Recommendation System utilizing various techniques: Alternating Least Square based Matrix Factorization,\\nFactorization Machines, Content-based Recommendation capturing information from Images/Text-based reviews\\n2\\n● Accelerated performance of Recommendation Engine by engineering way to combine results from various approaches to\\ncultivate strengths of each model and get more generalized recommendations\\nOptimal Location Prediction for Emergency Stations\\nJul 2018 - Jan 2019\\n● Identified and engineered various influencing parameters namely location attributes, population density, traffic, navigation,\\nfrequency of ambulance calls, and weather conditions\\n● Formulated various ML/DL Models to identify best suitable for Travel Time Estimation between different locations of city;\\nTravel Time estimated from XGBoost is used to drive K-Medoids for predicting optimal locations\\n● Conceptualized approach demonstrated promising test results - Decreased turnaround time along with reduced utility of\\nresources; for Staten Island: average time reduced by 6 seconds utilizing 14 Fire Stations in comparison to 19 actual ones\\nEnd-to-End Sentence Level Lipreading\\nJan 2018 - Apr 2018\\n● Designed model for performing end-to-end sentence level lip-reading, rather than approaches of detecting individual words\\nby simultaneously recognizing spatiotemporal visual features and sequence model; Improved performance by approximately\\n10% over the LSTM Baseline\\n● Structured method to process frames (captured at 25 fps from GRID Corpus) leveraging combination of CNN and\\nBidirectional Gated Recurrent Units (Bi-GRUs) to enhance performance of end-to-end sentence formation'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 308
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Replacing Job Titles with Standard O*Net Job Titles"
      ],
      "metadata": {
        "id": "iC79vCY_VIAz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "def replace_strings(work_experience, original_strings, replacement_strings):\n",
        "    \"\"\"\n",
        "    Replace occurrences of strings in 'original_strings' with corresponding strings in 'replacement_strings' in the 'work_experience' text.\n",
        "\n",
        "    Parameters:\n",
        "    - work_experience (str): The text containing the work experience.\n",
        "    - original_strings (list of str): Strings to be replaced.\n",
        "    - replacement_strings (list of str): Strings to replace with.\n",
        "\n",
        "    Returns:\n",
        "    - str: Updated work experience text.\n",
        "    \"\"\"\n",
        "    for original, replacement in zip(original_strings, replacement_strings):\n",
        "        work_experience = work_experience.replace(original, replacement)\n",
        "    return work_experience"
      ],
      "metadata": {
        "id": "BdSnKFYvRCMh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d8d4735-0d83-4c61-b1c6-c12d18ea5af9"
      },
      "execution_count": 309,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 7 µs, sys: 0 ns, total: 7 µs\n",
            "Wall time: 12.4 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "final_exp = replace_strings(raw_exp, store_designations, mapped_job_titles)"
      ],
      "metadata": {
        "id": "Vc0-ZAUCRIdE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "207ccef2-4267-4a6f-f9df-a1cdc55bec81"
      },
      "execution_count": 310,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 98 µs, sys: 0 ns, total: 98 µs\n",
            "Wall time: 2 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "63coTdUuVQnj"
      },
      "execution_count": 310,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "if len(store_designations) > 0 and len(mapped_job_titles) > 0:\n",
        "    for designation, standard_designation in zip(store_designations, mapped_job_titles):\n",
        "        if designation in raw_exp:\n",
        "            raw_exp = raw_exp.replace(designation, standard_designation)\n"
      ],
      "metadata": {
        "id": "jaEES2J3MHlG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd642d52-017b-4077-a2c4-0979f34367b0"
      },
      "execution_count": 311,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 154 µs, sys: 0 ns, total: 154 µs\n",
            "Wall time: 4 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from transformers import pipeline\n",
        "\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")"
      ],
      "metadata": {
        "id": "3yAsPUedRq4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "944d565b-d752-4b16-be1b-130a6df60b8b"
      },
      "execution_count": 312,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2.61 s, sys: 232 ms, total: 2.84 s\n",
            "Wall time: 4.83 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "import re\n",
        "\n",
        "def time_line():\n",
        "  date_pattern = r'\\b(?:\\d{2}/\\d{4}|\\d{2}/\\d{2}|\\d{2}-\\d{2}-\\d{2}|\\d{2}-\\d{2}-\\d{4})\\b'\n",
        "\n",
        "\n",
        "  #for designation\n",
        "  date_with_designation = []\n",
        "  for designations in store_designations:\n",
        "    index = final_designation.index(designations)\n",
        "    temp_str = final_designation[index : ]\n",
        "\n",
        "    dates = re.findall(date_pattern, temp_str)\n",
        "    if(len(dates) > 0):\n",
        "      date_with_designation.append(dates[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  return date_with_designation\n",
        "\n",
        "des_date = time_line()\n",
        "\n",
        "from dateutil.parser import parse\n",
        "\n",
        "# print(mapped_titles)\n",
        "# print(des_date)\n",
        "\n",
        "\n",
        "time = dict(zip(des_date, store_designations))\n",
        "dates = [parse(date_str) for date_str in des_date]\n",
        "sorted_dates_with_titles = sorted(zip(dates, store_designations))\n",
        "sorted_dates = [date.strftime('%Y-%m-%d') for date, _ in sorted_dates_with_titles]\n",
        "sorted_titles = [title for _, title in sorted_dates_with_titles]\n",
        "sorted_time = dict(zip(sorted_dates, sorted_titles))\n",
        "\n",
        "# print(sorted_time)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8Ci1-jZl96b",
        "outputId": "d5f2f5e6-4a68-4e3d-c656-bf2fa9b84e77"
      },
      "execution_count": 313,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.59 ms, sys: 0 ns, total: 1.59 ms\n",
            "Wall time: 1.6 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('----------------------------')\n",
        "print('RESUME DETAILS')\n",
        "print('----------------------------')\n",
        "print('----------------------------')\n",
        "print('EDUCATION')\n",
        "print('----------------------------')\n",
        "education = df.iloc[0]['education']\n",
        "if isinstance(education, float):\n",
        "    # Handle the case where education is NaN or a float\n",
        "    education_list = ['']\n",
        "else:\n",
        "    education_list = list(education)\n",
        "print('\\n'.join(education_list))\n",
        "print('----------------------------')\n",
        "print('----------------------------')\n",
        "print('EXPERIENCE')\n",
        "print('----------------------------')\n",
        "print('DESIGNATIONS AS PER O*NET DATABASE:')\n",
        "print('----------------------------')\n",
        "# print('\\n'.join(mapped_job_titles))\n",
        "for jtitle, desc, skill_pred in zip(mapped_job_titles, se, skill_preds):\n",
        "    print('***TITLE***')\n",
        "    print(f'{jtitle} --> {res[jtitle]}')\n",
        "    print('***DESCRIPTION***')\n",
        "    print(desc)\n",
        "    print('***PREDICTED SKILLS***')\n",
        "    print(skill_pred)\n",
        "    print('\\n')\n",
        "\n",
        "print('----------------------------')\n",
        "# print('\\n'.join(df.iloc[0]['experience']))\n",
        "# print(final_exp.strip())\n",
        "print('----------------------------')\n",
        "print('ABSTRACTIVE SKILLS')\n",
        "print('----------------------------')\n",
        "print(abstractive_skills)\n",
        "print('----------------------------')\n",
        "print('----------------------------')\n",
        "print('SKILLS')\n",
        "print('----------------------------')\n",
        "print('\\n'.join(list(df.iloc[0]['skills'])))\n",
        "print('----------------------------')\n",
        "print('----------------------------')\n",
        "print('ACHIEVEMENTS')\n",
        "print('----------------------------')\n",
        "achievements = df.iloc[0]['achievements']\n",
        "if isinstance(achievements, float):\n",
        "    # Handle the case where achievements is NaN or a float\n",
        "    achievements_list = ['']\n",
        "else:\n",
        "    achievements_list = list(achievements)\n",
        "print('\\n'.join(achievements_list))\n",
        "print('----------------------------')\n",
        "print('----------------------------')\n",
        "print('CAREER TRAJECTORY')\n",
        "print('----------------------------')\n",
        "for key in sorted_time:\n",
        "    print(f'{key}--->{sorted_time[key]}')\n",
        "print('----------------------------')\n",
        "print('----------------------------')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuT8SEU1FVT4",
        "outputId": "da24c0fe-4fc0-47cb-a160-b1d0aca85835"
      },
      "execution_count": 314,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------\n",
            "RESUME DETAILS\n",
            "----------------------------\n",
            "----------------------------\n",
            "EDUCATION\n",
            "----------------------------\n",
            "Columbia University\n",
            "New York, NY\n",
            "Master of Science in Data Science, GPA: 4.08/4.00\n",
            "Dec 2020\n",
            "Coursework: Machine Learning, Applied Machine Learning, Applied Deep Learning, Statistical Inference & Modeling,\n",
            "Personalization Theory, Natural Language Processing, Algorithms for Data Science, Computer Systems, Exploratory Data\n",
            "Analysis and Visualization\n",
            "Nirma University\n",
            "Ahmedabad, India\n",
            "Bachelor of Technology in Computer Engineering, GPA: 9.50/10, Rank: 2/900\n",
            "May 2019\n",
            "Coursework: Machine Learning, Deep Learning, Artificial Intelligence, Linear Algebra, Algorithms\n",
            "----------------------------\n",
            "----------------------------\n",
            "EXPERIENCE\n",
            "----------------------------\n",
            "DESIGNATIONS AS PER O*NET DATABASE:\n",
            "----------------------------\n",
            "***TITLE***\n",
            "Data Scientists --> 15-2051.00\n",
            "***DESCRIPTION***\n",
            "Data Scientist Feb 2021 - Present Physics-Informed Machine Learning and Time Series Analysis ● Developed Physics Informed Machine Learning based Hybrid Framework to create an advisory system that identifies the regions with risky Stick/Slip conditions and outputs an optimal operating window for drilling the future stands ● Devised Hybrid framework using Physics Informed Machine Learning for digitally generating LWD logs (Gamma-Ray logs) in real-time to increase efficiency and robustness of log collection process ● Working towards implementation of Physics Inspired Machine Learning based toolbox for Time Series data Computer Vision ● Researched and implemented various Computer Vision based use cases to improve Health Safety and Environment ● Evaluated 5+ state of the at solutions for Object Detection, Object Tracking, and Pose Estimation. Fine-tuned different object detection models and integrated them into the pose estimation pipelines for increased performance for field datasets Media Center of Art and History at Columbia University New York, NY \n",
            "***PREDICTED SKILLS***\n",
            "\n",
            "\n",
            "\n",
            "***TITLE***\n",
            "Social Science Research Assistants --> 19-4061.00\n",
            "***DESCRIPTION***\n",
            "Graduate Research Assistant Mar 2020 - Dec 2020 ● Engineered way to automate process of slide analysis for collection of slides, deploying image processing and ML/DL techniques to detect originality of photographic images in 35mm slides collection ● Formulated pipeline to replicate entire manual process by initially filtering images based on citation used in slides, followed by identifying presence of Halftone patterns (Precision: 95%, Recall:82%) Unilever Englewood Cliffs, NJ \n",
            "***PREDICTED SKILLS***\n",
            "\n",
            "\n",
            "\n",
            "***TITLE***\n",
            "Data Scientists --> 15-2051.00\n",
            "***DESCRIPTION***\n",
            "Data Science Analyst Mar 2020 - Dec 2020 ● Developed and deployed an application to streamline the feature extraction and data engineering process for Process Analytics Engine ● Supported development of Process Analytics Engine to get the insights interactively using the data collected from production unit 1 Swiss Reinsurance America Corporation Armonk, NY \n",
            "***PREDICTED SKILLS***\n",
            "\n",
            "\n",
            "\n",
            "***TITLE***\n",
            "Data Scientists --> 15-2051.00\n",
            "***DESCRIPTION***\n",
            "Data Scientist Intern May 2020 - Aug 2020 ● Designed and developed Smart Underwriting Framework to generate scores for each submission based on propensity to bind; Prioritizing processing for submissions based on scores improved Cumulative Gains by 20% ● Analyzed Drift in Data using KL Divergence and Logistic Regression-based models, constructed technique to retrain model dynamically in production setting to ensure Domain Adaptability compressing ● Designed low latency compressed models with minimal accuracy drop for formulated models for multiple datasets Hybrid approach combining Content and Model-based Techniques for Recommendation Sep 2019 - Dec 2019 ● Created Restaurant Recommendation System based on Yelp dataset (2019) (6,685,900 reviews, 192,609 businesses, 200,000 pictures, ten metropolitan areas, over 1.2 million business attributes: hours, parking, availability, and ambiance) ● Developed Recommendation System utilizing various techniques: Alternating Least Square based Matrix Factorization, Factorization Machines, Content-based Recommendation capturing information from Images/Text-based reviews 2 ● Accelerated performance of Recommendation Engine by engineering way to combine results from various approaches to cultivate strengths of each model and get more generalized recommendations Optimal Location Prediction for Emergency Stations Jul 2018 - Jan 2019 ● Identified and engineered various influencing parameters namely location attributes, population density, traffic, navigation, frequency of ambulance calls, and weather conditions ● Formulated various ML/DL Models to identify best suitable for Travel Time Estimation between different locations of city; Travel Time estimated from XGBoost is used to drive K-Medoids for predicting optimal locations ● Conceptualized approach demonstrated promising test results - Decreased turnaround time along with reduced utility of resources; for Staten Island: average time reduced by 6 seconds utilizing 14 Fire Stations in comparison to 19 actual ones End-to-End Sentence Level Lipreading Jan 2018 - Apr 2018 ● Designed model for performing end-to-end sentence level lip-reading, rather than approaches of detecting individual words by simultaneously recognizing spatiotemporal visual features and sequence model; Improved performance by approximately 10% over the LSTM Baseline ● Structured method to process frames (captured at 25 fps from GRID Corpus) leveraging combination of CNN and Bidirectional Gated Recurrent Units (Bi-GRUs) to enhance performance of end-to-end sentence formation\n",
            "***PREDICTED SKILLS***\n",
            "\n",
            "\n",
            "\n",
            "----------------------------\n",
            "----------------------------\n",
            "ABSTRACTIVE SKILLS\n",
            "----------------------------\n",
            "\n",
            "----------------------------\n",
            "----------------------------\n",
            "SKILLS\n",
            "----------------------------\n",
            "● Programming Languages: Python, SQL, R, Java, C++, C\n",
            "● Tools and Technologies: Scikit-Learn, NumPy, Pandas, Statsmodels, PyTorch, OpenCV, Scipy, Google BigQuery, Oracle\n",
            "DS, MongoDB, Google Cloud Platform, GitHub, LaTeX\n",
            "3\n",
            "\n",
            "----------------------------\n",
            "----------------------------\n",
            "ACHIEVEMENTS\n",
            "----------------------------\n",
            "document summarizing 89 research papers involving DL-based approaches for Electronic Health Records\n",
            "Samsung R&D Institute\n",
            "Noida, India\n",
            "Research Intern\n",
            "Jan 2019 - May 2019\n",
            "● Researched various On-Device AI solutions as part of AI core team and contributed to enhancing quality of services\n",
            "provided by Samsung for its mobile devices; Produced ML/DL models by utilizing Scikit-learn, TensorFlow, TF-Lite\n",
            "frameworks\n",
            "● Devised techniques for Facial Anti-Spoofing System leveraging various ML/DL methods in Python and deployed it as an\n",
            "Android Application\n",
            "● Analyzed different On-Device AI solutions for health and multimedia services on low-end Samsung smartphones with\n",
            "1GB of RAM to ensure robustness of solutions\n",
            "PUBLICATIONS\n",
            "Journal Publications:\n",
            "[1] Param Popat, Prasham Sheth, and Swati Jain. \"Animal/Object Identification Using Deep Learning on Raspberry Pi.\" In\n",
            "Information and Communication Technology for Intelligent Systems: Proceedings of ICTIS 2018, Volume 1, pp. 319-327.\n",
            "Springer Singapore, 2019.\n",
            "[2] Prasham Sheth, Priyank Thakkar, and Praxal Patel. \"Optimal Location Prediction for Emergency Stations Using Machine\n",
            "Learning.\" International Journal of Operational Research. 2022.\n",
            "[3] Prasham Sheth, Sai Shravani Sistla, Indranil Roychoudhury, Mengdi Gao, Crispin Chatar, Jose Celaya, and Priya Mishra.\n",
            "\"Real-Time Gamma Ray Log Generation from Drilling Parameters of Offset Wells Using Physics-Informed Machine\n",
            "Learning.\" SPE Journal (2023): 1-11.\n",
            "Conference Publications:\n",
            "[1] Prasham Sheth, Indranil Roychoudhury, Crispin Chatar, and José Celaya. \"A Hybrid Physics-Based and Machine-Learning\n",
            "Approach for Stick/Slip Prediction.\" In IADC/SPE International Drilling Conference and Exhibition. OnePetro, 2022.\n",
            "[2] Prasham Sheth, Sai Shravani Sistla, Indranil Roychoudhury, Mengdi Gao, Crispin Chatar, Jose Celaya, and Priya Mishra.\n",
            "\"Real-Time Digital Log Generation from Drilling Parameters of Offset Wells Using Physics Informed Machine Learning.\"\n",
            "In SPE/IADC International Drilling Conference and Exhibition. OnePetro, 2023.\n",
            "ACADEMIC PROJECTS\n",
            "Energy Efficient AI on Edge Devices (Master Thesis Project)\n",
            "Sep 2020 - Dec 2020\n",
            "● Developed techniques for compressing Deep Learning Models for faster inference on edge devices and reduced carbon\n",
            "footprint in association with GE Research\n",
            "----------------------------\n",
            "----------------------------\n",
            "CAREER TRAJECTORY\n",
            "----------------------------\n",
            "----------------------------\n",
            "----------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9cW7GggDnU-2"
      },
      "execution_count": 314,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VKuGbrCvd5hh"
      },
      "execution_count": 314,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}