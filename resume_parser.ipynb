{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HuHemCcizBfG",
        "outputId": "a637de40-9759-451f-c4a3-6ba7a8e69cbe"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# machine specifications:\n",
        "import platform\n",
        "print(platform.machine())\n",
        "print(platform.version())\n",
        "print(platform.platform())\n",
        "print(platform.uname())\n",
        "print(platform.system())\n",
        "print(platform.processor())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7cYAorXEwIv",
        "outputId": "bff1485a-51d6-4511-ed0d-859e273b70cc"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x86_64\n",
            "#1 SMP PREEMPT_DYNAMIC Sat Nov 18 15:31:17 UTC 2023\n",
            "Linux-6.1.58+-x86_64-with-glibc2.35\n",
            "uname_result(system='Linux', node='2b13a760ca66', release='6.1.58+', version='#1 SMP PREEMPT_DYNAMIC Sat Nov 18 15:31:17 UTC 2023', machine='x86_64')\n",
            "Linux\n",
            "x86_64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "!pip install spacy\n",
        "!python -m spacy download en_core_web_sm\n",
        "!pip install PyMuPDF\n",
        "!pip install python-docx\n",
        "!pip install beautifulsoup4 lxml\n",
        "!pip install pytesseract\n",
        "!sudo apt-get install tesseract-ocr\n",
        "!pip install tensorflow\n",
        "!pip install sentence_transformers\n",
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oj-zR3pixH70",
        "outputId": "f0dbe606-91b5-482b-a4fa-7eabbb6be0a1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.6.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.25.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.6.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.25.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Collecting PyMuPDF\n",
            "  Downloading PyMuPDF-1.23.26-cp310-none-manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyMuPDFb==1.23.22 (from PyMuPDF)\n",
            "  Downloading PyMuPDFb-1.23.22-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (30.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.6/30.6 MB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDFb, PyMuPDF\n",
            "Successfully installed PyMuPDF-1.23.26 PyMuPDFb-1.23.22\n",
            "Collecting python-docx\n",
            "  Downloading python_docx-1.1.0-py3-none-any.whl (239 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.6/239.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.10.0)\n",
            "Installing collected packages: python-docx\n",
            "Successfully installed python-docx-1.1.0\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (4.9.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (23.2)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (9.4.0)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.10\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 4,816 kB of archives.\n",
            "After this operation, 15.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1.1 [1,591 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1.1 [2,990 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr amd64 4.1.1-2.1build1 [236 kB]\n",
            "Fetched 4,816 kB in 3s (1,837 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 121749 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "esNMRoYcSNvs"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "import json\n",
        "import re\n",
        "import fitz\n",
        "from docx import Document\n",
        "from bs4 import BeautifulSoup\n",
        "import pytesseract\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer, util"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "def doc2text(file_path):\n",
        "    if file_path.endswith('pdf'):\n",
        "        with fitz.open(file_path) as doc:\n",
        "            text = \"\"\n",
        "            for page in doc:\n",
        "                text += page.get_text()\n",
        "        return text\n",
        "\n",
        "    elif file_path.endswith('docx'):\n",
        "        document = Document(file_path)\n",
        "        text = []\n",
        "        for paragraph in document.paragraphs:\n",
        "            text.append(paragraph.text)\n",
        "        return '\\n'.join(text)\n",
        "\n",
        "    elif file_path.endswith('html'):\n",
        "        with open(file_path, 'r', encoding='utf-8') as file:\n",
        "            html_content = file.read()\n",
        "        soup = BeautifulSoup(html_content, 'lxml')\n",
        "        return soup.get_text(separator='\\n', strip=True)\n",
        "\n",
        "    elif file_path.endswith('jpg') or file_path.endswith('jpeg') or file_path.endswith('png'):\n",
        "      image = Image.open(file_path)\n",
        "      extracted_text = pytesseract.image_to_string(image)\n",
        "      return extracted_text"
      ],
      "metadata": {
        "id": "uuZHPDZ1aGLz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resume Parsing"
      ],
      "metadata": {
        "id": "n9x3RrDsy0Jh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "y6lAnbfESWBi"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "sec = [[#skills\n",
        "        'areas of experience',\n",
        "        'areas of expertise',\n",
        "        'areas of knowledge',\n",
        "        'skills',\n",
        "\n",
        "        \"other skills\",\n",
        "        \"other abilities\",\n",
        "        'career related skills',\n",
        "        'professional skills',\n",
        "        'specialized skills',\n",
        "        'technical skills',\n",
        "        'soft skills',\n",
        "        'computer skills',\n",
        "        'personal skills',\n",
        "        # 'computer knowledge',\n",
        "        # 'technologies',\n",
        "\n",
        "        'proficiencies',\n",
        "        'languages',\n",
        "        'language competencies and skills',\n",
        "        'programming languages',\n",
        "        'competencies'\n",
        "],\n",
        "      [#experience\n",
        "        'employment history',\n",
        "        'employment data',\n",
        "        'career summary',\n",
        "        'work history',\n",
        "       'technical experience',\n",
        "        'working history',\n",
        "        'work experience',\n",
        "        'experience',\n",
        "        'professional experience',\n",
        "        'professional background',\n",
        "        'professional employment',\n",
        "        'additional experience',\n",
        "        'career related experience',\n",
        "        \"professional employment history\",\n",
        "        'related experience',\n",
        "        'relevant experience',\n",
        "        'programming experience',\n",
        "        'freelance',\n",
        "        'freelance experience',\n",
        "        'internship experience',\n",
        "        'internships',\n",
        "        'apprenticeships',\n",
        "        'army experience',\n",
        "        'military experience',\n",
        "        'military background',\n",
        "               'special training',\n",
        "       'training'\n",
        "\n",
        "],\n",
        "[#education\n",
        "        'academic background',\n",
        "        'academic experience',\n",
        "\n",
        "        'courses',\n",
        "        'qualification',\n",
        "        'related courses',\n",
        "        'education',\n",
        "        'educational background',\n",
        "        'educational qualifications',\n",
        "        'educational training',\n",
        "        'education and training',\n",
        "        'academic training',\n",
        "        'Academic Qualification',\n",
        "        #'professional training',\n",
        "        'course project experience',\n",
        "        'related course projects',\n",
        "        'college activities',\n",
        "        'certifications',\n",
        "    ],\n",
        "\n",
        "\n",
        "\n",
        "[#miscellaneous\n",
        "        'activities and honors',\n",
        "        #'activities',\n",
        "        'affiliations',\n",
        "        'professional affiliations',\n",
        "        'associations',\n",
        "        'professional associations',\n",
        "        'memberships',\n",
        "        'professional memberships',\n",
        "        'athletic involvement',\n",
        "        'community involvement',\n",
        "\n",
        "        'civic activities',\n",
        "        'extra-Curricular activities',\n",
        "        'professional activities',\n",
        "        'volunteer work',\n",
        "        'volunteer experience',\n",
        "        'additional information',\n",
        "\n",
        "],\n",
        "\n",
        "[#achievements\n",
        "        'achievement',\n",
        "        'achievements',\n",
        "        'awards and achievements',\n",
        "        'licenses',\n",
        "        'license',\n",
        "\n",
        "        'conference presentations',\n",
        "        'conventions',\n",
        "        'dissertations',\n",
        "        'exhibits',\n",
        "        'papers',\n",
        "        'publications',\n",
        "        'professional publications',\n",
        "        'research experience',\n",
        "        'research grants',\n",
        "\n",
        "\n",
        "        'research projects',\n",
        "        'personal projects',\n",
        "        'current research interests',\n",
        "\n",
        "]\n",
        "]\n",
        "\n",
        "section_names=[\"skills\",\"experience\",\"education\",\"miscellaneous\",\"achievements\"]\n",
        "check_segmented = [\n",
        "    False,\n",
        "    False,\n",
        "    False,\n",
        "    False,\n",
        "    False,\n",
        "\n",
        "]\n",
        "\n",
        "def classify_sections(text):\n",
        "    # custom logic for classifying sections (similar to the previous example)\n",
        "    sections = {}\n",
        "    current_section = None\n",
        "    temp=False\n",
        "    for line in text.split('\\n'):\n",
        "     # print(line)\n",
        "      temp=False\n",
        "      for section_keywords in sec:\n",
        "        if  (check_segmented[sec.index(section_keywords)]==False) and any((keyword.lower() in line.lower())  for keyword in section_keywords):\n",
        "            for i in range(len(check_segmented)):\n",
        "              check_segmented[i]=False\n",
        "            check_segmented[sec.index(section_keywords)] = True\n",
        "\n",
        "            temp=True\n",
        "            current_section =section_names[sec.index(section_keywords)]\n",
        "            if sections.get(current_section,0)!=0:\n",
        "              continue\n",
        "            sections[current_section] = []\n",
        "            break\n",
        "      if current_section !=None and temp==False:\n",
        "        sections[current_section].append(line)\n",
        "\n",
        "\n",
        "    return sections\n",
        "\n",
        "def parse_resume(path):\n",
        "    text = doc2text(path)\n",
        "    sections = classify_sections(text)\n",
        "    return text, sections\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "import pandas as pd\n",
        "df=pd.DataFrame(columns=section_names)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "i55C1RHmqNlM",
        "outputId": "4f90d6f0-8509-48bb-a5ec-24d3d1674c75"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3.24 ms, sys: 982 µs, total: 4.22 ms\n",
            "Wall time: 4.25 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [skills, experience, education, miscellaneous, achievements]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-70e261e6-3c5c-4656-8acb-74c7560d3695\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>skills</th>\n",
              "      <th>experience</th>\n",
              "      <th>education</th>\n",
              "      <th>miscellaneous</th>\n",
              "      <th>achievements</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-70e261e6-3c5c-4656-8acb-74c7560d3695')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-70e261e6-3c5c-4656-8acb-74c7560d3695 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-70e261e6-3c5c-4656-8acb-74c7560d3695');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_51170d33-a315-4122-8ccd-306c2c1a6f80\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_51170d33-a315-4122-8ccd-306c2c1a6f80 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "repr_error": "'str' object has no attribute 'empty'"
            }
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "0bQOogIXZxF4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71712c53-56be-4d5c-bf7f-343761ba03fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resume Sections:\n",
            "Skills   :\n",
            "software, languages, and tools with the ability to learn new tools, databases and systems to maintain/enhance strategic vision of \n",
            "the organization and able to provide cutting-edge data engineering skills. Seeking a reputable organization to contribute to with \n",
            "opportunities for personal growth.  \n",
            ". TECHNICAL SKILLS \n",
            "Languages \n",
            "• \n",
            "Python, SQL \n",
            "Others \n",
            "• \n",
            "Git, Bash \n",
            " \n",
            "Data Manipulation & \n",
            "Visualization  \n",
            "• \n",
            "Pandas, Tableau BI, ETL, \n",
            "Apache Spark, Hadoop \n",
            "HDFS, Snowflake Data \n",
            "Factory, SnowSQL and \n",
            "Snowpipe, Amazon Kinesis \n",
            "Firehose, Databricks, AWS \n",
            "EMR, Athena, Lambda, \n",
            "Amazon MW Apache \n",
            "Airflow and AWS EC2  \n",
            "QuickSight and SNS, \n",
            "Cloudera infrastructure – \n",
            "Ambari, Hortonworks \n",
            "Sandbox and Zeppelin \n",
            "Notebook \n",
            " \n",
            "Databases and Storage \n",
            "• \n",
            "AWS RDS, MySQL, \n",
            "MongoDB, AWS \n",
            "DynamoDB, \n",
            "SQLAlchemy, \n",
            "PostgreSQL, AWS S3 \n",
            "Buckets, SQLite, Azure, \n",
            "Oracle. \n",
            " \n",
            " \n",
            "  \n",
            " \n",
            " \n",
            " \n",
            "Excellent project and time manager with outstanding excellent presentation skills, a great team player and ability to extend \n",
            "empathy.  \n",
            " \n",
            " \n",
            "\n",
            "-----------------\n",
            "Experience   :\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "Data Engineer | TC Energy | Houston, TX | 09/2019– Present | Odfjell Terminal | Seabrook, TX | 02/2019– 09/2019 | Enterprise \n",
            "Products (Through CF) | Houston, TX | 10/2018 – 02/2019 \n",
            "• \n",
            "Design and implementation of process data pipeline for asset data migration into AWS cloud environment \n",
            "• \n",
            "Built Snowflake Data Pipeline using Amazon Kinesis Firehose starting from the AWS EC2 logs to storage in Snowflake \n",
            "and AWS S3 bucket post-transformation and orchestrating through Amazon Managed Workflows for Apache Airflow \n",
            "(MWAA) DAGs.. Programming language used are Pyspark, Python, SparkSql \n",
            "• \n",
            "Architecting data pipeline with Cloudera infrastructure – Ambari, Hortonworks Sandbox using Zeppelin Notebook. \n",
            "Programming language used are Python, SQL \n",
            "• \n",
            "Created DataStream using AWS kinesis DataStream and kinesis firehose. Programming language used are Pyspark, \n",
            "Python, SparkSql \n",
            "• \n",
            "Migration solution from SAP and Maximo to Data Lake. \n",
            "• \n",
            "Solved data quality issues using AWS Databrew and Apache PySpark on AWS EMR and Databricks on AWS EC2 Clusters \n",
            "for data wrangling and transformations. \n",
            "• \n",
            "AWS Project monitoring using AWS Lambda and Aurora \n",
            "• \n",
            "Performed SQL data analysis using Oracle Database \n",
            "• \n",
            "Regular meeting with stakeholders to gather user requirements and ascertain objectives. \n",
            "Senior Data Analyst | Tesoro Logistics (Through IG) | San Antonio, TX | 04/2017 – 10/2018 \n",
            " \n",
            "• \n",
            "Design and implementation of process data pipeline and loading of structured data for performing quantitative and \n",
            "qualitative asset risk modelling, predictive analysis for program budgeting and forecast. \n",
            "• \n",
            "Created process safety risk reduction metrics \n",
            "Project Engineer | Weatherford | Houston, TX | 09/2013– 03/2016 \n",
            "• \n",
            "Performed ETL of drilling well bottom hole pressure ‘.mbd’ data from field and wireline instrumentations (bottom hole \n",
            "pressure, well depth and true vertical height of drilling bit). \n",
            "• \n",
            "Cleaned and transformed data into a ‘.csv’ data file.  Load data into Weatherford microflux database for analysis. \n",
            "• \n",
            "Project management of secure drilling operations of over 80 wells in Canada, Iraq, Nigeria, Angola, and Cameroon for \n",
            "clients such as Repsol, Shell, Exxon Mobile, Chevron and Total \n",
            " \n",
            "-----------------\n",
            "Education   :\n",
            " \n",
            " \n",
            " \n",
            "University of North Texas | Master of Science | Mechanical and Energy Engineering| Denton, TX \n",
            "Rice University | Certificate | Data Analytics | Houston, TX  \n",
            " \n",
            "-----------------\n",
            "Achievements   :\n",
            " \n",
            " \n",
            " \n",
            "Licensed Texas Professional Engineer | Texas Board of Professional Engineer and Land Surveyors \n",
            " \n",
            "-----------------\n",
            "CPU times: user 59.5 ms, sys: 9.28 ms, total: 68.8 ms\n",
            "Wall time: 711 ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<timed exec>:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "import os\n",
        "resume_content=''\n",
        "for filename in os.listdir(\"/content/drive/MyDrive/hackathon/resume-data\"):\n",
        "\n",
        "    resume_content, sections = parse_resume('/content/drive/MyDrive/hackathon/resume-data/Charles Obuseh.pdf')\n",
        "    df=df.append(sections,ignore_index=True)\n",
        "    print(\"Resume Sections:\")\n",
        "    for section, content in sections.items():\n",
        "      print(section.capitalize() + \"   :\")\n",
        "\n",
        "      print('\\n'.join(content))\n",
        "\n",
        "      print(\"-----------------\")\n",
        "    break\n",
        "    print(\"******************************************************************\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Define a function to concatenate skill and experience for each row\n",
        "def concatenate_skills_experience(row):\n",
        "    # Convert the list of skills to a string\n",
        "    skills_str = ', '.join(row['skills']) if isinstance(row['skills'], list) else str(row['skills'])\n",
        "    # Convert the element in the 'experience' column to a string\n",
        "    experience_str = ', '.join(row['experience']) if isinstance(row['experience'], list) else str(row['experience'])\n",
        "    return skills_str + ', ' + experience_str\n",
        "\n",
        "# Create a new DataFrame 'x' with the 'skills' and 'experience' columns\n",
        "x = df[['skills', 'experience']].copy()\n",
        "\n",
        "# Apply the concatenate_skills_experience function to each row and assign the result to column 'y'\n",
        "x['y'] = x.apply(concatenate_skills_experience, axis=1)\n",
        "\n",
        "# Drop the original 'skills' and 'experience' columns\n",
        "x.drop(['skills', 'experience'], axis=1, inplace=True)\n",
        "\n",
        "x\n"
      ],
      "metadata": {
        "id": "Ooxw8NRrVZ6E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "4a73a81b-77e4-4cc3-a3e0-f1115c65431a"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 5.86 ms, sys: 0 ns, total: 5.86 ms\n",
            "Wall time: 5.91 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   y\n",
              "0  software, languages, and tools with the abilit..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e1f53d8f-aa1b-40c4-8ca5-cd5fe974c6fd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>software, languages, and tools with the abilit...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e1f53d8f-aa1b-40c4-8ca5-cd5fe974c6fd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e1f53d8f-aa1b-40c4-8ca5-cd5fe974c6fd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e1f53d8f-aa1b-40c4-8ca5-cd5fe974c6fd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_d1a2eb0d-ac34-4add-ba8b-eb942f6d5b3a\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('x')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_d1a2eb0d-ac34-4add-ba8b-eb942f6d5b3a button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('x');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "x",
              "summary": "{\n  \"name\": \"x\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"y\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"software, languages, and tools with the ability to learn new tools, databases and systems to maintain/enhance strategic vision of , the organization and able to provide cutting-edge data engineering skills. Seeking a reputable organization to contribute to with , opportunities for personal growth.  , . TECHNICAL SKILLS , Languages , \\u2022 , Python, SQL , Others , \\u2022 , Git, Bash ,  , Data Manipulation & , Visualization  , \\u2022 , Pandas, Tableau BI, ETL, , Apache Spark, Hadoop , HDFS, Snowflake Data , Factory, SnowSQL and , Snowpipe, Amazon Kinesis , Firehose, Databricks, AWS , EMR, Athena, Lambda, , Amazon MW Apache , Airflow and AWS EC2  , QuickSight and SNS, , Cloudera infrastructure \\u2013 , Ambari, Hortonworks , Sandbox and Zeppelin , Notebook ,  , Databases and Storage , \\u2022 , AWS RDS, MySQL, , MongoDB, AWS , DynamoDB, , SQLAlchemy, , PostgreSQL, AWS S3 , Buckets, SQLite, Azure, , Oracle. ,  ,  ,   ,  ,  ,  , Excellent project and time manager with outstanding excellent presentation skills, a great team player and ability to extend , empathy.  ,  ,  , ,  ,  ,  ,  ,  , Data Engineer | TC Energy | Houston, TX | 09/2019\\u2013 Present | Odfjell Terminal | Seabrook, TX | 02/2019\\u2013 09/2019 | Enterprise , Products (Through CF) | Houston, TX | 10/2018 \\u2013 02/2019 , \\u2022 , Design and implementation of process data pipeline for asset data migration into AWS cloud environment , \\u2022 , Built Snowflake Data Pipeline using Amazon Kinesis Firehose starting from the AWS EC2 logs to storage in Snowflake , and AWS S3 bucket post-transformation and orchestrating through Amazon Managed Workflows for Apache Airflow , (MWAA) DAGs.. Programming language used are Pyspark, Python, SparkSql , \\u2022 , Architecting data pipeline with Cloudera infrastructure \\u2013 Ambari, Hortonworks Sandbox using Zeppelin Notebook. , Programming language used are Python, SQL , \\u2022 , Created DataStream using AWS kinesis DataStream and kinesis firehose. Programming language used are Pyspark, , Python, SparkSql , \\u2022 , Migration solution from SAP and Maximo to Data Lake. , \\u2022 , Solved data quality issues using AWS Databrew and Apache PySpark on AWS EMR and Databricks on AWS EC2 Clusters , for data wrangling and transformations. , \\u2022 , AWS Project monitoring using AWS Lambda and Aurora , \\u2022 , Performed SQL data analysis using Oracle Database , \\u2022 , Regular meeting with stakeholders to gather user requirements and ascertain objectives. , Senior Data Analyst | Tesoro Logistics (Through IG) | San Antonio, TX | 04/2017 \\u2013 10/2018 ,  , \\u2022 , Design and implementation of process data pipeline and loading of structured data for performing quantitative and , qualitative asset risk modelling, predictive analysis for program budgeting and forecast. , \\u2022 , Created process safety risk reduction metrics , Project Engineer | Weatherford | Houston, TX | 09/2013\\u2013 03/2016 , \\u2022 , Performed ETL of drilling well bottom hole pressure \\u2018.mbd\\u2019 data from field and wireline instrumentations (bottom hole , pressure, well depth and true vertical height of drilling bit). , \\u2022 , Cleaned and transformed data into a \\u2018.csv\\u2019 data file.  Load data into Weatherford microflux database for analysis. , \\u2022 , Project management of secure drilling operations of over 80 wells in Canada, Iraq, Nigeria, Angola, and Cameroon for , clients such as Repsol, Shell, Exxon Mobile, Chevron and Total ,  \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract Noun Phrases"
      ],
      "metadata": {
        "id": "uml-aZ-Ky5VD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "import spacy\n",
        "import pandas as pd\n",
        "\n",
        "# Load the English language model in SpaCy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Function to extract noun phrases from text using SpaCy\n",
        "def extract_noun_phrases(text):\n",
        "    doc = nlp(text)\n",
        "    noun_phrases = [chunk.text for chunk in doc.noun_chunks]\n",
        "    return noun_phrases\n",
        "\n",
        "# Load the DataFrame 'x' created in the previous code\n",
        "# Replace 'x.csv' with the actual file path if saving/loading from a file\n",
        "\n",
        "\n",
        "# Extract noun phrases from the 'y' column of DataFrame 'x'\n",
        "noun_phrases = []\n",
        "for text in x['y']:\n",
        "    noun_phrases.extend(extract_noun_phrases(text))\n",
        "\n",
        "noun_phrases"
      ],
      "metadata": {
        "id": "R4TagTo9gQEv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93f853c3-c649-4bbd-95f5-a8db8c50530f"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 767 ms, sys: 12 ms, total: 779 ms\n",
            "Wall time: 920 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['software',\n",
              " 'languages',\n",
              " 'tools',\n",
              " 'the ability',\n",
              " 'new tools',\n",
              " 'databases',\n",
              " 'systems',\n",
              " 'enhance strategic vision',\n",
              " 'the organization',\n",
              " 'cutting-edge data engineering skills',\n",
              " 'a reputable organization',\n",
              " ', opportunities',\n",
              " 'personal growth',\n",
              " 'TECHNICAL SKILLS',\n",
              " 'Languages',\n",
              " 'Python',\n",
              " 'SQL',\n",
              " 'Others',\n",
              " 'Git',\n",
              " 'Bash',\n",
              " 'Data Manipulation',\n",
              " 'Visualization',\n",
              " 'Pandas',\n",
              " 'Tableau BI',\n",
              " 'ETL',\n",
              " 'Apache Spark',\n",
              " 'Hadoop',\n",
              " 'HDFS',\n",
              " 'Snowflake Data',\n",
              " 'Factory',\n",
              " 'SnowSQL',\n",
              " 'Snowpipe',\n",
              " 'Amazon Kinesis',\n",
              " 'Firehose',\n",
              " 'Databricks',\n",
              " 'AWS',\n",
              " 'EMR',\n",
              " 'Athena',\n",
              " 'Lambda',\n",
              " 'Amazon MW Apache',\n",
              " 'Airflow',\n",
              " 'AWS',\n",
              " 'EC2',\n",
              " 'QuickSight',\n",
              " 'SNS',\n",
              " 'Cloudera infrastructure',\n",
              " 'Ambari',\n",
              " 'Hortonworks',\n",
              " 'Sandbox',\n",
              " 'Zeppelin',\n",
              " 'Notebook',\n",
              " 'Databases',\n",
              " 'Storage',\n",
              " 'AWS RDS',\n",
              " 'MySQL',\n",
              " 'AWS',\n",
              " 'DynamoDB',\n",
              " 'SQLAlchemy',\n",
              " 'PostgreSQL',\n",
              " 'Buckets',\n",
              " 'SQLite',\n",
              " 'Azure',\n",
              " 'Oracle',\n",
              " ',  ,  ,   ,  ,  ,  , Excellent project and time manager',\n",
              " 'outstanding excellent presentation skills',\n",
              " 'a great team player',\n",
              " 'ability',\n",
              " 'Present | Odfjell Terminal',\n",
              " 'TX | 02/2019',\n",
              " '09/2019 | Enterprise',\n",
              " 'Products',\n",
              " 'CF',\n",
              " 'process data pipeline',\n",
              " 'asset data migration',\n",
              " 'AWS cloud environment',\n",
              " 'Built Snowflake Data Pipeline',\n",
              " 'Amazon Kinesis',\n",
              " 'the AWS',\n",
              " 'EC2 logs',\n",
              " 'storage',\n",
              " 'Snowflake',\n",
              " 'AWS S3',\n",
              " 'transformation',\n",
              " 'Amazon Managed Workflows',\n",
              " 'Apache Airflow',\n",
              " '(MWAA) DAGs',\n",
              " 'Programming language',\n",
              " 'Pyspark',\n",
              " 'Python',\n",
              " 'SparkSql',\n",
              " 'data pipeline',\n",
              " 'Cloudera infrastructure',\n",
              " 'Ambari, Hortonworks Sandbox',\n",
              " 'Zeppelin Notebook',\n",
              " 'Programming language',\n",
              " 'Python',\n",
              " 'SQL',\n",
              " 'Created DataStream',\n",
              " 'AWS kinesis DataStream',\n",
              " 'Programming language',\n",
              " 'Pyspark',\n",
              " 'Python',\n",
              " 'SparkSql',\n",
              " 'Migration solution',\n",
              " 'SAP',\n",
              " 'Maximo',\n",
              " 'Data Lake',\n",
              " 'Solved data quality issues',\n",
              " 'AWS Databrew',\n",
              " 'Apache PySpark',\n",
              " 'AWS EMR',\n",
              " 'Databricks',\n",
              " 'AWS',\n",
              " 'EC2 Clusters',\n",
              " 'data',\n",
              " 'transformations',\n",
              " 'AWS Lambda',\n",
              " 'Aurora',\n",
              " 'Performed SQL data analysis',\n",
              " 'Oracle Database',\n",
              " 'Regular meeting',\n",
              " 'stakeholders',\n",
              " 'user requirements',\n",
              " ', Senior Data Analyst | Tesoro Logistics',\n",
              " 'IG',\n",
              " 'TX |',\n",
              " '– 10/2018',\n",
              " 'Design',\n",
              " 'implementation',\n",
              " 'process data pipeline',\n",
              " 'loading',\n",
              " 'structured data',\n",
              " 'qualitative asset risk modelling',\n",
              " 'predictive analysis',\n",
              " 'program budgeting',\n",
              " 'forecast',\n",
              " ', • , Created process safety risk reduction metrics',\n",
              " 'Performed ETL',\n",
              " 'bottom hole pressure',\n",
              " '‘.mbd’ data',\n",
              " 'field',\n",
              " 'wireline instrumentations',\n",
              " 'bottom hole',\n",
              " 'pressure',\n",
              " 'well depth',\n",
              " 'true vertical height',\n",
              " 'drilling bit',\n",
              " 'data',\n",
              " 'a ‘.csv’ data file',\n",
              " 'Load data',\n",
              " 'Weatherford microflux database',\n",
              " 'analysis',\n",
              " 'secure drilling operations',\n",
              " 'over 80 wells',\n",
              " 'Canada',\n",
              " 'Iraq',\n",
              " 'Nigeria',\n",
              " 'Angola',\n",
              " 'Cameroon',\n",
              " 'Repsol',\n",
              " 'Shell',\n",
              " 'Exxon Mobile',\n",
              " 'Chevron',\n",
              " 'Total']"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "import pandas as pd\n",
        "df1 = pd.read_csv(r'/content/drive/MyDrive/hackathon/noun_phrases_1.csv')\n",
        "df2 = pd.read_csv(r'/content/drive/MyDrive/hackathon/noun_phrases_2.csv')\n",
        "\n",
        "\n",
        "# Append df2 to df1\n",
        "merged_df = df1.append(df2)\n",
        "merged_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "id": "i1wq0qPEhrB8",
        "outputId": "a8bbd0b7-2c81-4f41-8516-1a4fd37784e9"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 11 ms, sys: 1 ms, total: 12 ms\n",
            "Wall time: 17.9 ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<timed exec>:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     noun_phrase  skills/non_skills\n",
              "0     management decision-making             skills\n",
              "1                       Power bi             skills\n",
              "2                        Tableau             skills\n",
              "3            visualization tools             skills\n",
              "4                      Snowflake             skills\n",
              "...                          ...                ...\n",
              "1494                    database         non_skills\n",
              "1495            direct marketing         non_skills\n",
              "1496      the firm’s top clients         non_skills\n",
              "1497                      nature         non_skills\n",
              "1498             spending habits         non_skills\n",
              "\n",
              "[2498 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b0f93530-0b6f-43d2-8ab2-1866809d58c6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>noun_phrase</th>\n",
              "      <th>skills/non_skills</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>management decision-making</td>\n",
              "      <td>skills</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Power bi</td>\n",
              "      <td>skills</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Tableau</td>\n",
              "      <td>skills</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>visualization tools</td>\n",
              "      <td>skills</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Snowflake</td>\n",
              "      <td>skills</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1494</th>\n",
              "      <td>database</td>\n",
              "      <td>non_skills</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1495</th>\n",
              "      <td>direct marketing</td>\n",
              "      <td>non_skills</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1496</th>\n",
              "      <td>the firm’s top clients</td>\n",
              "      <td>non_skills</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1497</th>\n",
              "      <td>nature</td>\n",
              "      <td>non_skills</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1498</th>\n",
              "      <td>spending habits</td>\n",
              "      <td>non_skills</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2498 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b0f93530-0b6f-43d2-8ab2-1866809d58c6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b0f93530-0b6f-43d2-8ab2-1866809d58c6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b0f93530-0b6f-43d2-8ab2-1866809d58c6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5f022acb-2166-4698-bbf5-f658f6e57e7e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5f022acb-2166-4698-bbf5-f658f6e57e7e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5f022acb-2166-4698-bbf5-f658f6e57e7e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_c76bb9b8-d39f-4e09-b2d4-0ec80636a805\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('merged_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_c76bb9b8-d39f-4e09-b2d4-0ec80636a805 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('merged_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "merged_df",
              "summary": "{\n  \"name\": \"merged_df\",\n  \"rows\": 2498,\n  \"fields\": [\n    {\n      \"column\": \"noun_phrase\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1869,\n        \"samples\": [\n          \"Housing Price Projection\",\n          \"decreases\",\n          \"OpenCV\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \" skills/non_skills\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"non_skills\",\n          \"skills\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "merged_df = merged_df.sample(frac=1, random_state=42)\n",
        "merged_df.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "24EWcFFvPjrD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46a7e97f-1702-499c-c831-858bd1bcd0d2"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2.32 ms, sys: 21 µs, total: 2.34 ms\n",
            "Wall time: 2.34 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "merged_df['noun_phrase']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnEXhxvZTyn-",
        "outputId": "9ef64899-b42f-4826-c527-ad682adb44f2"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 216 µs, sys: 12 µs, total: 228 µs\n",
            "Wall time: 236 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                           portfolio\n",
              "1                                 Key\n",
              "2                   various locations\n",
              "3                                   ●\n",
              "4                    Google Workspace\n",
              "                    ...              \n",
              "2493                              Apr\n",
              "2494                          MongoDB\n",
              "2495                      A/B Testing\n",
              "2496    Hybrid Neural Network Library\n",
              "2497        the subject matter expert\n",
              "Name: noun_phrase, Length: 2498, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Skill Extraction"
      ],
      "metadata": {
        "id": "rnQ9G-j20dwG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "mapping = {'skills': 1, 'non_skills': 0}\n",
        "\n",
        "merged_df[' skills/non_skills'] = merged_df[' skills/non_skills'].map(mapping)\n"
      ],
      "metadata": {
        "id": "zDwNgLhtXokl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bffea36a-9079-4338-9727-47d41098b4f9"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3.59 ms, sys: 0 ns, total: 3.59 ms\n",
            "Wall time: 5.63 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "merged_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "yQemaqYDYpiL",
        "outputId": "5d99ad38-f695-4277-e140-f86e4fea0e6d"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 5 µs, sys: 1e+03 ns, total: 6 µs\n",
            "Wall time: 8.58 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        noun_phrase   skills/non_skills\n",
              "0                         portfolio                   0\n",
              "1                               Key                   0\n",
              "2                 various locations                   0\n",
              "3                                 ●                   0\n",
              "4                  Google Workspace                   1\n",
              "...                             ...                 ...\n",
              "2493                            Apr                   0\n",
              "2494                        MongoDB                   1\n",
              "2495                    A/B Testing                   1\n",
              "2496  Hybrid Neural Network Library                   1\n",
              "2497      the subject matter expert                   0\n",
              "\n",
              "[2498 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9400c61c-bf43-4c19-bb67-79774b077fc2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>noun_phrase</th>\n",
              "      <th>skills/non_skills</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>portfolio</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Key</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>various locations</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>●</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Google Workspace</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2493</th>\n",
              "      <td>Apr</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2494</th>\n",
              "      <td>MongoDB</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2495</th>\n",
              "      <td>A/B Testing</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2496</th>\n",
              "      <td>Hybrid Neural Network Library</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2497</th>\n",
              "      <td>the subject matter expert</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2498 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9400c61c-bf43-4c19-bb67-79774b077fc2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9400c61c-bf43-4c19-bb67-79774b077fc2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9400c61c-bf43-4c19-bb67-79774b077fc2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-70f5211e-3074-4ff6-b928-a13e0585c1a5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-70f5211e-3074-4ff6-b928-a13e0585c1a5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-70f5211e-3074-4ff6-b928-a13e0585c1a5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_85552226-b9fa-45eb-8c84-ac4626f86bad\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('merged_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_85552226-b9fa-45eb-8c84-ac4626f86bad button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('merged_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "merged_df",
              "summary": "{\n  \"name\": \"merged_df\",\n  \"rows\": 2498,\n  \"fields\": [\n    {\n      \"column\": \"noun_phrase\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1869,\n        \"samples\": [\n          \"k-Means\",\n          \"different initializers\",\n          \"insights\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \" skills/non_skills\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "merged_df['noun_phrase'] = merged_df['noun_phrase'].astype(str)"
      ],
      "metadata": {
        "id": "YuOLyrHDU6Wd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1641917c-084f-4225-b2a4-04dfd7c9f797"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 970 µs, sys: 0 ns, total: 970 µs\n",
            "Wall time: 985 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training for skill extraction"
      ],
      "metadata": {
        "id": "ydaOBPE-1JhC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.layers import SpatialDropout1D, LSTM, Conv1D, GlobalMaxPooling1D, Dense, Embedding\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten\n",
        "# Tokenize the noun phrases\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(merged_df['noun_phrase'])\n",
        "X_sequences = tokenizer.texts_to_sequences(merged_df['noun_phrase'])\n",
        "print(X_sequences)\n",
        "# Pad sequences to ensure uniform length\n",
        "max_length = 100\n",
        "X_padded = pad_sequences(X_sequences, maxlen=max_length, padding='post')\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_padded, merged_df[' skills/non_skills'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the model\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=100, input_length=max_length),\n",
        "    Conv1D(filters=128, kernel_size=5, activation='relu'),\n",
        "    GlobalMaxPooling1D(),\n",
        "    # Flatten(),\n",
        "    Dense(units=10, activation='relu'),\n",
        "    Dense(units=1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print model summary\n",
        "print(model.summary())\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=30, batch_size=32)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss}, Test Accuracy: {accuracy}')\n"
      ],
      "metadata": {
        "id": "7U-eKbp7ZtGB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5411cade-d777-4d73-95a5-fc16d13cb7df"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[206], [310], [53, 431], [18], [83, 748], [207], [162, 311, 312, 208], [54], [749, 73, 1], [13, 128], [84, 48], [209], [129, 210], [750, 751], [163], [11, 432, 211], [752, 753], [433, 754, 23, 28, 3, 755, 433, 756, 212, 63], [74, 757], [5, 758, 33], [434, 435], [213, 19], [164], [759, 214], [760, 75], [19], [761, 436, 8], [9], [24, 64], [2, 39], [762, 763, 437, 764], [765, 438, 40], [4, 165], [439], [83, 440], [34, 25], [766, 313], [14, 10], [767, 314, 768], [5, 769, 311, 312, 208], [164], [1, 26, 165], [441], [49, 442, 106, 34, 25], [166, 167], [315], [1, 107, 85], [316, 130, 443, 130], [9], [770], [771], [41], [772, 773, 774], [215], [775, 1, 216], [444, 445, 776], [1], [777], [6], [86], [317], [14, 10], [2, 40], [42], [87], [88, 217], [43], [13, 76], [22], [131], [778], [55, 446, 779, 780, 218], [318, 168, 7, 219, 319, 781, 447, 782, 783, 447, 448], [220], [784], [27], [132, 785], [221], [108, 222], [786, 320], [4], [2, 8], [35], [787], [2, 133, 65], [3, 134], [2, 1], [56], [788], [50], [169, 789], [449, 214], [790, 791, 77], [321], [450], [55, 85], [29, 451], [452, 135], [2, 8], [792, 170, 15], [30], [42], [793], [57, 28], [66, 794], [322, 9, 7, 67, 36], [795, 223], [796, 797, 57], [1, 58], [798, 75], [26], [453, 136], [799], [3, 224, 800], [2, 801], [2, 802, 323], [171], [225, 51], [803], [37, 454], [65, 804], [805, 806, 226], [2, 455, 227], [807, 456], [228, 109, 457], [229, 808], [3, 809, 810], [109, 811], [3, 812], [129], [53, 813], [814, 815, 816], [11, 89], [458], [5, 817, 818], [90, 91], [2, 819], [5, 31, 110, 324], [74, 325], [78], [111], [16], [459, 820], [53, 26, 821], [12], [172], [56], [460], [13, 77], [92], [112], [822], [1], [823, 824, 825], [14, 10], [326, 40], [3, 73, 173, 327, 1], [17, 165], [36, 6], [461], [12], [328], [5, 174, 93], [826], [175], [230], [13, 76], [79, 94], [6], [80], [329], [462, 75], [463], [113, 1], [17], [35], [2, 827, 828, 829, 65], [137, 15], [464, 830], [6], [831], [176, 1], [231, 832, 112], [132, 833], [30, 20], [44], [834, 835], [4], [4, 232, 465], [836, 1, 233], [837], [6], [23, 838, 466], [68], [839], [95], [3, 840, 234], [841, 467, 138], [235, 842, 843, 330], [139, 114], [468], [844], [2, 845, 846], [847, 848, 1], [849, 140, 469, 470, 210], [236], [14, 10, 331, 237], [108, 222], [141], [45], [83, 177, 471], [472], [2, 850, 473], [115], [43], [46], [851, 87, 238], [89], [46], [53, 239, 474], [14, 10], [17], [55, 852, 475, 853], [332, 854], [54], [855], [59], [81], [108, 333], [334], [856], [209, 240, 476], [173, 1], [4], [49], [857, 96], [21], [16], [26], [162, 69, 858], [97, 20], [311, 312, 208, 324], [225, 241], [859, 472], [142, 142, 860], [861], [80], [862, 863], [5, 37, 477], [335], [44], [864], [242], [95, 50], [46], [14, 10], [21], [143], [243, 478, 75], [865], [60, 178, 116, 61, 244, 866, 867, 178, 50, 61, 868], [336, 245, 479, 1], [480, 480], [869, 1], [243, 870], [98], [111], [5, 481], [482], [40, 337, 32], [3, 20], [179, 144], [338], [69, 63], [224, 180, 465], [339, 340, 246], [213, 19], [117, 871], [247], [5, 483], [872, 873], [874, 875], [341, 876, 877, 878, 879], [145], [342, 880], [320, 881], [484], [56], [310, 47, 485], [882, 1, 8], [22], [47, 181], [486, 883], [21], [14, 10], [1, 8], [884, 487], [17, 488], [134, 248], [885, 886], [489, 343, 344], [14, 10, 165], [5, 33], [6], [55, 182, 887, 99], [4, 16], [98, 183], [6], [75], [345, 146], [5, 888, 889], [89], [890, 217, 490], [172], [147, 346], [891, 491], [27], [16], [328], [35, 249], [492, 250, 892], [34, 25], [893, 8], [493], [894], [895], [2, 896], [106], [27, 494], [21], [148], [90, 91, 897], [18, 251, 347, 70], [495], [348], [2, 898, 184, 899, 252], [11], [496, 253, 497], [498], [109], [83, 254, 95, 148], [54], [185], [235], [164], [80], [32], [2, 900, 323], [255], [248], [901], [169], [902], [8], [903], [904, 251], [349, 499], [905], [350], [100], [106], [2, 906, 907, 65], [6], [14, 10, 908], [256], [112], [108, 222], [909, 20], [500, 910], [56], [501, 351], [257, 39], [12], [911, 912, 502], [17], [101, 178, 116, 61, 244, 503, 504, 913], [90, 91], [914, 505], [50], [915, 7, 916, 1, 506, 507, 35], [917], [508, 114], [73, 186, 1, 352], [67], [187, 1, 82], [509, 510], [258, 167], [446, 918], [511, 512], [919, 920], [64, 1, 513], [3, 118, 921, 7, 186, 102, 259], [1], [188, 149], [230], [353], [6], [189, 29, 190], [18], [43], [4], [191, 88], [58], [131], [12], [443, 211, 514, 211, 230], [9, 241], [922, 192, 8], [515, 923, 924, 10], [925, 926, 25], [927, 354], [119, 928, 929], [332, 260], [261, 516], [16], [213], [930], [43], [150, 262, 23, 325], [508, 931], [111], [355], [517], [207], [6], [118, 21, 102, 259], [193, 932], [263, 518, 66, 519, 933], [934], [935, 520, 521], [22], [936, 1, 937], [13, 1, 58], [258], [1, 264], [938], [522], [179], [939], [523], [940], [941, 356], [942, 943], [944, 23, 357], [79, 945], [946, 25], [947], [358], [948, 524], [98], [3, 171], [4], [2, 192, 8], [949, 1], [34, 25], [525], [35], [9], [30, 20], [434, 526], [11, 527], [528], [950, 149], [5, 951], [30, 265], [96], [23, 266], [90, 91], [120], [952, 953], [359], [6, 7, 1, 26, 529], [38, 102], [21], [71], [954, 1, 65, 58], [955], [67, 36], [956], [11], [5, 35], [11], [228, 175, 957], [2, 140, 138], [135], [958, 959], [530], [242], [28], [267], [73, 1, 121], [12], [179, 960], [268], [360, 75], [961, 962], [531], [963, 964], [965, 269, 256], [357], [966], [50, 116], [337, 54], [98], [967, 968], [9, 48], [532, 270, 15], [54], [42], [969], [970], [79, 971], [139], [37], [533, 534], [60], [1, 972], [973], [2, 151], [17], [84], [974], [194, 253, 1], [44], [535, 975], [3, 73, 142, 142, 536, 1], [271], [976, 977], [537, 538], [1, 82], [978], [148], [195], [979, 86], [34, 25], [4], [38], [37, 152], [122, 77], [539], [361, 99, 980, 28], [49], [249], [74, 1, 62], [4], [153, 97, 99, 981], [154, 20], [1, 540], [982, 272, 983, 984, 469, 470, 210], [237], [34, 25], [362, 985, 986, 273], [987], [988], [454, 206, 1, 8], [6], [541], [14, 10], [64, 267], [9], [363], [989], [542], [192, 990, 114, 7, 26, 89], [991], [80], [33], [1], [442, 106], [992, 993], [1, 8], [994, 63, 995], [996], [997], [317, 239], [14, 10], [364, 998], [999, 1000], [46], [118, 1001, 1002], [1, 176], [122, 194], [322, 365], [23, 1003], [4], [1004], [1005], [366, 140, 1], [274, 367, 7, 1006, 543, 1007], [544], [1008], [1, 275], [102], [2, 261, 123], [1009, 253], [1010], [545, 1011, 13, 76, 60, 3, 1012, 1013], [2, 368, 1014], [17], [109], [276], [106], [546], [547], [3, 1015], [432, 1016, 130], [81, 177], [68], [2, 1017, 1018, 1019], [1020, 548], [1021, 1022], [68], [549], [1, 1023], [9, 48], [1, 277], [], [2, 70], [550, 1024], [1025, 1026, 1027], [84], [27], [278, 7, 72, 1028, 96], [1, 26], [2, 37, 82], [2, 1029], [4], [279, 19], [5, 369, 31, 150, 1, 190], [19], [1030, 551], [46], [1], [60], [4], [31, 110], [4, 258], [280], [216], [1031, 264], [1, 52], [370], [12, 12], [12], [53, 62], [215], [34, 25], [1032, 371], [1033], [1034, 1035, 23], [1036, 7, 1037, 372], [30, 265], [1038], [373, 552, 223, 553], [81], [1039, 1040], [17], [554, 374, 174, 1041], [1042], [281, 555, 1043], [70, 28], [282], [27], [283, 375, 19], [118, 556], [1044], [2, 169, 1, 435], [4], [368], [11], [547], [339, 340, 246], [1045], [26], [1046, 48], [557, 103], [30, 20], [13, 77], [60], [24, 64, 6, 45], [124, 183], [335], [37, 558], [559, 235], [1047, 1048], [1049], [1050, 560], [231], [366], [1051, 227], [284], [561, 144], [24, 104], [1, 41], [43], [196], [9], [70, 51], [92], [18, 154, 376, 1052], [2, 1053], [377], [562], [144], [563, 1, 8], [115], [1, 41], [145], [59, 3, 42, 3, 17], [2, 564], [47, 168, 15], [342], [565, 90, 91, 1054], [81, 1, 482], [1055], [1056], [172], [1057], [21], [5, 57, 272], [377], [2, 151], [522], [1, 41, 85], [1, 41], [566, 567], [1, 58], [535, 499, 1058], [225, 285], [38, 1059, 43], [260, 353], [150, 233], [5, 1060, 1061, 151], [35], [105], [9], [46], [8], [5, 568, 569, 129], [67, 117, 378, 286], [117], [1062], [379], [1063], [109, 1064, 155, 1065], [6], [2, 1066], [137, 15], [13, 76], [1067], [560], [59], [111], [566, 63, 567], [1068], [2, 8], [1069, 1070], [1071, 493], [1072, 28], [74, 19, 40], [570], [112], [1073], [571, 1074], [3, 1075, 1], [55, 1076, 1077, 40], [24], [156, 10], [380], [55, 182, 481], [6, 157], [28], [1078, 1079, 1080], [572], [27], [16], [1081, 89], [58], [1, 26], [573, 574, 1], [124, 267], [1082], [287], [4], [18], [11], [102], [42], [354], [381], [565], [229, 88, 1083, 1, 41, 575], [119, 1084], [21], [576], [125], [577], [1085, 322, 1086, 578], [113, 288, 259], [1087], [101, 178, 116, 61, 244, 520, 521], [3, 579, 382, 276, 289, 181], [98], [260], [1088], [1089, 180], [4, 183], [46], [580], [383], [188, 581], [141], [4], [242], [1090, 1091, 1092], [81], [8], [148, 22], [582, 583], [277], [290, 1093, 321], [158], [1094, 384], [4], [1095, 1096, 1097, 353, 326, 1098, 1099, 7, 1100, 3, 584, 14, 10, 58], [585], [1101, 1102, 163, 372], [1103, 1104, 1105, 1106, 1107, 1108], [103], [11], [43], [501, 351], [1109, 7, 1, 41, 1110], [1111], [133], [100], [49], [586], [1, 587], [326], [1, 291], [8], [292], [72, 588, 29], [219, 33, 255, 589], [1, 121, 1112], [228, 167], [197, 195], [19, 40], [338], [24, 104], [45, 39, 33, 147], [293], [219, 319], [5, 169, 280, 198], [383, 286], [590, 1113], [66, 62], [63, 294], [53, 1114], [4], [591], [94, 592, 14], [1115], [68], [22], [1116, 51], [1117], [550, 373], [1118], [385, 170, 15], [12], [1119], [1120], [2, 63], [8], [1121], [295, 4], [44, 6], [386, 296], [11], [3, 387, 1122, 8], [1123], [1124], [593, 594], [73, 595, 7, 596, 297, 1], [171], [117], [597, 250, 143], [28], [103], [1, 26], [388], [258, 14, 10, 165], [13, 389], [87, 252], [2, 1125, 1126, 598, 1], [1127], [1128, 314], [1129], [50], [73, 1], [1130, 390], [1131], [44], [18, 126, 563, 1, 8], [53, 47, 92], [137, 598, 29, 1132], [44, 78], [9], [1133], [1134, 1135, 1136, 116], [2, 1137, 1138, 111], [585], [94], [27], [271], [47, 168], [182, 1139], [1140, 599, 233], [1141, 223], [4], [1142, 1143, 40], [102], [44], [1], [1144], [1145, 1, 163], [111], [4, 229, 364, 600], [30], [18], [1146, 1147], [237], [12], [66, 268, 89], [331], [1148], [601], [127], [101, 50, 61, 391], [297, 1, 7, 1149, 1150], [177, 99], [121, 296], [20], [162], [1151, 392, 1152, 1153, 89], [1154], [1155], [1156, 1157], [437], [147], [1158], [5, 32], [558, 52, 57], [1159], [216], [602, 544], [9, 241], [1160, 603], [24, 104], [1161], [3, 220, 32], [269, 8, 152], [604], [94], [605, 144], [1, 606], [1, 275], [289], [164, 20], [1162, 486, 123], [28, 176, 1], [18], [3, 607], [323], [6, 1163], [1, 114, 7, 52, 155], [12], [1164, 298, 1, 506], [11, 334], [26], [95], [314, 1165], [36, 159], [3, 197, 124, 195], [608], [2, 1166, 354], [299, 609], [1167], [1168], [68], [242], [2, 227], [84], [541], [1169, 1170], [378, 286], [208], [175], [1171], [150, 262, 23, 1], [1, 1172, 241], [3, 1173, 494, 7, 48, 8], [5, 1174], [99, 7, 610, 138], [36, 6, 157], [1175], [56], [611, 1176], [71], [63, 325], [2, 612], [1177], [115], [1178], [2, 613], [24, 64], [1179], [19], [55, 1180], [5, 45, 39, 33], [6], [1181], [2, 1182, 393, 1183, 394, 395], [614, 1184], [35], [341, 1185], [300], [14, 10], [217, 490, 273], [6], [615, 1186, 616], [1187, 1188, 617], [396], [74, 1, 62], [1189, 47, 96], [300], [1], [209], [1190], [6], [301, 302], [12], [100], [1, 8], [1191], [380], [1192], [2, 183], [1193], [1194], [11], [66, 618], [5, 619, 1195], [1], [87, 252], [72, 588], [124, 620, 52], [12, 166], [108, 333], [191, 1196, 160, 86], [83, 440], [1, 114], [133], [47, 190, 85], [126, 1197], [236], [1198], [621], [1199, 1200], [1201], [199, 1202], [4, 377], [80], [22], [2, 1203], [188, 374, 200, 303], [54, 157], [1, 26], [1204, 622], [9], [623], [196], [2, 1205], [6], [1206, 1, 1207, 395], [4], [247], [119, 1208, 1, 121], [624], [16], [12], [625, 1209, 548], [375, 19], [5, 45], [5, 297], [92], [1210], [515, 1211, 32], [626], [1, 1212, 1213], [627], [1, 103], [189, 294], [3, 107, 267], [303], [26], [2, 338], [221, 16], [385, 294], [16], [348], [87, 252], [628], [146], [115], [28], [136], [1214], [629, 31], [11], [16], [1215, 571], [56], [1216], [43, 1, 397], [3, 30], [137, 177, 398, 397, 75], [3, 249], [9, 48], [283, 19], [1217], [24], [21, 3, 4, 3, 12], [524], [1, 630], [103, 1218], [175], [631, 173, 212, 1219, 1220], [261, 123, 1221], [16], [484], [360, 51], [582, 7, 1222, 1], [265], [49], [135], [5, 33], [632, 1223], [1224], [95], [317, 239], [112], [1225], [17], [284, 457], [1226, 1227, 13, 76, 60, 3, 1228, 572, 487], [75], [4], [1229, 1230, 633, 399, 8], [6], [250, 143], [90, 91], [1231, 51], [185], [1, 8], [35], [34, 25], [1232, 1233], [9, 1], [131], [71], [552, 553], [218], [634, 304], [154, 20], [148], [635], [212], [285], [1], [607, 51], [536, 1234, 105, 255], [1235, 1236], [1237, 1238], [48], [1], [2, 63], [18], [60], [221], [636, 186, 36, 6], [4], [11], [38, 43], [626, 1239], [1240, 1241], [2, 33], [334], [217], [637, 1242, 1243, 516], [13, 128], [1244], [638, 1245], [2, 120], [300, 127], [359], [639, 277], [278, 1246], [640], [641, 181], [220, 257], [1247, 1248], [445], [78], [83, 642], [1, 41], [123, 163], [373, 152], [1, 52], [88, 104], [90, 91], [79, 393], [1249, 1250], [2, 1251], [71], [27], [1252, 1253], [643, 155], [3, 644, 400, 107], [201, 305], [1254], [1255, 645], [6], [55, 182, 306], [2, 1256], [2, 575], [156, 10], [49, 646, 106], [112], [644, 1257], [647, 648], [1258], [649, 94], [12], [1259, 343], [1260], [2, 281], [401], [650, 526], [88, 6], [2, 1261, 651], [145], [1262, 1263, 245, 5, 402, 198], [1264, 277], [24, 27], [590, 1265, 1266], [1267], [35, 304], [38], [1], [403, 307, 529], [348, 1268], [1, 145], [318, 168, 89], [2, 637, 1269, 604, 1270], [111], [1271, 1272, 173, 261, 1], [1273], [264, 1274], [38, 652, 653], [654], [73, 1], [5, 32], [69, 315], [2, 1], [1275], [655, 404], [5, 31, 110, 656], [29], [1276], [81], [1277, 93], [4], [202], [21, 44, 78, 46], [2, 405, 406, 33], [49], [657, 658, 407], [20], [55, 224, 180, 57], [464, 135], [60], [554], [20], [9, 38, 48], [2, 408], [537, 538], [232, 4, 1278], [1279], [], [659], [34, 25, 16], [139, 1280], [409, 1281], [290, 352], [1, 41, 410], [1282, 40, 660], [127], [1283], [20], [2, 69], [661, 6], [67, 662], [1284, 327, 1285], [444, 1286, 411], [18, 1287, 173, 1], [663], [34, 25], [17], [81], [627], [664], [21], [184], [284], [1288], [2, 280], [140], [121, 1289], [24, 64, 1290], [186, 1291, 92], [2, 665, 564], [1292, 62], [158], [1293, 1294], [21], [36, 38, 259], [56], [83, 254], [1295, 1296], [1297], [6, 304], [498], [11, 1298], [1299, 1, 1300], [270], [46], [67, 662], [1301], [193, 1302, 7, 1303, 1304], [150, 262, 23, 276, 289, 63], [29], [203], [1305], [666, 667], [3, 1306, 269, 638], [1307, 285], [668, 396], [1308, 99], [22], [14, 10, 1309], [1310], [163], [5, 110], [226], [37], [54], [1311], [26], [192, 8, 497], [64, 214, 1312], [1, 203, 8], [251, 347, 70], [57, 343, 669], [5, 1313, 412, 393], [56], [503, 1314, 504], [2, 13, 36, 159], [1315], [22], [46], [403, 152], [339, 340, 246], [181], [1316], [101, 50, 61, 391, 329, 57], [166], [129], [532, 270], [670, 331, 58], [525], [1317, 1318, 1319, 1320], [413, 125], [307, 671, 307, 7, 414, 1], [12], [12], [80], [1321, 672, 72], [21], [366, 673], [1322, 138], [5, 1323, 77, 556], [1324, 674], [13, 77], [1325, 675, 1326], [676, 677], [204], [9, 7, 113, 288, 157], [1327, 22, 195], [159], [302], [78], [678, 679, 105, 1328, 1329, 1330], [219, 319], [1331, 29, 680], [291], [158, 681], [3, 579, 1332, 1333, 65], [142, 142], [31], [1334, 1335], [1336], [24, 153, 97], [52], [4], [204, 1337], [665, 1, 1338], [1, 275], [70], [597, 218], [1339], [51], [1340], [290, 352], [146], [202], [164, 1341, 546], [1342, 7, 220, 1, 1343], [682], [9], [299], [71], [17], [137, 120], [1, 121, 683], [128, 668], [42, 471], [17], [1344], [16], [195], [11], [1345, 32, 581], [488, 1346], [1347, 684], [1348, 685], [4], [68], [1349], [1350, 1351], [686, 1352, 103], [274, 685, 1353], [49], [4, 30], [687, 306, 688], [689, 1354, 45], [690, 409, 33, 216], [1355], [45], [448], [1356], [1357], [691, 32], [5, 1358], [193, 360, 51], [80], [308, 616], [2, 1359, 1360, 1361, 1362], [415], [120], [133], [1363, 169], [49], [109, 1364, 125], [162, 692], [1365], [281, 1366, 1367], [1368, 52, 1369], [5, 1370, 451], [120], [631, 693, 664], [1371, 1372], [122, 94, 694], [4], [117], [189, 79, 693, 272], [88, 27], [3, 636, 1, 203], [1373, 372], [291], [30, 20], [27], [2, 456], [14, 10], [355], [2, 695], [143], [415], [5, 174, 93], [1374], [36], [1375], [60], [44, 78], [596], [5, 201, 305, 40], [6], [1376, 1377, 1378, 364, 1379, 1380, 30], [382, 1381], [387, 577, 5, 174, 93], [696, 349], [1382], [295, 9], [15], [274, 367, 140, 29], [17], [95], [1383, 105], [145], [608], [67, 98, 36, 416], [131], [54], [8], [2, 1384], [253, 669], [279], [386, 296], [300, 127], [113, 288, 159], [2, 13, 134], [184, 66, 105], [96], [18, 126, 66], [100, 157], [9], [13, 697, 1385], [136], [417], [5, 1386, 1387, 401], [698], [641, 135], [2, 410], [6], [218], [699, 700], [701, 85], [232], [9, 48], [1388, 148], [1389], [22], [2, 649, 180], [1390], [436, 1], [1391, 1], [702, 1392, 1393, 293, 1394], [1395], [2, 1396, 1397], [1398], [1399], [122], [71], [143, 505], [26, 15], [1400, 200], [2, 1401], [59], [6, 371], [231, 418, 301, 302], [2, 280], [355], [1402], [4], [441], [419, 1403, 1404], [236], [3, 73, 350, 703], [34, 25], [657, 658, 407], [5, 1405, 1406, 1407], [1408, 1409, 415], [39], [1, 507], [3, 1410, 226], [1], [70], [9, 512], [20], [1411, 175], [1412], [13], [1413, 1414], [2, 1415, 1416], [279, 19], [42], [1417, 450, 1418], [187, 1, 134], [704], [71], [705, 39], [90, 91], [1419, 407], [8], [240], [122, 257], [706, 420], [2, 625, 412, 45], [1420, 1421], [601], [11, 202, 1422, 263, 200], [707], [69, 1423], [134], [332, 260, 237], [22], [421], [295, 4], [131], [308], [118, 100, 384], [1424], [113, 1425], [11, 71, 263], [185], [4], [4], [205], [613, 1426], [708, 709], [438, 1427, 680], [182, 635], [299, 7, 1428, 1], [663], [43], [1429, 1430, 1431], [283], [602, 1432], [710], [68], [2, 1433], [576], [1434], [1435], [12], [1436], [1437], [1438, 50, 61, 1439], [422, 120], [119, 188, 149], [2, 97, 32], [1440], [16], [337, 399, 8], [1, 421], [139], [1], [449, 45], [1441, 160, 292], [1442, 1443], [1444, 99], [1445, 1446, 33], [], [417, 423, 711], [186, 92], [42], [9, 712], [4], [1447, 62], [31, 110, 320, 1448, 1], [1449], [389, 424], [172], [196], [59], [191, 6], [156, 10, 1450, 1451], [17], [], [1452, 1453, 647, 648, 8], [489, 1454], [1455, 1456, 265], [713], [422, 149], [13, 76], [205], [56], [11], [670, 149], [1457], [2, 1458, 345, 37], [16], [2, 1459, 141, 99], [23, 349], [101, 1460, 50, 1461, 206], [2, 1462, 1463], [1464], [4], [78], [500, 1465], [207], [530], [204], [122, 28], [363, 116], [1466], [9], [35], [308, 1467, 344], [1468, 371], [56], [1469], [201, 1470], [1471, 453, 713], [47], [318, 168, 158, 714, 51], [2, 206], [425, 167], [38], [86, 715], [698], [1472], [266, 256], [716, 16], [2, 617], [204], [455, 69], [], [2, 1473], [5, 492, 250], [359], [381, 33], [523], [2, 717, 1474], [1475, 1], [413, 125], [139, 114], [4], [358, 474], [68], [145], [1476], [37], [194, 82], [1477, 72, 1478, 113], [1, 1479], [283, 19], [4], [426, 485], [1480, 1481], [3, 1482, 7, 1483, 203], [293, 51], [199], [282], [531], [1], [1], [30], [356], [115], [100], [2, 408], [555], [1484], [3, 126, 1, 275], [659], [6], [2, 170, 15], [24, 64], [5, 413, 45], [2, 614, 123], [32, 7, 69, 32], [1485], [718, 1486], [2, 403, 1487], [1, 1488, 1489], [38, 43, 113, 288, 84, 67, 54, 9, 68, 67, 1490, 98, 284, 67, 196, 117, 495, 125], [2, 1], [196], [1491], [141], [282], [132, 62], [702], [1492, 19], [401], [100], [1493, 691], [1494, 1], [1495, 87, 238, 101, 178, 116, 61, 244, 1496], [643], [1497], [57, 28], [1498], [160, 86], [13, 674], [129], [3, 127], [2, 1499, 1500], [39, 201, 1501], [427, 31, 1], [221], [1502], [459], [655, 1], [584, 619, 7, 132, 1503, 58], [26, 719], [53, 38, 105], [13, 76], [1504], [46], [27], [118, 132, 102, 159], [1505], [2, 1506], [1507, 1508, 1509], [1510], [1, 496], [385, 170, 15], [517, 199], [228, 58], [1511, 1], [707], [1512], [2, 1513, 138], [94], [15], [23, 155, 1, 82], [42], [1514], [100], [147], [2, 392, 1515], [1516, 1517], [17], [4, 666, 600], [124, 1518, 183], [4], [12], [2, 1519, 1520], [1521, 1522], [197, 153, 97, 719], [479], [1523], [1524, 527], [49], [74, 1525], [15], [39, 32], [149], [1526], [427, 31, 52], [1527, 1528, 491], [1], [1, 41, 420], [632, 254], [3, 1529, 7, 1530, 1, 1531], [27], [710, 1532, 8], [1533, 294, 194, 82], [1534], [1535], [185], [93], [37, 1536], [30], [720], [95], [3, 118, 1537, 1538, 33], [1539], [127], [36], [86, 1540], [133], [36, 378, 1541], [618], [1542, 154], [106], [43], [287], [721], [72], [12, 12], [1543], [4], [6], [5, 1544], [49], [230], [54], [412], [1545, 1], [1546], [50], [14, 10], [151], [2, 1547, 705], [1548, 1549, 1550, 1551, 1552, 357], [1553, 1554, 269, 1555], [18], [2, 696, 426, 1556], [14, 10], [1557, 146, 272, 85, 1558], [1559, 72], [1560, 29], [22], [1561], [21], [188, 144], [1, 41], [22], [368, 29, 82], [1562, 722, 128, 255, 589, 316, 418, 1563, 418], [419, 386, 296], [1564, 1565, 376], [1566, 1567, 1568, 15], [115], [45], [17], [723, 47, 96], [6], [1569], [152], [1570], [287], [477], [722], [561, 591], [59], [383, 623], [131, 646, 42], [224, 170, 1571, 1], [77], [1, 52, 15], [34, 25], [213, 279, 19], [306, 1572], [724], [136], [1573, 7, 119, 1574, 303], [9], [1575, 1576], [1577], [204], [1578, 725, 1579, 721], [1580], [1581], [74, 1582], [726, 1583], [1584], [3, 126, 399, 8], [718, 727], [3, 1585, 603, 146, 411], [71], [19], [2, 70], [1586, 414, 7, 671, 307, 37, 1], [39, 1587], [704], [328], [28], [24, 153, 97], [400, 107], [158, 714], [1588], [651], [1589, 1590, 578], [1591, 1592], [2, 634], [78], [79, 1593], [1594, 10, 633, 1595, 1596, 123, 324, 40], [215], [309], [27], [414, 62], [101, 642, 83, 61, 1597, 72], [2, 298, 65], [136], [1598, 1599, 61, 341], [4], [44], [60], [47, 72, 8], [1600], [21, 166], [1601], [171], [59], [345, 620], [1602], [107, 1603, 1604, 1605, 678, 679, 105, 1606, 1607], [225, 15], [201, 305], [408], [248], [42], [177, 1608], [88, 104], [1609], [409], [45], [2, 611], [309, 724], [80], [539, 1610, 1611], [139, 653], [1612], [1613], [187, 1, 134], [1614], [18, 126, 1615, 8], [1, 41], [156, 10, 29, 304], [701, 85], [64, 728, 397], [1], [1616, 15], [1617], [4], [1618, 1619, 1620, 389, 424], [419], [6], [336, 245], [593, 594], [38], [1621, 19, 40], [46], [44], [381], [194, 1622], [1623, 628, 330], [533, 534, 87, 238], [728, 424], [1624], [13, 77], [1, 82], [5, 452, 40], [1625], [117], [2, 405, 406, 428], [54], [1626], [1, 1627], [3, 570, 729, 1628, 57], [5, 293], [14, 10], [187, 1], [362, 1629, 69], [18], [1630], [1631, 160, 292], [55, 410], [621], [27], [93], [1632, 1633], [1634, 1635, 1636, 1637, 727], [1638, 271, 65], [375, 640], [6], [13, 76], [1639, 549], [2, 629, 1640], [2, 77], [11], [1641, 1642], [3, 725, 107, 15], [1643, 5, 200], [102], [37, 730], [5, 66, 519], [247], [22], [731], [1644, 681], [128, 234], [47, 622], [654], [16], [156, 10], [720], [1645], [599], [3, 387, 29], [4], [1646, 351], [1647], [3, 1648], [2, 147, 7, 93, 1649], [81], [120], [9, 712], [358, 1], [1650], [108, 333, 233], [60], [732], [79, 51], [1651, 203], [1652, 398, 33], [189, 733], [1653], [1654], [101, 50, 61, 391, 687, 306, 688], [1655], [18], [23, 1656], [202], [282], [44], [369, 31], [690, 7, 1657, 1658, 1659], [1660], [1661, 7, 1662, 1663], [370, 1664, 336, 245], [23, 239], [28], [1665, 14, 10], [1666, 13, 262, 404], [528], [2, 1667], [676, 677], [16], [1668, 639, 8], [734, 1669, 273, 3, 423, 735, 711, 273], [1670], [2, 347], [11], [421], [4], [429], [22], [295, 511, 1671], [2, 1672, 404], [1673, 23, 266], [1674], [5, 154, 376], [1675], [689, 45], [235], [1676, 1677], [1678], [699], [1679, 1680], [59], [84], [127], [1681, 1682], [2, 1], [68], [17], [171], [1683], [66, 268], [42], [180, 75], [461], [1684, 1685, 238], [2, 509, 510, 416], [37], [458], [736, 65, 396], [672, 143], [128], [176], [215, 185], [199], [236], [7, 1686, 121, 7, 1, 243, 683], [1687, 695, 1688], [737, 586], [388], [57, 39], [231, 211, 301, 429], [466], [53, 431], [706, 420, 1689], [1690], [55, 392, 1, 264], [1691, 463], [1692, 1693], [394, 1694, 395], [53, 1, 62], [3, 559, 58, 31, 110, 8, 299, 243, 256], [172, 157], [1695, 738, 3, 285], [12], [425, 723, 1696], [430], [717], [136], [18, 708, 709, 483], [1697], [158, 309, 85], [212, 1698], [15], [96], [59, 161, 3, 161, 42], [34, 25], [1699], [28], [739, 161, 3, 161, 24, 104, 161, 3, 161, 379], [329], [36, 1, 630, 286], [11], [274, 367, 543, 1700], [740, 1701], [6], [2, 1702, 1703, 7, 1704, 1705, 551], [199, 1706], [1707, 428], [1708], [1709, 205, 31], [612], [18, 1710, 1711, 1712, 1713, 152], [13, 76], [460], [298, 473], [462, 125], [661, 6], [1714, 400, 660], [87], [63], [72, 266], [202], [44], [321], [166, 270, 105], [119, 422, 675, 151, 1715], [478], [1716, 1, 606], [16], [17], [1, 114], [156, 29], [290, 382, 292], [247], [1717, 214], [1718, 227], [557, 6, 1719, 1720], [5, 573, 574, 57], [315], [1721, 23], [741, 545, 1722], [1723, 730], [1724], [30, 20], [210], [439], [2, 405, 406, 1725], [240, 476], [6], [742], [35, 51], [119, 1726, 1, 62], [137, 144], [1727, 1728, 92], [330], [1729, 1], [229, 667], [126, 79, 37], [1730], [151, 1731], [684], [1732], [74, 1733], [427, 31, 1], [108, 222], [428, 1734, 1735, 1736], [53, 234], [1737, 1738], [3, 30, 423, 147], [5, 1739], [365], [38, 346], [3, 605, 1740, 162, 1, 1741, 692], [430], [5, 138], [132, 736, 7, 179, 62], [18, 251, 1742], [694], [1743, 595], [686, 356], [81, 20], [1744, 7, 1745, 1746, 1747, 1748], [1749], [9, 48], [467, 70], [193, 1750], [4], [1751, 309, 82], [1752, 1753, 1], [74, 92], [150, 732], [263, 518, 468], [122], [1754], [47], [1755], [1756], [1757, 1758], [743, 297, 15], [744], [1759, 734, 673], [587], [303], [430, 141], [370, 130, 429], [1760], [1761, 167], [112, 741, 301, 302], [425, 69, 29], [193, 1762], [610], [298, 181], [109], [2, 1763], [1764, 697, 1765], [153, 97], [1766], [362, 1767], [363], [1768, 1769], [1770], [78], [726], [1, 41], [2, 384], [1], [1771], [1772], [2, 1], [80], [36, 1773], [3, 1774, 656, 35, 1775, 1776, 249], [35, 107], [209], [1777], [34, 25], [184], [1778, 745, 361, 278, 32, 542], [3, 9], [240, 1779, 1780], [59, 207, 1781, 1782], [69, 1783], [24, 27], [287], [3, 1784, 52], [1785, 1], [192, 135], [1786], [2, 1787, 223], [226, 155], [6], [98, 7, 737, 39], [12, 733, 39], [191, 1788], [380], [716], [740, 609], [291], [1789, 103], [350, 703, 402, 198], [1790], [308, 1791], [1792], [24, 104, 254], [580, 198], [1793], [6], [746], [1794, 205], [1795, 735, 390], [153, 97], [1], [346, 583, 344], [1], [21], [4], [1, 540], [11, 316, 130, 514, 130], [154, 20], [1796, 1797, 1798, 746], [743, 2, 159], [1799, 246], [31], [1], [125], [417], [281, 1800, 1801], [426, 1802, 411], [1803, 1804, 502], [191, 388], [624], [1805], [79, 739], [1806], [1807, 1808], [88, 104], [11], [4], [310, 47, 1809], [184, 1810], [38], [747, 313], [124, 65], [21], [187, 1], [1811], [5, 1812, 1813, 32], [197, 48], [650, 1814, 7, 1815, 248], [615, 652, 398], [22], [1816, 1, 52], [3, 197, 9, 48], [327, 29, 32], [742], [562], [124, 1817], [1818], [1819], [342], [361, 278, 234], [1820, 390], [70], [747, 313], [645, 1821], [21], [66, 268], [22], [94, 592, 14], [141], [1822, 8], [96, 39], [176], [19, 305], [232], [1823], [1, 205], [738, 146, 682], [84], [745, 394, 1824], [189, 140, 190], [71], [1825, 1826, 369, 700], [5, 1827, 160, 86], [123], [179, 731], [1828], [276, 289, 23, 155, 744, 190, 1829], [6], [379], [271], [5, 46, 365], [5, 1830], [257], [115], [95], [133], [56], [4], [52], [715], [59], [2, 374, 200], [15], [4], [1831], [6], [402, 198], [43], [1832], [64, 1, 513], [729, 1833], [2, 31, 110, 1], [84], [49], [1834], [1835, 103], [1836], [335], [5, 174, 93], [475, 160, 86, 416], [2, 568, 569, 129]]\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 100, 100)          183700    \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 96, 128)           64128     \n",
            "                                                                 \n",
            " global_max_pooling1d_2 (Gl  (None, 128)               0         \n",
            " obalMaxPooling1D)                                               \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 249129 (973.16 KB)\n",
            "Trainable params: 249129 (973.16 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/30\n",
            "63/63 [==============================] - 4s 35ms/step - loss: 0.6708 - accuracy: 0.5786\n",
            "Epoch 2/30\n",
            "63/63 [==============================] - 4s 56ms/step - loss: 0.4881 - accuracy: 0.7743\n",
            "Epoch 3/30\n",
            "63/63 [==============================] - 3s 40ms/step - loss: 0.2143 - accuracy: 0.9209\n",
            "Epoch 4/30\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.1337 - accuracy: 0.9530\n",
            "Epoch 5/30\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.1060 - accuracy: 0.9610\n",
            "Epoch 6/30\n",
            "63/63 [==============================] - 2s 34ms/step - loss: 0.0877 - accuracy: 0.9670\n",
            "Epoch 7/30\n",
            "63/63 [==============================] - 2s 34ms/step - loss: 0.0891 - accuracy: 0.9655\n",
            "Epoch 8/30\n",
            "63/63 [==============================] - 3s 56ms/step - loss: 0.0790 - accuracy: 0.9680\n",
            "Epoch 9/30\n",
            "63/63 [==============================] - 3s 44ms/step - loss: 0.0714 - accuracy: 0.9700\n",
            "Epoch 10/30\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0720 - accuracy: 0.9685\n",
            "Epoch 11/30\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0650 - accuracy: 0.9685\n",
            "Epoch 12/30\n",
            "63/63 [==============================] - 2s 34ms/step - loss: 0.0635 - accuracy: 0.9720\n",
            "Epoch 13/30\n",
            "63/63 [==============================] - 2s 34ms/step - loss: 0.0639 - accuracy: 0.9695\n",
            "Epoch 14/30\n",
            "63/63 [==============================] - 3s 53ms/step - loss: 0.0596 - accuracy: 0.9705\n",
            "Epoch 15/30\n",
            "63/63 [==============================] - 3s 47ms/step - loss: 0.0601 - accuracy: 0.9710\n",
            "Epoch 16/30\n",
            "63/63 [==============================] - 2s 34ms/step - loss: 0.0589 - accuracy: 0.9705\n",
            "Epoch 17/30\n",
            "63/63 [==============================] - 2s 34ms/step - loss: 0.0581 - accuracy: 0.9720\n",
            "Epoch 18/30\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0558 - accuracy: 0.9755\n",
            "Epoch 19/30\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0564 - accuracy: 0.9725\n",
            "Epoch 20/30\n",
            "63/63 [==============================] - 3s 47ms/step - loss: 0.0569 - accuracy: 0.9705\n",
            "Epoch 21/30\n",
            "63/63 [==============================] - 3s 51ms/step - loss: 0.0540 - accuracy: 0.9735\n",
            "Epoch 22/30\n",
            "63/63 [==============================] - 2s 34ms/step - loss: 0.0524 - accuracy: 0.9710\n",
            "Epoch 23/30\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0546 - accuracy: 0.9740\n",
            "Epoch 24/30\n",
            "63/63 [==============================] - 2s 34ms/step - loss: 0.0526 - accuracy: 0.9715\n",
            "Epoch 25/30\n",
            "63/63 [==============================] - 2s 34ms/step - loss: 0.0537 - accuracy: 0.9725\n",
            "Epoch 26/30\n",
            "63/63 [==============================] - 3s 45ms/step - loss: 0.0539 - accuracy: 0.9740\n",
            "Epoch 27/30\n",
            "63/63 [==============================] - 3s 52ms/step - loss: 0.0516 - accuracy: 0.9755\n",
            "Epoch 28/30\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0511 - accuracy: 0.9710\n",
            "Epoch 29/30\n",
            "63/63 [==============================] - 5s 86ms/step - loss: 0.0522 - accuracy: 0.9715\n",
            "Epoch 30/30\n",
            "63/63 [==============================] - 3s 47ms/step - loss: 0.0517 - accuracy: 0.9710\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.9993 - accuracy: 0.7600\n",
            "Test Loss: 0.9992706179618835, Test Accuracy: 0.7599999904632568\n",
            "CPU times: user 1min 47s, sys: 2.18 s, total: 1min 49s\n",
            "Wall time: 1min 24s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "model.save('/content/drive/MyDrive/hackathon/model.h5')"
      ],
      "metadata": {
        "id": "_jACUIiMaDoK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f5b37a5-0c26-4f23-ecf9-9e8f6e2d88a3"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 31.7 ms, sys: 1.55 ms, total: 33.2 ms\n",
            "Wall time: 54.7 ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Skill Extraction"
      ],
      "metadata": {
        "id": "nW0eCEN92R17"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "text='\\n'.join(df['skills'][0])\n",
        "# text+=df['experience'][0]\n",
        "text+='\\n'.join(df['experience'][0])\n",
        "text"
      ],
      "metadata": {
        "id": "-insKt4DgEC-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "outputId": "f21d45c7-a180-4dcc-a5d6-708f712a5860"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 0 ns, sys: 394 µs, total: 394 µs\n",
            "Wall time: 400 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'software, languages, and tools with the ability to learn new tools, databases and systems to maintain/enhance strategic vision of \\nthe organization and able to provide cutting-edge data engineering skills. Seeking a reputable organization to contribute to with \\nopportunities for personal growth.  \\n. TECHNICAL SKILLS \\nLanguages \\n• \\nPython, SQL \\nOthers \\n• \\nGit, Bash \\n \\nData Manipulation & \\nVisualization  \\n• \\nPandas, Tableau BI, ETL, \\nApache Spark, Hadoop \\nHDFS, Snowflake Data \\nFactory, SnowSQL and \\nSnowpipe, Amazon Kinesis \\nFirehose, Databricks, AWS \\nEMR, Athena, Lambda, \\nAmazon MW Apache \\nAirflow and AWS EC2  \\nQuickSight and SNS, \\nCloudera infrastructure – \\nAmbari, Hortonworks \\nSandbox and Zeppelin \\nNotebook \\n \\nDatabases and Storage \\n• \\nAWS RDS, MySQL, \\nMongoDB, AWS \\nDynamoDB, \\nSQLAlchemy, \\nPostgreSQL, AWS S3 \\nBuckets, SQLite, Azure, \\nOracle. \\n \\n \\n  \\n \\n \\n \\nExcellent project and time manager with outstanding excellent presentation skills, a great team player and ability to extend \\nempathy.  \\n \\n \\n \\n \\n \\n \\n \\nData Engineer | TC Energy | Houston, TX | 09/2019– Present | Odfjell Terminal | Seabrook, TX | 02/2019– 09/2019 | Enterprise \\nProducts (Through CF) | Houston, TX | 10/2018 – 02/2019 \\n• \\nDesign and implementation of process data pipeline for asset data migration into AWS cloud environment \\n• \\nBuilt Snowflake Data Pipeline using Amazon Kinesis Firehose starting from the AWS EC2 logs to storage in Snowflake \\nand AWS S3 bucket post-transformation and orchestrating through Amazon Managed Workflows for Apache Airflow \\n(MWAA) DAGs.. Programming language used are Pyspark, Python, SparkSql \\n• \\nArchitecting data pipeline with Cloudera infrastructure – Ambari, Hortonworks Sandbox using Zeppelin Notebook. \\nProgramming language used are Python, SQL \\n• \\nCreated DataStream using AWS kinesis DataStream and kinesis firehose. Programming language used are Pyspark, \\nPython, SparkSql \\n• \\nMigration solution from SAP and Maximo to Data Lake. \\n• \\nSolved data quality issues using AWS Databrew and Apache PySpark on AWS EMR and Databricks on AWS EC2 Clusters \\nfor data wrangling and transformations. \\n• \\nAWS Project monitoring using AWS Lambda and Aurora \\n• \\nPerformed SQL data analysis using Oracle Database \\n• \\nRegular meeting with stakeholders to gather user requirements and ascertain objectives. \\nSenior Data Analyst | Tesoro Logistics (Through IG) | San Antonio, TX | 04/2017 – 10/2018 \\n \\n• \\nDesign and implementation of process data pipeline and loading of structured data for performing quantitative and \\nqualitative asset risk modelling, predictive analysis for program budgeting and forecast. \\n• \\nCreated process safety risk reduction metrics \\nProject Engineer | Weatherford | Houston, TX | 09/2013– 03/2016 \\n• \\nPerformed ETL of drilling well bottom hole pressure ‘.mbd’ data from field and wireline instrumentations (bottom hole \\npressure, well depth and true vertical height of drilling bit). \\n• \\nCleaned and transformed data into a ‘.csv’ data file.  Load data into Weatherford microflux database for analysis. \\n• \\nProject management of secure drilling operations of over 80 wells in Canada, Iraq, Nigeria, Angola, and Cameroon for \\nclients such as Repsol, Shell, Exxon Mobile, Chevron and Total \\n '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "def extract_skills(text):\n",
        "    noun_phrases = extract_noun_phrases(text)\n",
        "    noun_phrases = np.array(noun_phrases).astype(str)\n",
        "\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(noun_phrases)\n",
        "    X_sequences = tokenizer.texts_to_sequences(noun_phrases)\n",
        "\n",
        "    # Pad sequences to ensure uniform length\n",
        "    max_length = 100\n",
        "    X_padded = pad_sequences(X_sequences, maxlen=max_length, padding='post')\n",
        "\n",
        "    # Reshape input data to add embedding dimension\n",
        "    X_padded = np.expand_dims(X_padded, axis=-1)  # Add embedding dimension\n",
        "\n",
        "    predictions = model.predict(X_padded)\n",
        "\n",
        "    # Filter predicted skills based on the threshold\n",
        "    threshold = 0.5  # Adjust as needed\n",
        "    predicted_skills = [noun_phrases[i] for i, pred in enumerate(predictions) if pred > threshold]\n",
        "\n",
        "    return predicted_skills\n"
      ],
      "metadata": {
        "id": "jlWyxP7PZPiH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e47775d8-4c8e-43b0-9094-4ae94ff62629"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n",
            "Wall time: 7.87 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "extracted_skills = extract_skills(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSYAYf_jbxT3",
        "outputId": "09847268-2a96-4e57-a8a7-6c2d5240a296"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 14ms/step\n",
            "CPU times: user 331 ms, sys: 7.69 ms, total: 338 ms\n",
            "Wall time: 382 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "print(f'Extracted Skills: {extracted_skills}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLJMCenR2czv",
        "outputId": "8b2d22a7-10a9-4812-ff90-1b19a70d824c"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Skills: ['software', 'languages', 'tools', 'new tools', 'databases', 'enhance strategic vision', 'opportunities', 'personal growth', 'TECHNICAL SKILLS \\nLanguages \\n• \\nPython', 'SQL \\nOthers \\n• \\nGit', 'Pandas', 'Hadoop \\nHDFS', 'Snowflake Data \\nFactory', 'Amazon Kinesis \\nFirehose', 'Databricks', 'AWS \\nEMR', 'Athena', 'Lambda', 'Amazon MW Apache \\nAirflow', 'Hortonworks \\nSandbox', 'Zeppelin \\nNotebook \\n \\nDatabases', 'Storage', 'MySQL', 'AWS \\nDynamoDB', 'SQLAlchemy', 'AWS S3 \\nBuckets', 'Azure', 'Oracle', 'Excellent project and time manager', 'outstanding excellent presentation skills', 'a great team player', 'Data Engineer | TC Energy', 'Present | Odfjell Terminal', 'TX | 02/2019', '09/2019 | Enterprise \\nProducts', 'CF', 'process data pipeline', 'asset data migration', 'Amazon Kinesis', 'Firehose', 'storage', 'Snowflake', 'bucket', 'Amazon Managed Workflows', 'Programming language', 'Python', 'SparkSql', 'data pipeline', 'Zeppelin Notebook', 'Programming language', 'Python', 'SQL \\n• \\nCreated DataStream', 'AWS kinesis DataStream', 'Programming language', 'Python', 'SparkSql \\n• \\nMigration solution', '• \\nSolved data quality issues', 'AWS EMR', 'Databricks', '• \\nAWS Project monitoring', 'AWS Lambda', 'IG', 'TX |', '04/2017', 'process data pipeline', 'structured data', 'quantitative and \\nqualitative asset risk modelling', 'predictive analysis', 'forecast', 'bottom hole pressure', 'field', 'bottom hole \\npressure', 'true vertical height', 'Load data', 'analysis', '• \\nProject management', 'over 80 wells', 'Canada', 'Iraq', 'Repsol', 'Exxon Mobile', 'Chevron']\n",
            "CPU times: user 183 µs, sys: 10 µs, total: 193 µs\n",
            "Wall time: 203 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "final_skills = '\\n'.join(extracted_skills)"
      ],
      "metadata": {
        "id": "FXmembUXECJK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77a4ea20-93b8-4c27-9962-1fba6748106a"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 16 µs, sys: 0 ns, total: 16 µs\n",
            "Wall time: 19.3 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Abstractive Skill Extraction"
      ],
      "metadata": {
        "id": "4nEb4nPL2GSP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "nlp_model = spacy.load('/content/drive/MyDrive/hackathon/skills_model')\n",
        "# text=df['skills']\n",
        "doc = nlp_model(final_skills)\n",
        "abstractive_skills=''\n",
        "for ent in doc.ents:\n",
        "  abstractive_skills+=ent.text\n",
        "  print(f'{ent.label_.upper()}->\\n {ent.text}')"
      ],
      "metadata": {
        "id": "1c-ZwDBjbK62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e69b9d08-be29-4e08-d477-ce539120ab8c"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SKILLS->\n",
            " Languages \n",
            "• \n",
            "Python\n",
            "SQL \n",
            "Others \n",
            "• \n",
            "Git\n",
            "Pandas\n",
            "Hadoop \n",
            "HDFS\n",
            "Snowflake Data \n",
            "Factory\n",
            "Amazon Kinesis \n",
            "Firehose\n",
            "Databricks\n",
            "AWS \n",
            "EMR\n",
            "Athena\n",
            "Lambda\n",
            "Amazon MW Apache \n",
            "Airflow\n",
            "Hortonworks \n",
            "Sandbox\n",
            "Zeppelin \n",
            "Notebook \n",
            " \n",
            "Databases\n",
            "Storage\n",
            "MySQL\n",
            "AWS \n",
            "DynamoDB\n",
            "SQLAlchemy\n",
            "AWS S3 \n",
            "Buckets\n",
            "Azure\n",
            "Oracle\n",
            "Excellent project and time manager\n",
            "outstanding excellent presentation skills\n",
            "a great team player\n",
            "Data Engineer | TC Energy\n",
            "Present | Odfjell Terminal\n",
            "TX | 02/2019\n",
            "09/2019 | Enterprise \n",
            "Products\n",
            "CF\n",
            "process data pipeline\n",
            "asset data migration\n",
            "Amazon Kinesis\n",
            "Firehose\n",
            "storage\n",
            "Snowflake\n",
            "bucket\n",
            "Amazon Managed Workflows\n",
            "Programming language\n",
            "Python\n",
            "SparkSql\n",
            "data pipeline\n",
            "Zeppelin Notebook\n",
            "Programming language\n",
            "Python\n",
            "SQL \n",
            "• \n",
            "Created DataStream\n",
            "AWS kinesis DataStream\n",
            "Programming language\n",
            "Python\n",
            "SparkSql \n",
            "• \n",
            "Migration solution\n",
            "• \n",
            "Solved data quality issues\n",
            "AWS EMR\n",
            "Databricks\n",
            "• \n",
            "AWS Project monitoring\n",
            "AWS Lambda\n",
            "IG\n",
            "TX |\n",
            "04/2017\n",
            "process data pipeline\n",
            "structured data\n",
            "quantitative and \n",
            "qualitative asset risk modelling\n",
            "predictive analysis\n",
            "forecast\n",
            "bottom hole pressure\n",
            "field\n",
            "bottom hole \n",
            "pressure\n",
            "true vertical height\n",
            "Load data\n",
            "analysis\n",
            "• \n",
            "Project management\n",
            "over 80 wells\n",
            "Canada\n",
            "Iraq\n",
            "Repsol\n",
            "Exxon Mobile\n",
            "Chevron\n",
            "CPU times: user 742 ms, sys: 30.8 ms, total: 773 ms\n",
            "Wall time: 863 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "H1-F_DVyERQp",
        "outputId": "9df98fa1-5f6d-4366-b657-a226c31547fb"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              skills  \\\n",
              "0  [software, languages, and tools with the abili...   \n",
              "\n",
              "                                          experience  \\\n",
              "0  [ ,  ,  ,  ,  , Data Engineer | TC Energy | Ho...   \n",
              "\n",
              "                                           education miscellaneous  \\\n",
              "0  [ ,  ,  , University of North Texas | Master o...           NaN   \n",
              "\n",
              "                                        achievements  \n",
              "0  [ ,  ,  , Licensed Texas Professional Engineer...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-19fde77a-0998-40c2-b4e1-239bbece25c6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>skills</th>\n",
              "      <th>experience</th>\n",
              "      <th>education</th>\n",
              "      <th>miscellaneous</th>\n",
              "      <th>achievements</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[software, languages, and tools with the abili...</td>\n",
              "      <td>[ ,  ,  ,  ,  , Data Engineer | TC Energy | Ho...</td>\n",
              "      <td>[ ,  ,  , University of North Texas | Master o...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[ ,  ,  , Licensed Texas Professional Engineer...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-19fde77a-0998-40c2-b4e1-239bbece25c6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-19fde77a-0998-40c2-b4e1-239bbece25c6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-19fde77a-0998-40c2-b4e1-239bbece25c6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_444fb0fa-e542-4a13-ac58-63ab14f49d01\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_444fb0fa-e542-4a13-ac58-63ab14f49d01 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "repr_error": "'str' object has no attribute 'empty'"
            }
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "final_designation = '\\n'.join(df['experience'][0])\n",
        "final_designation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "OGfO2OeDEkqF",
        "outputId": "33a778fa-affa-4c24-e849-0cabe67fe405"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 131 µs, sys: 8 µs, total: 139 µs\n",
            "Wall time: 144 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' \\n \\n \\n \\n \\nData Engineer | TC Energy | Houston, TX | 09/2019– Present | Odfjell Terminal | Seabrook, TX | 02/2019– 09/2019 | Enterprise \\nProducts (Through CF) | Houston, TX | 10/2018 – 02/2019 \\n• \\nDesign and implementation of process data pipeline for asset data migration into AWS cloud environment \\n• \\nBuilt Snowflake Data Pipeline using Amazon Kinesis Firehose starting from the AWS EC2 logs to storage in Snowflake \\nand AWS S3 bucket post-transformation and orchestrating through Amazon Managed Workflows for Apache Airflow \\n(MWAA) DAGs.. Programming language used are Pyspark, Python, SparkSql \\n• \\nArchitecting data pipeline with Cloudera infrastructure – Ambari, Hortonworks Sandbox using Zeppelin Notebook. \\nProgramming language used are Python, SQL \\n• \\nCreated DataStream using AWS kinesis DataStream and kinesis firehose. Programming language used are Pyspark, \\nPython, SparkSql \\n• \\nMigration solution from SAP and Maximo to Data Lake. \\n• \\nSolved data quality issues using AWS Databrew and Apache PySpark on AWS EMR and Databricks on AWS EC2 Clusters \\nfor data wrangling and transformations. \\n• \\nAWS Project monitoring using AWS Lambda and Aurora \\n• \\nPerformed SQL data analysis using Oracle Database \\n• \\nRegular meeting with stakeholders to gather user requirements and ascertain objectives. \\nSenior Data Analyst | Tesoro Logistics (Through IG) | San Antonio, TX | 04/2017 – 10/2018 \\n \\n• \\nDesign and implementation of process data pipeline and loading of structured data for performing quantitative and \\nqualitative asset risk modelling, predictive analysis for program budgeting and forecast. \\n• \\nCreated process safety risk reduction metrics \\nProject Engineer | Weatherford | Houston, TX | 09/2013– 03/2016 \\n• \\nPerformed ETL of drilling well bottom hole pressure ‘.mbd’ data from field and wireline instrumentations (bottom hole \\npressure, well depth and true vertical height of drilling bit). \\n• \\nCleaned and transformed data into a ‘.csv’ data file.  Load data into Weatherford microflux database for analysis. \\n• \\nProject management of secure drilling operations of over 80 wells in Canada, Iraq, Nigeria, Angola, and Cameroon for \\nclients such as Repsol, Shell, Exxon Mobile, Chevron and Total \\n '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Find Job titles in resume"
      ],
      "metadata": {
        "id": "cGiV7ecr3nnr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "store_designations = []\n",
        "\n",
        "nlp_model_d = spacy.load('/content/drive/MyDrive/hackathon/designation_model')\n",
        "doc = nlp_model_d(final_designation)\n",
        "for ent in doc.ents:\n",
        "    store_designations.append(ent.text)\n",
        "    print(f'{ent.label_.upper():{30}}- {ent.text}')"
      ],
      "metadata": {
        "id": "AYao5cOaEbsi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7513762a-43d0-4155-c64c-704b629bc8b7"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DESIGNATION                   - Senior Data Analyst\n",
            "DESIGNATION                   - Project Engineer\n",
            "CPU times: user 773 ms, sys: 30 ms, total: 803 ms\n",
            "Wall time: 973 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "store_designations"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srYTUZYdKrWy",
        "outputId": "63ea5eae-9232-43b0-9ebf-1b8631f77e93"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
            "Wall time: 6.91 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Senior Data Analyst', 'Project Engineer']"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# O-Net mapping for Standardised Job Title"
      ],
      "metadata": {
        "id": "IzEwrK9P4Trv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Get the file path\n",
        "file_path = '/content/drive/MyDrive/hackathon/data.csv'\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "df_ = pd.read_csv(file_path)\n",
        "\n",
        "# Get the desired column as a list\n",
        "labels = df_['Title'].tolist()\n",
        "codes = df_['O*NET Code'].tolist()\n",
        "res = dict(zip(labels, codes))"
      ],
      "metadata": {
        "id": "YbmyxMD4ly-w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa3e4ffe-1178-42b2-8e03-61690f6e4a87"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 15.3 ms, sys: 985 µs, total: 16.3 ms\n",
            "Wall time: 599 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "model2 = SentenceTransformer('all-MiniLM-L6-v2')"
      ],
      "metadata": {
        "id": "81glzBJKnxEN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c70a6ed9-4274-4a1a-f6d4-0efe04e7f6a1"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 276 ms, sys: 49.2 ms, total: 326 ms\n",
            "Wall time: 2.21 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "standard_job_titles = labels\n",
        "standard_embeddings = model2.encode(standard_job_titles)"
      ],
      "metadata": {
        "id": "U7fdtblPn8Wa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d0f52d9-aef5-461c-afe8-940ae3bb4b05"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 5.26 s, sys: 22 ms, total: 5.28 s\n",
            "Wall time: 5.29 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "extracted_job_titles = store_designations\n",
        "extracted_embeddings = model2.encode(extracted_job_titles)"
      ],
      "metadata": {
        "id": "-OsGj7XYoDfH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "776f6d65-6e04-4716-c57f-e11086f7513b"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 27.5 ms, sys: 969 µs, total: 28.5 ms\n",
            "Wall time: 28.3 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Function to find the most similar standard job title for each extracted job title\n",
        "def find_most_similar_jobs(extracted_embeddings, standard_embeddings, standard_job_titles):\n",
        "    for extracted_embedding in extracted_embeddings:\n",
        "        similarities = util.cos_sim(extracted_embedding, standard_embeddings)\n",
        "        max_index = np.argmax(similarities)\n",
        "\n",
        "        yield standard_job_titles[max_index]"
      ],
      "metadata": {
        "id": "ZgkzYLJDoEtP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ee35ac2-243c-4dbf-9397-e7bbf4144a3b"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n",
            "Wall time: 8.11 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Mapping each extracted job title to the most similar standard job title\n",
        "mapped_job_titles = list(find_most_similar_jobs(extracted_embeddings, standard_embeddings, standard_job_titles))\n",
        "for extracted, mapped in zip(store_designations, mapped_job_titles):\n",
        "    print(f'Extracted: {extracted} -> Mapped: {mapped}')"
      ],
      "metadata": {
        "id": "-TUNWo_roNJX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52349917-0414-414e-e076-5153b52e873d"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted: Senior Data Analyst -> Mapped: Data Scientists\n",
            "Extracted: Project Engineer -> Mapped: Project Management Specialists\n",
            "CPU times: user 8.51 ms, sys: 0 ns, total: 8.51 ms\n",
            "Wall time: 23 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting Education"
      ],
      "metadata": {
        "id": "7tCwSRIH449I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "final_education = '\\n'.join(df['education'][0])\n",
        "final_education"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "Zbh21VwLd3RE",
        "outputId": "aa2dfb7a-8f4d-496c-9172-d1694555b4ad"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 155 µs, sys: 0 ns, total: 155 µs\n",
            "Wall time: 162 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Nirma University\\nAhmedabad, In\\nB.Tech Computer Science Engineering\\n2021-Present\\nCumulative GPA: 8.30/10; Certificate of Scholar, 3rd Semester\\nPuna International School\\nAhmedabad, In\\nHSC, CBSE: 85.4%\\n2021'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting Timeline"
      ],
      "metadata": {
        "id": "S4fYMR8-5SoE"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7-zxSDcKeW0",
        "outputId": "351c8ca5-1866-4f35-8d27-44b882fd6ede"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'2013-09-02': 'Project Engineer', '2017-04-02': 'Senior Data Analyst'}\n",
            "CPU times: user 500 µs, sys: 0 ns, total: 500 µs\n",
            "Wall time: 508 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MS_YL1kVlP4l",
        "outputId": "b90d244f-19c8-4787-d80e-3873cb70e9af"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'2013-09-02': 'Project Management Specialists', '2017-04-02': 'Data Scientists'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mapping description and extracting skills for each job title"
      ],
      "metadata": {
        "id": "SqGdU2EMbJcV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "s=df['experience'][0]\n",
        "s=' '.join(s)\n",
        "l=[0]\n",
        "for i in store_designations:\n",
        "  l+=[s.index(i)]\n",
        "l+=[len(s)]\n",
        "l\n",
        "se=[]\n",
        "for i in range(1,len(l)-1):\n",
        "  se+=[s[l[i]:l[i+1]]]\n",
        "sk=[]\n",
        "for d in se:\n",
        "  sk+=[extract_skills(d)]\n",
        "sk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MI3eQLg9aMo5",
        "outputId": "a786e89f-d4a0-4520-bbc4-2c78b9bc3bea"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Senior Data Analyst | Tesoro Logistics',\n",
              "  'IG',\n",
              "  'TX |',\n",
              "  '04/2017',\n",
              "  '10/2018    •  Design',\n",
              "  'implementation',\n",
              "  'process data pipeline',\n",
              "  'structured data',\n",
              "  'quantitative and  qualitative asset risk modelling',\n",
              "  'predictive analysis',\n",
              "  'forecast'],\n",
              " ['wireline instrumentations',\n",
              "  'well depth',\n",
              "  'true vertical height',\n",
              "  'drilling bit',\n",
              "  'a ‘.csv’ data file',\n",
              "  'Load data',\n",
              "  'Weatherford microflux database',\n",
              "  'analysis',\n",
              "  '•  Project management',\n",
              "  'secure drilling operations',\n",
              "  'Iraq',\n",
              "  'Angola',\n",
              "  'clients',\n",
              "  'Repsol',\n",
              "  'Exxon Mobile',\n",
              "  'Total']]"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "skill_preds=[]\n",
        "for skill in sk:\n",
        "  temp='\\n'.join(skill)\n",
        "  doc=nlp_model(temp)\n",
        "  temp_skills=''\n",
        "  for ent in doc.ents:\n",
        "   temp_skills+=ent.text\n",
        "  skill_preds.append(temp_skills)"
      ],
      "metadata": {
        "id": "3GqeSgCjbsxA"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resume Summary"
      ],
      "metadata": {
        "id": "fMLOC5XlB_mp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "14zk6dbMFU0n",
        "outputId": "e29d3d9c-1534-4837-aaa3-17bf5da17baf"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              skills  \\\n",
              "0  [software, languages, and tools with the abili...   \n",
              "\n",
              "                                          experience  \\\n",
              "0  [ ,  ,  ,  ,  , Data Engineer | TC Energy | Ho...   \n",
              "\n",
              "                                           education miscellaneous  \\\n",
              "0  [ ,  ,  , University of North Texas | Master o...           NaN   \n",
              "\n",
              "                                        achievements  \n",
              "0  [ ,  ,  , Licensed Texas Professional Engineer...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7d70e5f8-4830-4adc-83fd-51701d5be729\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>skills</th>\n",
              "      <th>experience</th>\n",
              "      <th>education</th>\n",
              "      <th>miscellaneous</th>\n",
              "      <th>achievements</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[software, languages, and tools with the abili...</td>\n",
              "      <td>[ ,  ,  ,  ,  , Data Engineer | TC Energy | Ho...</td>\n",
              "      <td>[ ,  ,  , University of North Texas | Master o...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[ ,  ,  , Licensed Texas Professional Engineer...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7d70e5f8-4830-4adc-83fd-51701d5be729')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7d70e5f8-4830-4adc-83fd-51701d5be729 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7d70e5f8-4830-4adc-83fd-51701d5be729');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_97e41c60-8ba5-4ad0-9f32-88aa9add36e6\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_97e41c60-8ba5-4ad0-9f32-88aa9add36e6 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "repr_error": "'str' object has no attribute 'empty'"
            }
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "raw_exp='\\n'.join(df.iloc[0]['experience'])\n",
        "raw_exp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "urHdETlLKGfx",
        "outputId": "3ef18f35-ff5b-4047-9aac-4ff47702f3f3"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' \\n \\n \\n \\n \\nData Engineer | TC Energy | Houston, TX | 09/2019– Present | Odfjell Terminal | Seabrook, TX | 02/2019– 09/2019 | Enterprise \\nProducts (Through CF) | Houston, TX | 10/2018 – 02/2019 \\n• \\nDesign and implementation of process data pipeline for asset data migration into AWS cloud environment \\n• \\nBuilt Snowflake Data Pipeline using Amazon Kinesis Firehose starting from the AWS EC2 logs to storage in Snowflake \\nand AWS S3 bucket post-transformation and orchestrating through Amazon Managed Workflows for Apache Airflow \\n(MWAA) DAGs.. Programming language used are Pyspark, Python, SparkSql \\n• \\nArchitecting data pipeline with Cloudera infrastructure – Ambari, Hortonworks Sandbox using Zeppelin Notebook. \\nProgramming language used are Python, SQL \\n• \\nCreated DataStream using AWS kinesis DataStream and kinesis firehose. Programming language used are Pyspark, \\nPython, SparkSql \\n• \\nMigration solution from SAP and Maximo to Data Lake. \\n• \\nSolved data quality issues using AWS Databrew and Apache PySpark on AWS EMR and Databricks on AWS EC2 Clusters \\nfor data wrangling and transformations. \\n• \\nAWS Project monitoring using AWS Lambda and Aurora \\n• \\nPerformed SQL data analysis using Oracle Database \\n• \\nRegular meeting with stakeholders to gather user requirements and ascertain objectives. \\nSenior Data Analyst | Tesoro Logistics (Through IG) | San Antonio, TX | 04/2017 – 10/2018 \\n \\n• \\nDesign and implementation of process data pipeline and loading of structured data for performing quantitative and \\nqualitative asset risk modelling, predictive analysis for program budgeting and forecast. \\n• \\nCreated process safety risk reduction metrics \\nProject Engineer | Weatherford | Houston, TX | 09/2013– 03/2016 \\n• \\nPerformed ETL of drilling well bottom hole pressure ‘.mbd’ data from field and wireline instrumentations (bottom hole \\npressure, well depth and true vertical height of drilling bit). \\n• \\nCleaned and transformed data into a ‘.csv’ data file.  Load data into Weatherford microflux database for analysis. \\n• \\nProject management of secure drilling operations of over 80 wells in Canada, Iraq, Nigeria, Angola, and Cameroon for \\nclients such as Repsol, Shell, Exxon Mobile, Chevron and Total \\n '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Replacing Job Titles with Standard O*Net Job Titles"
      ],
      "metadata": {
        "id": "iC79vCY_VIAz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "def replace_strings(work_experience, original_strings, replacement_strings):\n",
        "    \"\"\"\n",
        "    Replace occurrences of strings in 'original_strings' with corresponding strings in 'replacement_strings' in the 'work_experience' text.\n",
        "\n",
        "    Parameters:\n",
        "    - work_experience (str): The text containing the work experience.\n",
        "    - original_strings (list of str): Strings to be replaced.\n",
        "    - replacement_strings (list of str): Strings to replace with.\n",
        "\n",
        "    Returns:\n",
        "    - str: Updated work experience text.\n",
        "    \"\"\"\n",
        "    for original, replacement in zip(original_strings, replacement_strings):\n",
        "        work_experience = work_experience.replace(original, replacement)\n",
        "    return work_experience"
      ],
      "metadata": {
        "id": "BdSnKFYvRCMh"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "final_exp = replace_strings(raw_exp, store_designations, mapped_job_titles)"
      ],
      "metadata": {
        "id": "Vc0-ZAUCRIdE"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "for designation, standard_designation in store_designations, mapped_job_titles:\n",
        "  if designation in raw_exp:\n",
        "    raw_exp.replace(designation, standard_designation)"
      ],
      "metadata": {
        "id": "jaEES2J3MHlG"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from transformers import pipeline\n",
        "\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")"
      ],
      "metadata": {
        "id": "3yAsPUedRq4e"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "import re\n",
        "\n",
        "def time_line():\n",
        "  date_pattern = r'\\b(?:\\d{2}/\\d{4}|\\d{2}/\\d{2}|\\d{2}-\\d{2}-\\d{2}|\\d{2}-\\d{2}-\\d{4})\\b'\n",
        "\n",
        "\n",
        "  #for designation\n",
        "  date_with_designation = []\n",
        "  for designations in store_designations:\n",
        "    index = final_designation.index(designations)\n",
        "    temp_str = final_designation[index : ]\n",
        "\n",
        "    dates = re.findall(date_pattern, temp_str)\n",
        "    if(len(dates) > 0):\n",
        "      date_with_designation.append(dates[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  return date_with_designation\n",
        "\n",
        "des_date = time_line()\n",
        "\n",
        "from dateutil.parser import parse\n",
        "\n",
        "# print(mapped_titles)\n",
        "# print(des_date)\n",
        "\n",
        "\n",
        "time = dict(zip(des_date, store_designations))\n",
        "dates = [parse(date_str) for date_str in des_date]\n",
        "sorted_dates_with_titles = sorted(zip(dates, store_designations))\n",
        "sorted_dates = [date.strftime('%Y-%m-%d') for date, _ in sorted_dates_with_titles]\n",
        "sorted_titles = [title for _, title in sorted_dates_with_titles]\n",
        "sorted_time = dict(zip(sorted_dates, sorted_titles))\n",
        "\n",
        "# print(sorted_time)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8Ci1-jZl96b",
        "outputId": "a21b12ef-9b29-48fa-91c3-74ee71937b7b"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'2013-09-02': 'Project Engineer', '2017-04-02': 'Senior Data Analyst'}\n",
            "CPU times: user 1.68 ms, sys: 0 ns, total: 1.68 ms\n",
            "Wall time: 1.66 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "print('----------------------------')\n",
        "print('RESUME DETAILS')\n",
        "print('----------------------------')\n",
        "print('----------------------------')\n",
        "print('EDUCATION')\n",
        "print('----------------------------')\n",
        "print('\\n'.join(df.iloc[0]['education']))\n",
        "print('----------------------------')\n",
        "print('----------------------------')\n",
        "print('EXPERIENCE')\n",
        "print('----------------------------')\n",
        "print('DESIGNATIONS AS PER O*NET DATABASE:')\n",
        "print('----------------------------')\n",
        "# print('\\n'.join(mapped_job_titles))\n",
        "for jtitle, desc, skill_pred in zip(mapped_job_titles,se,skill_preds):\n",
        "  print('***TITLE***')\n",
        "  print(f'{jtitle} --> {res[jtitle]}')\n",
        "  print('***DESCRIPTION***')\n",
        "  print(desc)\n",
        "  print('***PREDICTED SKILLS***')\n",
        "  print(skill_pred)\n",
        "  print('\\n')\n",
        "\n",
        "print('----------------------------')\n",
        "# print('\\n'.join(df.iloc[0]['experience']))\n",
        "# print(final_exp.strip())\n",
        "print('----------------------------')\n",
        "print('ABSTRACTIVE SKILLS')\n",
        "print('----------------------------')\n",
        "print(abstractive_skills)\n",
        "print('----------------------------')\n",
        "print('----------------------------')\n",
        "print('SKILLS')\n",
        "print('----------------------------')\n",
        "print('\\n'.join(df.iloc[0]['skills']))\n",
        "print('----------------------------')\n",
        "print('----------------------------')\n",
        "print('ACHIEVEMENTS')\n",
        "print('----------------------------')\n",
        "print('\\n'.join(df.iloc[0]['achievements']))\n",
        "print('----------------------------')\n",
        "print('----------------------------')\n",
        "print('CAREER TRAJECTORY')\n",
        "print('----------------------------')\n",
        "for key in sorted_time:\n",
        "  print(f'{key}--->{sorted_time[key]}')\n",
        "print('----------------------------')\n",
        "print('----------------------------')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuT8SEU1FVT4",
        "outputId": "02400606-be10-45ec-813d-28517e838cd5"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------\n",
            "RESUME DETAILS\n",
            "----------------------------\n",
            "----------------------------\n",
            "EDUCATION\n",
            "----------------------------\n",
            " \n",
            " \n",
            " \n",
            "University of North Texas | Master of Science | Mechanical and Energy Engineering| Denton, TX \n",
            "Rice University | Certificate | Data Analytics | Houston, TX  \n",
            " \n",
            "----------------------------\n",
            "----------------------------\n",
            "EXPERIENCE\n",
            "----------------------------\n",
            "DESIGNATIONS AS PER O*NET DATABASE:\n",
            "----------------------------\n",
            "***TITLE***\n",
            "Data Scientists --> 15-2051.00\n",
            "***DESCRIPTION***\n",
            "Senior Data Analyst | Tesoro Logistics (Through IG) | San Antonio, TX | 04/2017 – 10/2018    •  Design and implementation of process data pipeline and loading of structured data for performing quantitative and  qualitative asset risk modelling, predictive analysis for program budgeting and forecast.  •  Created process safety risk reduction metrics  \n",
            "***PREDICTED SKILLS***\n",
            "\n",
            "\n",
            "\n",
            "***TITLE***\n",
            "Project Management Specialists --> 13-1082.00\n",
            "***DESCRIPTION***\n",
            "Project Engineer | Weatherford | Houston, TX | 09/2013– 03/2016  •  Performed ETL of drilling well bottom hole pressure ‘.mbd’ data from field and wireline instrumentations (bottom hole  pressure, well depth and true vertical height of drilling bit).  •  Cleaned and transformed data into a ‘.csv’ data file.  Load data into Weatherford microflux database for analysis.  •  Project management of secure drilling operations of over 80 wells in Canada, Iraq, Nigeria, Angola, and Cameroon for  clients such as Repsol, Shell, Exxon Mobile, Chevron and Total   \n",
            "***PREDICTED SKILLS***\n",
            "\n",
            "\n",
            "\n",
            "----------------------------\n",
            "----------------------------\n",
            "ABSTRACTIVE SKILLS\n",
            "----------------------------\n",
            "Languages \n",
            "• \n",
            "Python\n",
            "SQL \n",
            "Others \n",
            "• \n",
            "Git\n",
            "Pandas\n",
            "Hadoop \n",
            "HDFS\n",
            "Snowflake Data \n",
            "Factory\n",
            "Amazon Kinesis \n",
            "Firehose\n",
            "Databricks\n",
            "AWS \n",
            "EMR\n",
            "Athena\n",
            "Lambda\n",
            "Amazon MW Apache \n",
            "Airflow\n",
            "Hortonworks \n",
            "Sandbox\n",
            "Zeppelin \n",
            "Notebook \n",
            " \n",
            "Databases\n",
            "Storage\n",
            "MySQL\n",
            "AWS \n",
            "DynamoDB\n",
            "SQLAlchemy\n",
            "AWS S3 \n",
            "Buckets\n",
            "Azure\n",
            "Oracle\n",
            "Excellent project and time manager\n",
            "outstanding excellent presentation skills\n",
            "a great team player\n",
            "Data Engineer | TC Energy\n",
            "Present | Odfjell Terminal\n",
            "TX | 02/2019\n",
            "09/2019 | Enterprise \n",
            "Products\n",
            "CF\n",
            "process data pipeline\n",
            "asset data migration\n",
            "Amazon Kinesis\n",
            "Firehose\n",
            "storage\n",
            "Snowflake\n",
            "bucket\n",
            "Amazon Managed Workflows\n",
            "Programming language\n",
            "Python\n",
            "SparkSql\n",
            "data pipeline\n",
            "Zeppelin Notebook\n",
            "Programming language\n",
            "Python\n",
            "SQL \n",
            "• \n",
            "Created DataStream\n",
            "AWS kinesis DataStream\n",
            "Programming language\n",
            "Python\n",
            "SparkSql \n",
            "• \n",
            "Migration solution\n",
            "• \n",
            "Solved data quality issues\n",
            "AWS EMR\n",
            "Databricks\n",
            "• \n",
            "AWS Project monitoring\n",
            "AWS Lambda\n",
            "IG\n",
            "TX |\n",
            "04/2017\n",
            "process data pipeline\n",
            "structured data\n",
            "quantitative and \n",
            "qualitative asset risk modelling\n",
            "predictive analysis\n",
            "forecast\n",
            "bottom hole pressure\n",
            "field\n",
            "bottom hole \n",
            "pressure\n",
            "true vertical height\n",
            "Load data\n",
            "analysis\n",
            "• \n",
            "Project management\n",
            "over 80 wells\n",
            "Canada\n",
            "Iraq\n",
            "Repsol\n",
            "Exxon Mobile\n",
            "Chevron\n",
            "----------------------------\n",
            "----------------------------\n",
            "SKILLS\n",
            "----------------------------\n",
            "software, languages, and tools with the ability to learn new tools, databases and systems to maintain/enhance strategic vision of \n",
            "the organization and able to provide cutting-edge data engineering skills. Seeking a reputable organization to contribute to with \n",
            "opportunities for personal growth.  \n",
            ". TECHNICAL SKILLS \n",
            "Languages \n",
            "• \n",
            "Python, SQL \n",
            "Others \n",
            "• \n",
            "Git, Bash \n",
            " \n",
            "Data Manipulation & \n",
            "Visualization  \n",
            "• \n",
            "Pandas, Tableau BI, ETL, \n",
            "Apache Spark, Hadoop \n",
            "HDFS, Snowflake Data \n",
            "Factory, SnowSQL and \n",
            "Snowpipe, Amazon Kinesis \n",
            "Firehose, Databricks, AWS \n",
            "EMR, Athena, Lambda, \n",
            "Amazon MW Apache \n",
            "Airflow and AWS EC2  \n",
            "QuickSight and SNS, \n",
            "Cloudera infrastructure – \n",
            "Ambari, Hortonworks \n",
            "Sandbox and Zeppelin \n",
            "Notebook \n",
            " \n",
            "Databases and Storage \n",
            "• \n",
            "AWS RDS, MySQL, \n",
            "MongoDB, AWS \n",
            "DynamoDB, \n",
            "SQLAlchemy, \n",
            "PostgreSQL, AWS S3 \n",
            "Buckets, SQLite, Azure, \n",
            "Oracle. \n",
            " \n",
            " \n",
            "  \n",
            " \n",
            " \n",
            " \n",
            "Excellent project and time manager with outstanding excellent presentation skills, a great team player and ability to extend \n",
            "empathy.  \n",
            " \n",
            " \n",
            "\n",
            "----------------------------\n",
            "----------------------------\n",
            "ACHIEVEMENTS\n",
            "----------------------------\n",
            " \n",
            " \n",
            " \n",
            "Licensed Texas Professional Engineer | Texas Board of Professional Engineer and Land Surveyors \n",
            " \n",
            "----------------------------\n",
            "----------------------------\n",
            "CAREER TRAJECTORY\n",
            "----------------------------\n",
            "2013-09-02--->Project Engineer\n",
            "2017-04-02--->Senior Data Analyst\n",
            "----------------------------\n",
            "----------------------------\n",
            "CPU times: user 7.12 ms, sys: 3 µs, total: 7.13 ms\n",
            "Wall time: 10.4 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9cW7GggDnU-2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}